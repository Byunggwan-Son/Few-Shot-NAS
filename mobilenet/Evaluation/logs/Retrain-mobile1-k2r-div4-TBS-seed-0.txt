[05/30 06:05:37] Re-training INFO: tag                 : mobile1-k2r-div4-TBS
[05/30 06:05:37] Re-training INFO: arch                : [5, 6, 6, 2, 4, 0, 2, 0, 4, 0, 2, 6, 1, 2, 4, 2, 5, 4, 0, 3, 3]
[05/30 06:05:37] Re-training INFO: seed                : 0
[05/30 06:05:37] Re-training INFO: data_path           : ../../../dataset/ILSVRC2012
[05/30 06:05:37] Re-training INFO: save_path           : ./Evaluation
[05/30 06:05:37] Re-training INFO: search_space        : proxyless
[05/30 06:05:37] Re-training INFO: valid_size          : 0
[05/30 06:05:37] Re-training INFO: num_gpus            : 8
[05/30 06:05:37] Re-training INFO: workers             : 4
[05/30 06:05:37] Re-training INFO: interval_ep_eval    : 20
[05/30 06:05:37] Re-training INFO: train_batch_size    : 1024
[05/30 06:05:37] Re-training INFO: test_batch_size     : 256
[05/30 06:05:37] Re-training INFO: max_epoch           : 240
[05/30 06:05:37] Re-training INFO: learning_rate       : 0.5
[05/30 06:05:37] Re-training INFO: momentum            : 0.9
[05/30 06:05:37] Re-training INFO: weight_decay        : 4e-05
[05/30 06:05:37] Re-training INFO: nesterov            : True
[05/30 06:05:37] Re-training INFO: lr_schedule_type    : cosine
[05/30 06:05:37] Re-training INFO: warmup              : False
[05/30 06:05:37] Re-training INFO: drop_out            : 0.2
[05/30 06:05:37] Re-training INFO: label_smooth        : 0.1
[05/30 06:05:37] Re-training INFO: rank                : 0
[05/30 06:05:37] Re-training INFO: gpu                 : 0
[05/30 06:05:37] Re-training INFO: save_name           : Retrain-mobile1-k2r-div4-TBS-seed-0
[05/30 06:05:37] Re-training INFO: log_path            : ./Evaluation/logs/Retrain-mobile1-k2r-div4-TBS-seed-0.txt
[05/30 06:05:37] Re-training INFO: ckpt_path           : ./Evaluation/checkpoint/Retrain-mobile1-k2r-div4-TBS-seed-0.pt
[05/30 06:05:37] Re-training INFO: dist_url            : tcp://127.0.0.1:23456
[05/30 06:05:37] Re-training INFO: world_size          : 8
[05/30 06:05:37] Re-training INFO: distributed         : True
[05/30 06:05:37] Re-training INFO: ['3x3_MBConv3', '3x3_MBConv6', '5x5_MBConv3', '5x5_MBConv6', '7x7_MBConv3', '7x7_MBConv6', 'Identity']
[05/30 06:05:44] Re-training INFO: # of Params : 3.937
[05/30 06:05:45] Re-training INFO: DistributedDataParallel(
  (module): CNN(
    (first_conv): Sequential(
      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU6(inplace=True)
    )
    (first_block): InvertedResidual(
      (depth_conv): Sequential(
        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
        (1): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
      )
      (point_linear): Sequential(
        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): SyncBatchNorm(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (blocks): ModuleList(
      (0): InvertedResidual(
        (inverted_bottleneck): Sequential(
          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (depth_conv): Sequential(
          (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=96, bias=False)
          (1): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (point_linear): Sequential(
          (0): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Identity()
      (2): Identity()
      (3): InvertedResidual(
        (inverted_bottleneck): Sequential(
          (0): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (depth_conv): Sequential(
          (0): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=96, bias=False)
          (1): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (point_linear): Sequential(
          (0): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): InvertedResidual(
        (inverted_bottleneck): Sequential(
          (0): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (depth_conv): Sequential(
          (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=96, bias=False)
          (1): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (point_linear): Sequential(
          (0): Conv2d(96, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): InvertedResidual(
        (inverted_bottleneck): Sequential(
          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (depth_conv): Sequential(
          (0): Conv2d(120, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=120, bias=False)
          (1): SyncBatchNorm(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (point_linear): Sequential(
          (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (6): InvertedResidual(
        (inverted_bottleneck): Sequential(
          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (depth_conv): Sequential(
          (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)
          (1): SyncBatchNorm(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (point_linear): Sequential(
          (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (7): InvertedResidual(
        (inverted_bottleneck): Sequential(
          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (depth_conv): Sequential(
          (0): Conv2d(120, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=120, bias=False)
          (1): SyncBatchNorm(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (point_linear): Sequential(
          (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (8): InvertedResidual(
        (inverted_bottleneck): Sequential(
          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (depth_conv): Sequential(
          (0): Conv2d(120, 120, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=120, bias=False)
          (1): SyncBatchNorm(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (point_linear): Sequential(
          (0): Conv2d(120, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (9): InvertedResidual(
        (inverted_bottleneck): Sequential(
          (0): Conv2d(80, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (depth_conv): Sequential(
          (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=240, bias=False)
          (1): SyncBatchNorm(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (point_linear): Sequential(
          (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (10): InvertedResidual(
        (inverted_bottleneck): Sequential(
          (0): Conv2d(80, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (depth_conv): Sequential(
          (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)
          (1): SyncBatchNorm(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (point_linear): Sequential(
          (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (11): Identity()
      (12): InvertedResidual(
        (inverted_bottleneck): Sequential(
          (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (depth_conv): Sequential(
          (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)
          (1): SyncBatchNorm(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (point_linear): Sequential(
          (0): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (13): InvertedResidual(
        (inverted_bottleneck): Sequential(
          (0): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (depth_conv): Sequential(
          (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)
          (1): SyncBatchNorm(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (point_linear): Sequential(
          (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (14): InvertedResidual(
        (inverted_bottleneck): Sequential(
          (0): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (depth_conv): Sequential(
          (0): Conv2d(288, 288, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=288, bias=False)
          (1): SyncBatchNorm(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (point_linear): Sequential(
          (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (15): InvertedResidual(
        (inverted_bottleneck): Sequential(
          (0): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (depth_conv): Sequential(
          (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)
          (1): SyncBatchNorm(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (point_linear): Sequential(
          (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (16): InvertedResidual(
        (inverted_bottleneck): Sequential(
          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (depth_conv): Sequential(
          (0): Conv2d(576, 576, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=576, bias=False)
          (1): SyncBatchNorm(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (point_linear): Sequential(
          (0): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (17): InvertedResidual(
        (inverted_bottleneck): Sequential(
          (0): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (depth_conv): Sequential(
          (0): Conv2d(576, 576, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=576, bias=False)
          (1): SyncBatchNorm(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (point_linear): Sequential(
          (0): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (18): InvertedResidual(
        (inverted_bottleneck): Sequential(
          (0): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (depth_conv): Sequential(
          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
          (1): SyncBatchNorm(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (point_linear): Sequential(
          (0): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (19): InvertedResidual(
        (inverted_bottleneck): Sequential(
          (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (depth_conv): Sequential(
          (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)
          (1): SyncBatchNorm(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (point_linear): Sequential(
          (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (20): InvertedResidual(
        (inverted_bottleneck): Sequential(
          (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (depth_conv): Sequential(
          (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)
          (1): SyncBatchNorm(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (point_linear): Sequential(
          (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (feature_mix_layer): Sequential(
      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): SyncBatchNorm(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU6(inplace=True)
    )
    (avgpool): AvgPool2d(kernel_size=7, stride=7, padding=0)
    (classifier): Sequential(
      (0): Dropout(p=0.2, inplace=False)
      (1): Linear(in_features=1280, out_features=1000, bias=True)
    )
  )
)
[05/30 06:05:53] Re-training INFO: Trainset Size: 1281167
[05/30 06:05:53] Re-training INFO: Validset Size:   50000
[05/30 06:05:53] Re-training INFO: Compose(
    RandomResizedCrop(size=(224, 224), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=bilinear)
    RandomHorizontalFlip(p=0.5)
    ColorJitter(brightness=[0.6, 1.4], contrast=[0.6, 1.4], saturation=[0.6, 1.4], hue=[-0.1, 0.1])
    ToTensor()
    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
)
[05/30 06:05:53] Re-training INFO: SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.5
    lr: 0.5
    momentum: 0.9
    nesterov: True
    weight_decay: 4e-05

Parameter Group 1
    dampening: 0
    initial_lr: 0.5
    lr: 0.5
    momentum: 0.9
    nesterov: True
    weight_decay: 0.0
)
[05/30 06:05:53] Re-training INFO: <torch.optim.lr_scheduler.CosineAnnealingLR object at 0x7f15d46db310>
[05/30 06:05:53] Re-training INFO: --> START Retrain-mobile1-k2r-div4-TBS-seed-0
[05/30 06:07:43] Re-training INFO: iter:   125/300480  CE: 6.5205  
[05/30 06:09:08] Re-training INFO: iter:   250/300480  CE: 5.9746  
[05/30 06:10:32] Re-training INFO: iter:   375/300480  CE: 5.7607  
[05/30 06:11:57] Re-training INFO: iter:   500/300480  CE: 5.8183  
[05/30 06:13:22] Re-training INFO: iter:   625/300480  CE: 5.4026  
[05/30 06:14:46] Re-training INFO: iter:   750/300480  CE: 4.7538  
[05/30 06:16:10] Re-training INFO: iter:   875/300480  CE: 5.1212  
[05/30 06:17:35] Re-training INFO: iter:  1000/300480  CE: 4.8109  
[05/30 06:18:59] Re-training INFO: iter:  1125/300480  CE: 4.4972  
[05/30 06:20:22] Re-training INFO: iter:  1250/300480  CE: 4.7158  
[05/30 06:20:22] Re-training INFO: --> epoch:   1/240  avg CE: 5.4646  lr: 0.49997858189350175
[05/30 06:22:05] Re-training INFO: iter:  1375/300480  CE: 4.5452  
[05/30 06:23:31] Re-training INFO: iter:  1500/300480  CE: 4.4117  
[05/30 06:24:58] Re-training INFO: iter:  1625/300480  CE: 4.6305  
[05/30 06:26:25] Re-training INFO: iter:  1750/300480  CE: 4.6127  
[05/30 06:27:52] Re-training INFO: iter:  1875/300480  CE: 4.0416  
[05/30 06:29:16] Re-training INFO: iter:  2000/300480  CE: 4.3524  
[05/30 06:30:42] Re-training INFO: iter:  2125/300480  CE: 4.2655  
[05/30 06:32:07] Re-training INFO: iter:  2250/300480  CE: 4.3977  
[05/30 06:33:32] Re-training INFO: iter:  2375/300480  CE: 4.1116  
[05/30 06:34:58] Re-training INFO: iter:  2500/300480  CE: 4.2516  
[05/30 06:34:59] Re-training INFO: --> epoch:   2/240  avg CE: 4.2673  lr: 0.4999143312438893
[05/30 06:36:43] Re-training INFO: iter:  2625/300480  CE: 3.8897  
[05/30 06:38:10] Re-training INFO: iter:  2750/300480  CE: 3.9207  
[05/30 06:39:38] Re-training INFO: iter:  2875/300480  CE: 3.8879  
[05/30 06:41:05] Re-training INFO: iter:  3000/300480  CE: 4.0244  
[05/30 06:42:32] Re-training INFO: iter:  3125/300480  CE: 4.0347  
[05/30 06:43:58] Re-training INFO: iter:  3250/300480  CE: 3.8761  
[05/30 06:45:24] Re-training INFO: iter:  3375/300480  CE: 3.8158  
[05/30 06:46:50] Re-training INFO: iter:  3500/300480  CE: 3.7006  
[05/30 06:48:17] Re-training INFO: iter:  3625/300480  CE: 3.6812  
[05/30 06:49:44] Re-training INFO: iter:  3750/300480  CE: 3.8278  
[05/30 06:49:46] Re-training INFO: --> epoch:   3/240  avg CE: 3.8407  lr: 0.49980725906018075
[05/30 06:51:28] Re-training INFO: iter:  3875/300480  CE: 3.5885  
[05/30 06:52:55] Re-training INFO: iter:  4000/300480  CE: 3.6613  
[05/30 06:54:23] Re-training INFO: iter:  4125/300480  CE: 3.6508  
[05/30 06:55:50] Re-training INFO: iter:  4250/300480  CE: 3.5885  
[05/30 06:57:18] Re-training INFO: iter:  4375/300480  CE: 3.6510  
[05/30 06:58:45] Re-training INFO: iter:  4500/300480  CE: 3.7209  
[05/30 07:00:13] Re-training INFO: iter:  4625/300480  CE: 3.3941  
[05/30 07:01:38] Re-training INFO: iter:  4750/300480  CE: 3.7718  
[05/30 07:03:03] Re-training INFO: iter:  4875/300480  CE: 3.5086  
[05/30 07:04:27] Re-training INFO: iter:  5000/300480  CE: 3.3309  
[05/30 07:04:31] Re-training INFO: --> epoch:   4/240  avg CE: 3.6294  lr: 0.49965738368864343
[05/30 07:06:11] Re-training INFO: iter:  5125/300480  CE: 3.4658  
[05/30 07:07:40] Re-training INFO: iter:  5250/300480  CE: 3.4186  
[05/30 07:09:08] Re-training INFO: iter:  5375/300480  CE: 3.4237  
[05/30 07:10:34] Re-training INFO: iter:  5500/300480  CE: 3.5975  
[05/30 07:12:02] Re-training INFO: iter:  5625/300480  CE: 3.7098  
[05/30 07:13:29] Re-training INFO: iter:  5750/300480  CE: 3.1363  
[05/30 07:14:55] Re-training INFO: iter:  5875/300480  CE: 3.3651  
[05/30 07:16:21] Re-training INFO: iter:  6000/300480  CE: 3.2357  
[05/30 07:17:46] Re-training INFO: iter:  6125/300480  CE: 3.4036  
[05/30 07:19:10] Re-training INFO: iter:  6250/300480  CE: 3.5109  
[05/30 07:19:15] Re-training INFO: --> epoch:   5/240  avg CE: 3.4883  lr: 0.49946473080965087
[05/30 07:20:50] Re-training INFO: iter:  6375/300480  CE: 3.4944  
[05/30 07:22:13] Re-training INFO: iter:  6500/300480  CE: 2.9212  
[05/30 07:23:37] Re-training INFO: iter:  6625/300480  CE: 3.1487  
[05/30 07:25:01] Re-training INFO: iter:  6750/300480  CE: 3.4552  
[05/30 07:26:26] Re-training INFO: iter:  6875/300480  CE: 3.1917  
[05/30 07:27:50] Re-training INFO: iter:  7000/300480  CE: 3.3598  
[05/30 07:29:14] Re-training INFO: iter:  7125/300480  CE: 3.4363  
[05/30 07:30:38] Re-training INFO: iter:  7250/300480  CE: 3.2208  
[05/30 07:32:02] Re-training INFO: iter:  7375/300480  CE: 3.4524  
[05/30 07:33:26] Re-training INFO: iter:  7500/300480  CE: 3.3014  
[05/30 07:33:33] Re-training INFO: --> epoch:   6/240  avg CE: 3.3909  lr: 0.499229333433282
[05/30 07:35:13] Re-training INFO: iter:  7625/300480  CE: 3.0360  
[05/30 07:36:42] Re-training INFO: iter:  7750/300480  CE: 3.3337  
[05/30 07:38:09] Re-training INFO: iter:  7875/300480  CE: 3.7097  
[05/30 07:39:36] Re-training INFO: iter:  8000/300480  CE: 3.1779  
[05/30 07:41:04] Re-training INFO: iter:  8125/300480  CE: 3.5293  
[05/30 07:42:30] Re-training INFO: iter:  8250/300480  CE: 3.4075  
[05/30 07:43:57] Re-training INFO: iter:  8375/300480  CE: 3.3431  
[05/30 07:45:24] Re-training INFO: iter:  8500/300480  CE: 3.3815  
[05/30 07:46:48] Re-training INFO: iter:  8625/300480  CE: 3.2795  
[05/30 07:48:13] Re-training INFO: iter:  8750/300480  CE: 3.3675  
[05/30 07:48:20] Re-training INFO: --> epoch:   7/240  avg CE: 3.3250  lr: 0.4989512318936654
[05/30 07:49:58] Re-training INFO: iter:  8875/300480  CE: 3.1670  
[05/30 07:51:26] Re-training INFO: iter:  9000/300480  CE: 3.2372  
[05/30 07:52:53] Re-training INFO: iter:  9125/300480  CE: 3.2577  
[05/30 07:54:21] Re-training INFO: iter:  9250/300480  CE: 3.1629  
[05/30 07:55:46] Re-training INFO: iter:  9375/300480  CE: 3.2850  
[05/30 07:57:11] Re-training INFO: iter:  9500/300480  CE: 3.2442  
[05/30 07:58:38] Re-training INFO: iter:  9625/300480  CE: 3.2021  
[05/30 08:00:04] Re-training INFO: iter:  9750/300480  CE: 3.0860  
[05/30 08:01:29] Re-training INFO: iter:  9875/300480  CE: 3.3467  
[05/30 08:02:53] Re-training INFO: iter: 10000/300480  CE: 3.1474  
[05/30 08:03:02] Re-training INFO: --> epoch:   8/240  avg CE: 3.2716  lr: 0.4986304738420683
[05/30 08:04:38] Re-training INFO: iter: 10125/300480  CE: 3.0193  
[05/30 08:06:04] Re-training INFO: iter: 10250/300480  CE: 3.0174  
[05/30 08:07:31] Re-training INFO: iter: 10375/300480  CE: 2.9413  
[05/30 08:08:56] Re-training INFO: iter: 10500/300480  CE: 3.1191  
[05/30 08:10:20] Re-training INFO: iter: 10625/300480  CE: 3.2754  
[05/30 08:11:47] Re-training INFO: iter: 10750/300480  CE: 3.1899  
[05/30 08:13:11] Re-training INFO: iter: 10875/300480  CE: 3.1888  
[05/30 08:14:35] Re-training INFO: iter: 11000/300480  CE: 3.2395  
[05/30 08:15:59] Re-training INFO: iter: 11125/300480  CE: 3.2601  
[05/30 08:17:23] Re-training INFO: iter: 11250/300480  CE: 3.1540  
[05/30 08:17:33] Re-training INFO: --> epoch:   9/240  avg CE: 3.2444  lr: 0.4982671142387316
[05/30 08:19:04] Re-training INFO: iter: 11375/300480  CE: 3.1091  
[05/30 08:20:30] Re-training INFO: iter: 11500/300480  CE: 3.0282  
[05/30 08:21:57] Re-training INFO: iter: 11625/300480  CE: 3.2499  
[05/30 08:23:24] Re-training INFO: iter: 11750/300480  CE: 2.9651  
[05/30 08:24:49] Re-training INFO: iter: 11875/300480  CE: 3.2315  
[05/30 08:26:14] Re-training INFO: iter: 12000/300480  CE: 3.1414  
[05/30 08:27:39] Re-training INFO: iter: 12125/300480  CE: 3.2076  
[05/30 08:29:02] Re-training INFO: iter: 12250/300480  CE: 2.9989  
[05/30 08:30:26] Re-training INFO: iter: 12375/300480  CE: 3.1759  
[05/30 08:31:52] Re-training INFO: iter: 12500/300480  CE: 3.1287  
[05/30 08:32:03] Re-training INFO: --> epoch:  10/240  avg CE: 3.2053  lr: 0.4978612153434526
[05/30 08:33:36] Re-training INFO: iter: 12625/300480  CE: 3.0572  
[05/30 08:35:06] Re-training INFO: iter: 12750/300480  CE: 3.4508  
[05/30 08:36:33] Re-training INFO: iter: 12875/300480  CE: 3.1549  
[05/30 08:37:59] Re-training INFO: iter: 13000/300480  CE: 3.0208  
[05/30 08:39:24] Re-training INFO: iter: 13125/300480  CE: 3.3442  
[05/30 08:40:50] Re-training INFO: iter: 13250/300480  CE: 3.0873  
[05/30 08:42:17] Re-training INFO: iter: 13375/300480  CE: 2.9393  
[05/30 08:43:43] Re-training INFO: iter: 13500/300480  CE: 3.2957  
[05/30 08:45:09] Re-training INFO: iter: 13625/300480  CE: 3.2971  
[05/30 08:46:35] Re-training INFO: iter: 13750/300480  CE: 3.2409  
[05/30 08:46:48] Re-training INFO: --> epoch:  11/240  avg CE: 3.1761  lr: 0.4974128467049176
[05/30 08:48:16] Re-training INFO: iter: 13875/300480  CE: 3.2183  
[05/30 08:49:41] Re-training INFO: iter: 14000/300480  CE: 3.4295  
[05/30 08:51:07] Re-training INFO: iter: 14125/300480  CE: 3.2665  
[05/30 08:52:32] Re-training INFO: iter: 14250/300480  CE: 3.2086  
[05/30 08:53:57] Re-training INFO: iter: 14375/300480  CE: 3.2872  
[05/30 08:55:22] Re-training INFO: iter: 14500/300480  CE: 2.9693  
[05/30 08:56:45] Re-training INFO: iter: 14625/300480  CE: 2.9684  
[05/30 08:58:11] Re-training INFO: iter: 14750/300480  CE: 3.3489  
[05/30 08:59:35] Re-training INFO: iter: 14875/300480  CE: 3.1467  
[05/30 09:01:00] Re-training INFO: iter: 15000/300480  CE: 3.3102  
[05/30 09:01:15] Re-training INFO: --> epoch:  12/240  avg CE: 3.1542  lr: 0.49692208514878444
[05/30 09:02:44] Re-training INFO: iter: 15125/300480  CE: 3.1939  
[05/30 09:04:14] Re-training INFO: iter: 15250/300480  CE: 3.0556  
[05/30 09:05:42] Re-training INFO: iter: 15375/300480  CE: 3.0921  
[05/30 09:07:10] Re-training INFO: iter: 15500/300480  CE: 3.3718  
[05/30 09:08:36] Re-training INFO: iter: 15625/300480  CE: 3.0512  
[05/30 09:10:03] Re-training INFO: iter: 15750/300480  CE: 3.1317  
[05/30 09:11:30] Re-training INFO: iter: 15875/300480  CE: 3.0280  
[05/30 09:12:55] Re-training INFO: iter: 16000/300480  CE: 3.0025  
[05/30 09:14:22] Re-training INFO: iter: 16125/300480  CE: 3.3449  
[05/30 09:15:48] Re-training INFO: iter: 16250/300480  CE: 3.1595  
[05/30 09:16:04] Re-training INFO: --> epoch:  13/240  avg CE: 3.1364  lr: 0.49638901476451947
[05/30 09:17:33] Re-training INFO: iter: 16375/300480  CE: 3.3269  
[05/30 09:18:59] Re-training INFO: iter: 16500/300480  CE: 3.1592  
[05/30 09:20:27] Re-training INFO: iter: 16625/300480  CE: 3.0303  
[05/30 09:21:52] Re-training INFO: iter: 16750/300480  CE: 2.8938  
[05/30 09:23:17] Re-training INFO: iter: 16875/300480  CE: 3.1657  
[05/30 09:24:41] Re-training INFO: iter: 17000/300480  CE: 3.0727  
[05/30 09:26:05] Re-training INFO: iter: 17125/300480  CE: 3.3203  
[05/30 09:27:29] Re-training INFO: iter: 17250/300480  CE: 3.0084  
[05/30 09:28:54] Re-training INFO: iter: 17375/300480  CE: 3.3323  
[05/30 09:30:19] Re-training INFO: iter: 17500/300480  CE: 2.8944  
[05/30 09:30:35] Re-training INFO: --> epoch:  14/240  avg CE: 3.1171  lr: 0.4958137268909887
[05/30 09:32:05] Re-training INFO: iter: 17625/300480  CE: 2.7945  
[05/30 09:33:32] Re-training INFO: iter: 17750/300480  CE: 3.2843  
[05/30 09:35:00] Re-training INFO: iter: 17875/300480  CE: 3.1482  
[05/30 09:36:25] Re-training INFO: iter: 18000/300480  CE: 2.9896  
[05/30 09:37:51] Re-training INFO: iter: 18125/300480  CE: 3.2103  
[05/30 09:39:15] Re-training INFO: iter: 18250/300480  CE: 3.1509  
[05/30 09:40:40] Re-training INFO: iter: 18375/300480  CE: 3.1909  
[05/30 09:42:06] Re-training INFO: iter: 18500/300480  CE: 3.0403  
[05/30 09:43:30] Re-training INFO: iter: 18625/300480  CE: 3.0321  
[05/30 09:44:54] Re-training INFO: iter: 18750/300480  CE: 3.1786  
[05/30 09:45:13] Re-training INFO: --> epoch:  15/240  avg CE: 3.1042  lr: 0.4951963201008076
[05/30 09:46:39] Re-training INFO: iter: 18875/300480  CE: 3.0932  
[05/30 09:48:08] Re-training INFO: iter: 19000/300480  CE: 3.0719  
[05/30 09:49:37] Re-training INFO: iter: 19125/300480  CE: 3.3529  
[05/30 09:51:05] Re-training INFO: iter: 19250/300480  CE: 2.8274  
[05/30 09:52:34] Re-training INFO: iter: 19375/300480  CE: 2.9699  
[05/30 09:54:03] Re-training INFO: iter: 19500/300480  CE: 3.1351  
[05/30 09:55:30] Re-training INFO: iter: 19625/300480  CE: 2.7385  
[05/30 09:56:57] Re-training INFO: iter: 19750/300480  CE: 3.2278  
[05/30 09:58:22] Re-training INFO: iter: 19875/300480  CE: 2.9545  
[05/30 09:59:50] Re-training INFO: iter: 20000/300480  CE: 2.8178  
[05/30 10:00:10] Re-training INFO: --> epoch:  16/240  avg CE: 3.0996  lr: 0.4945369001834514
[05/30 10:01:35] Re-training INFO: iter: 20125/300480  CE: 3.2728  
[05/30 10:03:04] Re-training INFO: iter: 20250/300480  CE: 3.1943  
[05/30 10:04:32] Re-training INFO: iter: 20375/300480  CE: 3.1635  
[05/30 10:06:02] Re-training INFO: iter: 20500/300480  CE: 3.1470  
[05/30 10:07:31] Re-training INFO: iter: 20625/300480  CE: 3.1795  
[05/30 10:08:59] Re-training INFO: iter: 20750/300480  CE: 3.3768  
[05/30 10:10:28] Re-training INFO: iter: 20875/300480  CE: 3.0273  
[05/30 10:11:56] Re-training INFO: iter: 21000/300480  CE: 3.1987  
[05/30 10:13:26] Re-training INFO: iter: 21125/300480  CE: 2.9060  
[05/30 10:14:54] Re-training INFO: iter: 21250/300480  CE: 3.2141  
[05/30 10:15:16] Re-training INFO: --> epoch:  17/240  avg CE: 3.0865  lr: 0.49383558012712814
[05/30 10:16:40] Re-training INFO: iter: 21375/300480  CE: 3.2055  
[05/30 10:18:08] Re-training INFO: iter: 21500/300480  CE: 2.8947  
[05/30 10:19:35] Re-training INFO: iter: 21625/300480  CE: 3.2128  
[05/30 10:21:03] Re-training INFO: iter: 21750/300480  CE: 3.1994  
[05/30 10:22:29] Re-training INFO: iter: 21875/300480  CE: 3.1322  
[05/30 10:23:57] Re-training INFO: iter: 22000/300480  CE: 2.9185  
[05/30 10:25:22] Re-training INFO: iter: 22125/300480  CE: 3.0872  
[05/30 10:26:48] Re-training INFO: iter: 22250/300480  CE: 3.0070  
[05/30 10:28:14] Re-training INFO: iter: 22375/300480  CE: 3.2620  
[05/30 10:29:40] Re-training INFO: iter: 22500/300480  CE: 3.1000  
[05/30 10:30:03] Re-training INFO: --> epoch:  18/240  avg CE: 3.0746  lr: 0.49309248009941914
[05/30 10:31:25] Re-training INFO: iter: 22625/300480  CE: 3.1978  
[05/30 10:32:52] Re-training INFO: iter: 22750/300480  CE: 3.2715  
[05/30 10:34:20] Re-training INFO: iter: 22875/300480  CE: 2.9982  
[05/30 10:35:46] Re-training INFO: iter: 23000/300480  CE: 3.2161  
[05/30 10:37:12] Re-training INFO: iter: 23125/300480  CE: 3.1897  
[05/30 10:38:38] Re-training INFO: iter: 23250/300480  CE: 3.0950  
[05/30 10:40:02] Re-training INFO: iter: 23375/300480  CE: 3.1912  
[05/30 10:41:26] Re-training INFO: iter: 23500/300480  CE: 3.2809  
[05/30 10:42:50] Re-training INFO: iter: 23625/300480  CE: 3.0049  
[05/30 10:44:14] Re-training INFO: iter: 23750/300480  CE: 3.1586  
[05/30 10:44:38] Re-training INFO: --> epoch:  19/240  avg CE: 3.0596  lr: 0.4923077274266886
[05/30 10:45:57] Re-training INFO: iter: 23875/300480  CE: 3.3702  
[05/30 10:47:25] Re-training INFO: iter: 24000/300480  CE: 2.6562  
[05/30 10:48:52] Re-training INFO: iter: 24125/300480  CE: 3.0452  
[05/30 10:50:19] Re-training INFO: iter: 24250/300480  CE: 2.8778  
[05/30 10:51:44] Re-training INFO: iter: 24375/300480  CE: 2.9979  
[05/30 10:53:09] Re-training INFO: iter: 24500/300480  CE: 3.1975  
[05/30 10:54:36] Re-training INFO: iter: 24625/300480  CE: 3.0288  
[05/30 10:56:01] Re-training INFO: iter: 24750/300480  CE: 3.0331  
[05/30 10:57:26] Re-training INFO: iter: 24875/300480  CE: 3.2568  
[05/30 10:58:50] Re-training INFO: iter: 25000/300480  CE: 2.9701  
[05/30 10:59:15] Re-training INFO: --> epoch:  20/240  avg CE: 3.0492  lr: 0.49148145657226705
[05/30 10:59:48] Re-training INFO: # of Test Samples: 50000.0
[05/30 10:59:48] Re-training INFO: Top-1/-5 acc: 53.54 / 78.76
[05/30 10:59:48] Re-training INFO: Top-1/-5 acc: 46.46 / 21.24
[05/30 10:59:48] Re-training INFO: 

[05/30 11:01:05] Re-training INFO: iter: 25125/300480  CE: 3.0147  
[05/30 11:02:33] Re-training INFO: iter: 25250/300480  CE: 3.1149  
[05/30 11:04:00] Re-training INFO: iter: 25375/300480  CE: 2.9062  
[05/30 11:05:27] Re-training INFO: iter: 25500/300480  CE: 3.2191  
[05/30 11:06:52] Re-training INFO: iter: 25625/300480  CE: 2.7803  
[05/30 11:08:17] Re-training INFO: iter: 25750/300480  CE: 2.9435  
[05/30 11:09:42] Re-training INFO: iter: 25875/300480  CE: 3.1257  
[05/30 11:11:07] Re-training INFO: iter: 26000/300480  CE: 3.3697  
[05/30 11:12:31] Re-training INFO: iter: 26125/300480  CE: 3.2000  
[05/30 11:13:56] Re-training INFO: iter: 26250/300480  CE: 2.9874  
[05/30 11:14:22] Re-training INFO: --> epoch:  21/240  avg CE: 3.0475  lr: 0.4906138091134118
[05/30 11:15:36] Re-training INFO: iter: 26375/300480  CE: 2.9117  
[05/30 11:17:00] Re-training INFO: iter: 26500/300480  CE: 3.2413  
[05/30 11:18:24] Re-training INFO: iter: 26625/300480  CE: 2.8173  
[05/30 11:19:48] Re-training INFO: iter: 26750/300480  CE: 2.9505  
[05/30 11:21:12] Re-training INFO: iter: 26875/300480  CE: 3.4209  
[05/30 11:22:36] Re-training INFO: iter: 27000/300480  CE: 3.2205  
[05/30 11:24:01] Re-training INFO: iter: 27125/300480  CE: 2.9820  
[05/30 11:25:23] Re-training INFO: iter: 27250/300480  CE: 2.8347  
[05/30 11:26:47] Re-training INFO: iter: 27375/300480  CE: 2.9085  
[05/30 11:28:11] Re-training INFO: iter: 27500/300480  CE: 2.9307  
[05/30 11:28:39] Re-training INFO: --> epoch:  22/240  avg CE: 3.0329  lr: 0.48970493371704826
[05/30 11:29:51] Re-training INFO: iter: 27625/300480  CE: 2.9023  
[05/30 11:31:16] Re-training INFO: iter: 27750/300480  CE: 3.1517  
[05/30 11:32:40] Re-training INFO: iter: 27875/300480  CE: 3.1272  
[05/30 11:34:04] Re-training INFO: iter: 28000/300480  CE: 2.9509  
[05/30 11:35:28] Re-training INFO: iter: 28125/300480  CE: 2.8864  
[05/30 11:36:53] Re-training INFO: iter: 28250/300480  CE: 2.9527  
[05/30 11:38:16] Re-training INFO: iter: 28375/300480  CE: 3.2461  
[05/30 11:39:39] Re-training INFO: iter: 28500/300480  CE: 3.1831  
[05/30 11:41:03] Re-training INFO: iter: 28625/300480  CE: 3.0449  
[05/30 11:42:27] Re-training INFO: iter: 28750/300480  CE: 2.9928  
[05/30 11:42:57] Re-training INFO: --> epoch:  23/240  avg CE: 3.0238  lr: 0.4887549861142967
[05/30 11:44:06] Re-training INFO: iter: 28875/300480  CE: 3.0731  
[05/30 11:45:29] Re-training INFO: iter: 29000/300480  CE: 3.0093  
[05/30 11:46:54] Re-training INFO: iter: 29125/300480  CE: 2.9591  
[05/30 11:48:17] Re-training INFO: iter: 29250/300480  CE: 2.8976  
[05/30 11:49:41] Re-training INFO: iter: 29375/300480  CE: 3.0715  
[05/30 11:51:04] Re-training INFO: iter: 29500/300480  CE: 2.9085  
[05/30 11:52:28] Re-training INFO: iter: 29625/300480  CE: 3.1072  
[05/30 11:53:52] Re-training INFO: iter: 29750/300480  CE: 3.0451  
[05/30 11:55:16] Re-training INFO: iter: 29875/300480  CE: 2.6372  
[05/30 11:56:38] Re-training INFO: iter: 30000/300480  CE: 3.0413  
[05/30 11:57:09] Re-training INFO: --> epoch:  24/240  avg CE: 3.0147  lr: 0.4877641290737884
[05/30 11:58:17] Re-training INFO: iter: 30125/300480  CE: 3.1953  
[05/30 11:59:41] Re-training INFO: iter: 30250/300480  CE: 2.8162  
[05/30 12:01:05] Re-training INFO: iter: 30375/300480  CE: 2.9467  
[05/30 12:02:29] Re-training INFO: iter: 30500/300480  CE: 3.1242  
[05/30 12:03:54] Re-training INFO: iter: 30625/300480  CE: 3.0656  
[05/30 12:05:17] Re-training INFO: iter: 30750/300480  CE: 3.3371  
[05/30 12:06:40] Re-training INFO: iter: 30875/300480  CE: 3.1133  
[05/30 12:08:05] Re-training INFO: iter: 31000/300480  CE: 3.3552  
[05/30 12:09:29] Re-training INFO: iter: 31125/300480  CE: 2.9821  
[05/30 12:10:54] Re-training INFO: iter: 31250/300480  CE: 3.0269  
[05/30 12:11:25] Re-training INFO: --> epoch:  25/240  avg CE: 3.0163  lr: 0.48673253237377645
[05/30 12:12:32] Re-training INFO: iter: 31375/300480  CE: 3.1787  
[05/30 12:13:55] Re-training INFO: iter: 31500/300480  CE: 3.1854  
[05/30 12:15:18] Re-training INFO: iter: 31625/300480  CE: 3.0970  
[05/30 12:16:42] Re-training INFO: iter: 31750/300480  CE: 3.0664  
[05/30 12:18:07] Re-training INFO: iter: 31875/300480  CE: 3.0030  
[05/30 12:19:30] Re-training INFO: iter: 32000/300480  CE: 2.9894  
[05/30 12:20:53] Re-training INFO: iter: 32125/300480  CE: 3.1470  
[05/30 12:22:17] Re-training INFO: iter: 32250/300480  CE: 2.9661  
[05/30 12:23:40] Re-training INFO: iter: 32375/300480  CE: 2.8141  
[05/30 12:25:04] Re-training INFO: iter: 32500/300480  CE: 2.7361  
[05/30 12:25:36] Re-training INFO: --> epoch:  26/240  avg CE: 3.0054  lr: 0.48566037277304464
[05/30 12:26:42] Re-training INFO: iter: 32625/300480  CE: 3.1093  
[05/30 12:28:05] Re-training INFO: iter: 32750/300480  CE: 2.9188  
[05/30 12:29:29] Re-training INFO: iter: 32875/300480  CE: 2.9754  
[05/30 12:30:52] Re-training INFO: iter: 33000/300480  CE: 2.8003  
[05/30 12:32:15] Re-training INFO: iter: 33125/300480  CE: 2.9549  
[05/30 12:33:39] Re-training INFO: iter: 33250/300480  CE: 3.1575  
[05/30 12:35:04] Re-training INFO: iter: 33375/300480  CE: 3.1314  
[05/30 12:36:27] Re-training INFO: iter: 33500/300480  CE: 2.8379  
[05/30 12:37:52] Re-training INFO: iter: 33625/300480  CE: 2.6880  
[05/30 12:39:14] Re-training INFO: iter: 33750/300480  CE: 2.9214  
[05/30 12:39:48] Re-training INFO: --> epoch:  27/240  avg CE: 2.9970  lr: 0.48454783398062107
[05/30 12:40:53] Re-training INFO: iter: 33875/300480  CE: 2.9659  
[05/30 12:42:17] Re-training INFO: iter: 34000/300480  CE: 3.1152  
[05/30 12:43:41] Re-training INFO: iter: 34125/300480  CE: 3.0397  
[05/30 12:45:05] Re-training INFO: iter: 34250/300480  CE: 3.1613  
[05/30 12:46:30] Re-training INFO: iter: 34375/300480  CE: 2.8132  
[05/30 12:47:54] Re-training INFO: iter: 34500/300480  CE: 2.7338  
[05/30 12:49:19] Re-training INFO: iter: 34625/300480  CE: 3.0765  
[05/30 12:50:43] Re-training INFO: iter: 34750/300480  CE: 3.1351  
[05/30 12:52:07] Re-training INFO: iter: 34875/300480  CE: 2.8619  
[05/30 12:53:31] Re-training INFO: iter: 35000/300480  CE: 2.7579  
[05/30 12:54:07] Re-training INFO: --> epoch:  28/240  avg CE: 2.9926  lr: 0.4833951066243004
[05/30 12:55:10] Re-training INFO: iter: 35125/300480  CE: 3.0250  
[05/30 12:56:34] Re-training INFO: iter: 35250/300480  CE: 2.9121  
[05/30 12:57:57] Re-training INFO: iter: 35375/300480  CE: 2.9774  
[05/30 12:59:21] Re-training INFO: iter: 35500/300480  CE: 2.8626  
[05/30 13:00:46] Re-training INFO: iter: 35625/300480  CE: 2.8966  
[05/30 13:02:10] Re-training INFO: iter: 35750/300480  CE: 3.0211  
[05/30 13:03:33] Re-training INFO: iter: 35875/300480  CE: 2.9739  
[05/30 13:04:57] Re-training INFO: iter: 36000/300480  CE: 2.9217  
[05/30 13:06:20] Re-training INFO: iter: 36125/300480  CE: 2.8857  
[05/30 13:07:44] Re-training INFO: iter: 36250/300480  CE: 2.8322  
[05/30 13:08:22] Re-training INFO: --> epoch:  29/240  avg CE: 2.9926  lr: 0.48220238821798106
[05/30 13:09:24] Re-training INFO: iter: 36375/300480  CE: 2.8249  
[05/30 13:10:47] Re-training INFO: iter: 36500/300480  CE: 3.0992  
[05/30 13:12:12] Re-training INFO: iter: 36625/300480  CE: 2.9142  
[05/30 13:13:36] Re-training INFO: iter: 36750/300480  CE: 3.1809  
[05/30 13:15:00] Re-training INFO: iter: 36875/300480  CE: 2.8902  
[05/30 13:16:23] Re-training INFO: iter: 37000/300480  CE: 3.0535  
[05/30 13:17:47] Re-training INFO: iter: 37125/300480  CE: 2.9590  
[05/30 13:19:10] Re-training INFO: iter: 37250/300480  CE: 3.3236  
[05/30 13:20:33] Re-training INFO: iter: 37375/300480  CE: 2.9491  
[05/30 13:21:58] Re-training INFO: iter: 37500/300480  CE: 3.1083  
[05/30 13:22:36] Re-training INFO: --> epoch:  30/240  avg CE: 2.9845  lr: 0.4809698831278217
[05/30 13:23:35] Re-training INFO: iter: 37625/300480  CE: 2.8418  
[05/30 13:24:58] Re-training INFO: iter: 37750/300480  CE: 3.2198  
[05/30 13:26:23] Re-training INFO: iter: 37875/300480  CE: 3.1789  
[05/30 13:27:45] Re-training INFO: iter: 38000/300480  CE: 2.7785  
[05/30 13:29:09] Re-training INFO: iter: 38125/300480  CE: 2.7890  
[05/30 13:30:32] Re-training INFO: iter: 38250/300480  CE: 2.8139  
[05/30 13:31:56] Re-training INFO: iter: 38375/300480  CE: 2.9040  
[05/30 13:33:19] Re-training INFO: iter: 38500/300480  CE: 2.7766  
[05/30 13:34:43] Re-training INFO: iter: 38625/300480  CE: 3.1917  
[05/30 13:36:06] Re-training INFO: iter: 38750/300480  CE: 3.2486  
[05/30 13:36:45] Re-training INFO: --> epoch:  31/240  avg CE: 2.9766  lr: 0.4796978025372246
[05/30 13:37:45] Re-training INFO: iter: 38875/300480  CE: 2.8085  
[05/30 13:39:09] Re-training INFO: iter: 39000/300480  CE: 3.1497  
[05/30 13:40:34] Re-training INFO: iter: 39125/300480  CE: 2.7881  
[05/30 13:41:58] Re-training INFO: iter: 39250/300480  CE: 2.9302  
[05/30 13:43:21] Re-training INFO: iter: 39375/300480  CE: 2.8955  
[05/30 13:44:45] Re-training INFO: iter: 39500/300480  CE: 3.0040  
[05/30 13:46:09] Re-training INFO: iter: 39625/300480  CE: 3.0493  
[05/30 13:47:32] Re-training INFO: iter: 39750/300480  CE: 2.8769  
[05/30 13:48:55] Re-training INFO: iter: 39875/300480  CE: 2.9634  
[05/30 13:50:20] Re-training INFO: iter: 40000/300480  CE: 2.8534  
[05/30 13:51:01] Re-training INFO: --> epoch:  32/240  avg CE: 2.9938  lr: 0.4783863644106502
[05/30 13:51:58] Re-training INFO: iter: 40125/300480  CE: 3.0251  
[05/30 13:53:21] Re-training INFO: iter: 40250/300480  CE: 2.9393  
[05/30 13:54:45] Re-training INFO: iter: 40375/300480  CE: 3.2889  
[05/30 13:56:08] Re-training INFO: iter: 40500/300480  CE: 3.1340  
[05/30 13:57:32] Re-training INFO: iter: 40625/300480  CE: 2.9751  
[05/30 13:58:56] Re-training INFO: iter: 40750/300480  CE: 2.9493  
[05/30 14:00:19] Re-training INFO: iter: 40875/300480  CE: 3.2495  
[05/30 14:01:43] Re-training INFO: iter: 41000/300480  CE: 3.0105  
[05/30 14:03:08] Re-training INFO: iter: 41125/300480  CE: 3.0147  
[05/30 14:04:33] Re-training INFO: iter: 41250/300480  CE: 3.3028  
[05/30 14:05:14] Re-training INFO: --> epoch:  33/240  avg CE: 2.9832  lr: 0.47703579345627034
[05/30 14:06:10] Re-training INFO: iter: 41375/300480  CE: 2.9667  
[05/30 14:07:34] Re-training INFO: iter: 41500/300480  CE: 2.9854  
[05/30 14:08:59] Re-training INFO: iter: 41625/300480  CE: 2.9747  
[05/30 14:10:22] Re-training INFO: iter: 41750/300480  CE: 3.2246  
[05/30 14:11:47] Re-training INFO: iter: 41875/300480  CE: 3.1421  
[05/30 14:13:11] Re-training INFO: iter: 42000/300480  CE: 3.0115  
[05/30 14:14:36] Re-training INFO: iter: 42125/300480  CE: 2.9612  
[05/30 14:15:59] Re-training INFO: iter: 42250/300480  CE: 2.7850  
[05/30 14:17:25] Re-training INFO: iter: 42375/300480  CE: 3.0160  
[05/30 14:18:49] Re-training INFO: iter: 42500/300480  CE: 2.8840  
[05/30 14:19:32] Re-training INFO: --> epoch:  34/240  avg CE: 2.9604  lr: 0.4756463210874652
[05/30 14:20:26] Re-training INFO: iter: 42625/300480  CE: 2.8943  
[05/30 14:21:52] Re-training INFO: iter: 42750/300480  CE: 2.9423  
[05/30 14:23:15] Re-training INFO: iter: 42875/300480  CE: 3.0190  
[05/30 14:24:40] Re-training INFO: iter: 43000/300480  CE: 3.0642  
[05/30 14:26:04] Re-training INFO: iter: 43125/300480  CE: 2.9959  
[05/30 14:27:28] Re-training INFO: iter: 43250/300480  CE: 2.8473  
[05/30 14:28:51] Re-training INFO: iter: 43375/300480  CE: 2.8355  
[05/30 14:30:15] Re-training INFO: iter: 43500/300480  CE: 2.6676  
[05/30 14:31:39] Re-training INFO: iter: 43625/300480  CE: 2.7889  
[05/30 14:33:02] Re-training INFO: iter: 43750/300480  CE: 2.7007  
[05/30 14:33:47] Re-training INFO: --> epoch:  35/240  avg CE: 2.9695  lr: 0.47421818538317206
[05/30 14:34:40] Re-training INFO: iter: 43875/300480  CE: 3.0270  
[05/30 14:36:03] Re-training INFO: iter: 44000/300480  CE: 2.9820  
[05/30 14:37:28] Re-training INFO: iter: 44125/300480  CE: 3.2328  
[05/30 14:38:51] Re-training INFO: iter: 44250/300480  CE: 2.8461  
[05/30 14:40:15] Re-training INFO: iter: 44375/300480  CE: 3.2310  
[05/30 14:41:39] Re-training INFO: iter: 44500/300480  CE: 3.1383  
[05/30 14:43:03] Re-training INFO: iter: 44625/300480  CE: 2.9978  
[05/30 14:44:28] Re-training INFO: iter: 44750/300480  CE: 2.8978  
[05/30 14:45:50] Re-training INFO: iter: 44875/300480  CE: 2.7534  
[05/30 14:47:13] Re-training INFO: iter: 45000/300480  CE: 3.0296  
[05/30 14:48:00] Re-training INFO: --> epoch:  36/240  avg CE: 2.9573  lr: 0.47275163104709195
[05/30 14:48:52] Re-training INFO: iter: 45125/300480  CE: 3.0883  
[05/30 14:50:17] Re-training INFO: iter: 45250/300480  CE: 3.1666  
[05/30 14:51:41] Re-training INFO: iter: 45375/300480  CE: 2.9754  
[05/30 14:53:06] Re-training INFO: iter: 45500/300480  CE: 3.1101  
[05/30 14:54:30] Re-training INFO: iter: 45625/300480  CE: 3.2011  
[05/30 14:55:55] Re-training INFO: iter: 45750/300480  CE: 3.2018  
[05/30 14:57:18] Re-training INFO: iter: 45875/300480  CE: 3.0136  
[05/30 14:58:43] Re-training INFO: iter: 46000/300480  CE: 2.8869  
[05/30 15:00:07] Re-training INFO: iter: 46125/300480  CE: 2.7504  
[05/30 15:01:31] Re-training INFO: iter: 46250/300480  CE: 2.6997  
[05/30 15:02:19] Re-training INFO: --> epoch:  37/240  avg CE: 2.9595  lr: 0.47124690936576047
[05/30 15:03:09] Re-training INFO: iter: 46375/300480  CE: 2.9689  
[05/30 15:04:32] Re-training INFO: iter: 46500/300480  CE: 2.9383  
[05/30 15:05:57] Re-training INFO: iter: 46625/300480  CE: 2.7324  
[05/30 15:07:21] Re-training INFO: iter: 46750/300480  CE: 2.7746  
[05/30 15:08:44] Re-training INFO: iter: 46875/300480  CE: 2.9713  
[05/30 15:10:08] Re-training INFO: iter: 47000/300480  CE: 2.8527  
[05/30 15:11:31] Re-training INFO: iter: 47125/300480  CE: 2.7535  
[05/30 15:12:55] Re-training INFO: iter: 47250/300480  CE: 3.1246  
[05/30 15:14:19] Re-training INFO: iter: 47375/300480  CE: 2.8251  
[05/30 15:15:44] Re-training INFO: iter: 47500/300480  CE: 3.0321  
[05/30 15:16:33] Re-training INFO: --> epoch:  38/240  avg CE: 2.9623  lr: 0.4697042781654913
[05/30 15:17:22] Re-training INFO: iter: 47625/300480  CE: 2.8887  
[05/30 15:18:47] Re-training INFO: iter: 47750/300480  CE: 2.9123  
[05/30 15:20:10] Re-training INFO: iter: 47875/300480  CE: 2.8370  
[05/30 15:21:34] Re-training INFO: iter: 48000/300480  CE: 3.0223  
[05/30 15:22:57] Re-training INFO: iter: 48125/300480  CE: 3.2413  
[05/30 15:24:21] Re-training INFO: iter: 48250/300480  CE: 3.0199  
[05/30 15:25:47] Re-training INFO: iter: 48375/300480  CE: 3.1654  
[05/30 15:27:11] Re-training INFO: iter: 48500/300480  CE: 2.7707  
[05/30 15:28:34] Re-training INFO: iter: 48625/300480  CE: 2.9129  
[05/30 15:29:58] Re-training INFO: iter: 48750/300480  CE: 3.0652  
[05/30 15:30:48] Re-training INFO: --> epoch:  39/240  avg CE: 2.9519  lr: 0.4681240017681993
[05/30 15:31:35] Re-training INFO: iter: 48875/300480  CE: 3.0926  
[05/30 15:32:59] Re-training INFO: iter: 49000/300480  CE: 2.9725  
[05/30 15:34:25] Re-training INFO: iter: 49125/300480  CE: 2.7290  
[05/30 15:35:48] Re-training INFO: iter: 49250/300480  CE: 2.5840  
[05/30 15:37:12] Re-training INFO: iter: 49375/300480  CE: 2.9797  
[05/30 15:38:35] Re-training INFO: iter: 49500/300480  CE: 2.8460  
[05/30 15:39:57] Re-training INFO: iter: 49625/300480  CE: 2.7206  
[05/30 15:41:23] Re-training INFO: iter: 49750/300480  CE: 2.6370  
[05/30 15:42:46] Re-training INFO: iter: 49875/300480  CE: 2.7492  
[05/30 15:44:08] Re-training INFO: iter: 50000/300480  CE: 2.8315  
[05/30 15:45:00] Re-training INFO: --> epoch:  40/240  avg CE: 2.9525  lr: 0.4665063509461097
[05/30 15:45:32] Re-training INFO: # of Test Samples: 50000.0
[05/30 15:45:32] Re-training INFO: Top-1/-5 acc: 53.36 / 78.23
[05/30 15:45:32] Re-training INFO: Top-1/-5 acc: 46.64 / 21.77
[05/30 15:45:32] Re-training INFO: 

[05/30 15:46:19] Re-training INFO: iter: 50125/300480  CE: 3.1942  
[05/30 15:47:43] Re-training INFO: iter: 50250/300480  CE: 2.7423  
[05/30 15:49:06] Re-training INFO: iter: 50375/300480  CE: 3.2743  
[05/30 15:50:29] Re-training INFO: iter: 50500/300480  CE: 2.6225  
[05/30 15:51:53] Re-training INFO: iter: 50625/300480  CE: 2.6681  
[05/30 15:53:16] Re-training INFO: iter: 50750/300480  CE: 2.8673  
[05/30 15:54:41] Re-training INFO: iter: 50875/300480  CE: 2.9996  
[05/30 15:56:04] Re-training INFO: iter: 51000/300480  CE: 2.9026  
[05/30 15:57:27] Re-training INFO: iter: 51125/300480  CE: 2.6759  
[05/30 15:58:52] Re-training INFO: iter: 51250/300480  CE: 3.0361  
[05/30 15:59:44] Re-training INFO: --> epoch:  41/240  avg CE: 2.9438  lr: 0.4648516028753632
[05/30 16:00:29] Re-training INFO: iter: 51375/300480  CE: 3.1592  
[05/30 16:01:53] Re-training INFO: iter: 51500/300480  CE: 2.9893  
[05/30 16:03:16] Re-training INFO: iter: 51625/300480  CE: 2.7238  
[05/30 16:04:39] Re-training INFO: iter: 51750/300480  CE: 2.8648  
[05/30 16:06:05] Re-training INFO: iter: 51875/300480  CE: 3.0274  
[05/30 16:07:28] Re-training INFO: iter: 52000/300480  CE: 2.8729  
[05/30 16:08:52] Re-training INFO: iter: 52125/300480  CE: 3.0169  
[05/30 16:10:15] Re-training INFO: iter: 52250/300480  CE: 3.1726  
[05/30 16:11:39] Re-training INFO: iter: 52375/300480  CE: 2.9940  
[05/30 16:13:03] Re-training INFO: iter: 52500/300480  CE: 2.7303  
[05/30 16:13:58] Re-training INFO: --> epoch:  42/240  avg CE: 2.9379  lr: 0.46316004108852304
[05/30 16:14:42] Re-training INFO: iter: 52625/300480  CE: 3.0473  
[05/30 16:16:05] Re-training INFO: iter: 52750/300480  CE: 2.7588  
[05/30 16:17:29] Re-training INFO: iter: 52875/300480  CE: 2.8214  
[05/30 16:18:52] Re-training INFO: iter: 53000/300480  CE: 2.7921  
[05/30 16:20:16] Re-training INFO: iter: 53125/300480  CE: 3.0843  
[05/30 16:21:39] Re-training INFO: iter: 53250/300480  CE: 2.5878  
[05/30 16:23:03] Re-training INFO: iter: 53375/300480  CE: 2.9108  
[05/30 16:24:26] Re-training INFO: iter: 53500/300480  CE: 3.0528  
[05/30 16:25:50] Re-training INFO: iter: 53625/300480  CE: 2.8167  
[05/30 16:27:14] Re-training INFO: iter: 53750/300480  CE: 3.1817  
[05/30 16:28:09] Re-training INFO: --> epoch:  43/240  avg CE: 2.9353  lr: 0.46143195542599336
[05/30 16:28:51] Re-training INFO: iter: 53875/300480  CE: 2.8209  
[05/30 16:30:15] Re-training INFO: iter: 54000/300480  CE: 2.8075  
[05/30 16:31:38] Re-training INFO: iter: 54125/300480  CE: 3.0228  
[05/30 16:33:01] Re-training INFO: iter: 54250/300480  CE: 3.1904  
[05/30 16:34:27] Re-training INFO: iter: 54375/300480  CE: 2.8251  
[05/30 16:35:50] Re-training INFO: iter: 54500/300480  CE: 3.2920  
[05/30 16:37:13] Re-training INFO: iter: 54625/300480  CE: 3.2475  
[05/30 16:38:37] Re-training INFO: iter: 54750/300480  CE: 2.8504  
[05/30 16:40:02] Re-training INFO: iter: 54875/300480  CE: 3.1169  
[05/30 16:41:25] Re-training INFO: iter: 55000/300480  CE: 2.9948  
[05/30 16:42:22] Re-training INFO: --> epoch:  44/240  avg CE: 2.9307  lr: 0.459667641986356
[05/30 16:43:03] Re-training INFO: iter: 55125/300480  CE: 3.0180  
[05/30 16:44:27] Re-training INFO: iter: 55250/300480  CE: 3.1128  
[05/30 16:45:50] Re-training INFO: iter: 55375/300480  CE: 2.9183  
[05/30 16:47:15] Re-training INFO: iter: 55500/300480  CE: 2.9952  
[05/30 16:48:38] Re-training INFO: iter: 55625/300480  CE: 2.9515  
[05/30 16:50:03] Re-training INFO: iter: 55750/300480  CE: 2.7617  
[05/30 16:51:27] Re-training INFO: iter: 55875/300480  CE: 3.0337  
[05/30 16:52:51] Re-training INFO: iter: 56000/300480  CE: 2.9365  
[05/30 16:54:14] Re-training INFO: iter: 56125/300480  CE: 2.8936  
[05/30 16:55:38] Re-training INFO: iter: 56250/300480  CE: 2.9071  
[05/30 16:56:37] Re-training INFO: --> epoch:  45/240  avg CE: 2.9280  lr: 0.45786740307563634
[05/30 16:57:16] Re-training INFO: iter: 56375/300480  CE: 2.8496  
[05/30 16:58:40] Re-training INFO: iter: 56500/300480  CE: 2.8100  
[05/30 17:00:04] Re-training INFO: iter: 56625/300480  CE: 3.0377  
[05/30 17:01:28] Re-training INFO: iter: 56750/300480  CE: 3.2147  
[05/30 17:02:52] Re-training INFO: iter: 56875/300480  CE: 2.9376  
[05/30 17:04:16] Re-training INFO: iter: 57000/300480  CE: 2.9387  
[05/30 17:05:41] Re-training INFO: iter: 57125/300480  CE: 2.9374  
[05/30 17:07:05] Re-training INFO: iter: 57250/300480  CE: 3.1154  
[05/30 17:08:29] Re-training INFO: iter: 57375/300480  CE: 3.2093  
[05/30 17:09:53] Re-training INFO: iter: 57500/300480  CE: 2.9469  
[05/30 17:10:53] Re-training INFO: --> epoch:  46/240  avg CE: 2.9267  lr: 0.45603154715550387
[05/30 17:11:32] Re-training INFO: iter: 57625/300480  CE: 2.9131  
[05/30 17:12:56] Re-training INFO: iter: 57750/300480  CE: 2.9663  
[05/30 17:14:19] Re-training INFO: iter: 57875/300480  CE: 2.8682  
[05/30 17:15:43] Re-training INFO: iter: 58000/300480  CE: 3.0798  
[05/30 17:17:06] Re-training INFO: iter: 58125/300480  CE: 2.9648  
[05/30 17:18:29] Re-training INFO: iter: 58250/300480  CE: 2.8788  
[05/30 17:19:53] Re-training INFO: iter: 58375/300480  CE: 2.8421  
[05/30 17:21:17] Re-training INFO: iter: 58500/300480  CE: 2.9739  
[05/30 17:22:40] Re-training INFO: iter: 58625/300480  CE: 2.9994  
[05/30 17:24:04] Re-training INFO: iter: 58750/300480  CE: 3.0378  
[05/30 17:25:05] Re-training INFO: --> epoch:  47/240  avg CE: 2.9309  lr: 0.45416038879041976
[05/30 17:25:43] Re-training INFO: iter: 58875/300480  CE: 2.9697  
[05/30 17:27:08] Re-training INFO: iter: 59000/300480  CE: 2.7584  
[05/30 17:28:33] Re-training INFO: iter: 59125/300480  CE: 2.8965  
[05/30 17:29:57] Re-training INFO: iter: 59250/300480  CE: 2.7589  
[05/30 17:31:20] Re-training INFO: iter: 59375/300480  CE: 2.9745  
[05/30 17:32:45] Re-training INFO: iter: 59500/300480  CE: 2.9143  
[05/30 17:34:09] Re-training INFO: iter: 59625/300480  CE: 2.9747  
[05/30 17:35:33] Re-training INFO: iter: 59750/300480  CE: 2.7310  
[05/30 17:36:57] Re-training INFO: iter: 59875/300480  CE: 3.1037  
[05/30 17:38:22] Re-training INFO: iter: 60000/300480  CE: 2.9476  
[05/30 17:39:24] Re-training INFO: --> epoch:  48/240  avg CE: 2.9226  lr: 0.45225424859373686
[05/30 17:40:00] Re-training INFO: iter: 60125/300480  CE: 3.1620  
[05/30 17:41:26] Re-training INFO: iter: 60250/300480  CE: 2.9715  
[05/30 17:42:49] Re-training INFO: iter: 60375/300480  CE: 3.0493  
[05/30 17:44:13] Re-training INFO: iter: 60500/300480  CE: 2.9937  
[05/30 17:45:37] Re-training INFO: iter: 60625/300480  CE: 2.6412  
[05/30 17:47:00] Re-training INFO: iter: 60750/300480  CE: 3.0826  
[05/30 17:48:23] Re-training INFO: iter: 60875/300480  CE: 3.0842  
[05/30 17:49:46] Re-training INFO: iter: 61000/300480  CE: 2.8238  
[05/30 17:51:11] Re-training INFO: iter: 61125/300480  CE: 2.6184  
[05/30 17:52:35] Re-training INFO: iter: 61250/300480  CE: 3.0049  
[05/30 17:53:38] Re-training INFO: --> epoch:  49/240  avg CE: 2.9161  lr: 0.45031345317276517
[05/30 17:54:13] Re-training INFO: iter: 61375/300480  CE: 2.6639  
[05/30 17:55:36] Re-training INFO: iter: 61500/300480  CE: 2.8188  
[05/30 17:56:59] Re-training INFO: iter: 61625/300480  CE: 3.2275  
[05/30 17:58:24] Re-training INFO: iter: 61750/300480  CE: 2.5826  
[05/30 17:59:48] Re-training INFO: iter: 61875/300480  CE: 2.9682  
[05/30 18:01:12] Re-training INFO: iter: 62000/300480  CE: 2.9805  
[05/30 18:02:35] Re-training INFO: iter: 62125/300480  CE: 3.0307  
[05/30 18:03:59] Re-training INFO: iter: 62250/300480  CE: 2.7939  
[05/30 18:05:22] Re-training INFO: iter: 62375/300480  CE: 2.7926  
[05/30 18:06:46] Re-training INFO: iter: 62500/300480  CE: 3.1305  
[05/30 18:07:51] Re-training INFO: --> epoch:  50/240  avg CE: 2.9177  lr: 0.4483383350728088
[05/30 18:08:25] Re-training INFO: iter: 62625/300480  CE: 2.9728  
[05/30 18:09:48] Re-training INFO: iter: 62750/300480  CE: 2.8129  
[05/30 18:11:12] Re-training INFO: iter: 62875/300480  CE: 2.7978  
[05/30 18:12:35] Re-training INFO: iter: 63000/300480  CE: 2.4565  
[05/30 18:14:00] Re-training INFO: iter: 63125/300480  CE: 2.9965  
[05/30 18:15:24] Re-training INFO: iter: 63250/300480  CE: 2.8295  
[05/30 18:16:48] Re-training INFO: iter: 63375/300480  CE: 2.9716  
[05/30 18:18:14] Re-training INFO: iter: 63500/300480  CE: 3.0563  
[05/30 18:19:38] Re-training INFO: iter: 63625/300480  CE: 2.8059  
[05/30 18:21:02] Re-training INFO: iter: 63750/300480  CE: 2.9046  
[05/30 18:22:08] Re-training INFO: --> epoch:  51/240  avg CE: 2.9176  lr: 0.4463292327201862
[05/30 18:22:40] Re-training INFO: iter: 63875/300480  CE: 3.0156  
[05/30 18:24:05] Re-training INFO: iter: 64000/300480  CE: 2.6925  
[05/30 18:25:28] Re-training INFO: iter: 64125/300480  CE: 2.7266  
[05/30 18:26:53] Re-training INFO: iter: 64250/300480  CE: 2.6899  
[05/30 18:28:17] Re-training INFO: iter: 64375/300480  CE: 2.8835  
[05/30 18:29:40] Re-training INFO: iter: 64500/300480  CE: 3.0112  
[05/30 18:31:05] Re-training INFO: iter: 64625/300480  CE: 2.6744  
[05/30 18:32:30] Re-training INFO: iter: 64750/300480  CE: 2.9574  
[05/30 18:33:55] Re-training INFO: iter: 64875/300480  CE: 2.8775  
[05/30 18:35:18] Re-training INFO: iter: 65000/300480  CE: 2.8712  
[05/30 18:36:26] Re-training INFO: --> epoch:  52/240  avg CE: 2.9089  lr: 0.4442864903642427
[05/30 18:36:57] Re-training INFO: iter: 65125/300480  CE: 2.8365  
[05/30 18:38:23] Re-training INFO: iter: 65250/300480  CE: 3.2232  
[05/30 18:39:48] Re-training INFO: iter: 65375/300480  CE: 2.7750  
[05/30 18:41:11] Re-training INFO: iter: 65500/300480  CE: 2.8755  
[05/30 18:42:37] Re-training INFO: iter: 65625/300480  CE: 2.9216  
[05/30 18:44:01] Re-training INFO: iter: 65750/300480  CE: 2.9160  
[05/30 18:45:25] Re-training INFO: iter: 65875/300480  CE: 2.8533  
[05/30 18:46:48] Re-training INFO: iter: 66000/300480  CE: 2.8953  
[05/30 18:48:14] Re-training INFO: iter: 66125/300480  CE: 2.5933  
[05/30 18:49:38] Re-training INFO: iter: 66250/300480  CE: 2.8670  
[05/30 18:50:49] Re-training INFO: --> epoch:  53/240  avg CE: 2.9074  lr: 0.4422104580183649
[05/30 18:51:18] Re-training INFO: iter: 66375/300480  CE: 2.7250  
[05/30 18:52:41] Re-training INFO: iter: 66500/300480  CE: 3.0899  
[05/30 18:54:05] Re-training INFO: iter: 66625/300480  CE: 3.0423  
[05/30 18:55:28] Re-training INFO: iter: 66750/300480  CE: 2.8809  
[05/30 18:56:52] Re-training INFO: iter: 66875/300480  CE: 3.0407  
[05/30 18:58:15] Re-training INFO: iter: 67000/300480  CE: 2.8333  
[05/30 18:59:39] Re-training INFO: iter: 67125/300480  CE: 3.0117  
[05/30 19:01:03] Re-training INFO: iter: 67250/300480  CE: 2.9554  
[05/30 19:02:28] Re-training INFO: iter: 67375/300480  CE: 2.5761  
[05/30 19:03:52] Re-training INFO: iter: 67500/300480  CE: 2.9325  
[05/30 19:05:03] Re-training INFO: --> epoch:  54/240  avg CE: 2.9022  lr: 0.44010149140000776
[05/30 19:05:30] Re-training INFO: iter: 67625/300480  CE: 2.8104  
[05/30 19:06:54] Re-training INFO: iter: 67750/300480  CE: 2.7831  
[05/30 19:08:18] Re-training INFO: iter: 67875/300480  CE: 2.7886  
[05/30 19:09:41] Re-training INFO: iter: 68000/300480  CE: 2.7936  
[05/30 19:11:06] Re-training INFO: iter: 68125/300480  CE: 2.7403  
[05/30 19:12:30] Re-training INFO: iter: 68250/300480  CE: 2.7429  
[05/30 19:13:53] Re-training INFO: iter: 68375/300480  CE: 2.8627  
[05/30 19:15:17] Re-training INFO: iter: 68500/300480  CE: 2.9915  
[05/30 19:16:41] Re-training INFO: iter: 68625/300480  CE: 2.9342  
[05/30 19:18:06] Re-training INFO: iter: 68750/300480  CE: 3.0385  
[05/30 19:19:17] Re-training INFO: --> epoch:  55/240  avg CE: 2.8990  lr: 0.43795995186974435
[05/30 19:19:44] Re-training INFO: iter: 68875/300480  CE: 2.8917  
[05/30 19:21:08] Re-training INFO: iter: 69000/300480  CE: 2.8764  
[05/30 19:22:31] Re-training INFO: iter: 69125/300480  CE: 2.9162  
[05/30 19:23:57] Re-training INFO: iter: 69250/300480  CE: 3.0055  
[05/30 19:25:21] Re-training INFO: iter: 69375/300480  CE: 2.8304  
[05/30 19:26:45] Re-training INFO: iter: 69500/300480  CE: 2.7911  
[05/30 19:28:09] Re-training INFO: iter: 69625/300480  CE: 2.9800  
[05/30 19:29:34] Re-training INFO: iter: 69750/300480  CE: 3.0305  
[05/30 19:30:57] Re-training INFO: iter: 69875/300480  CE: 2.8774  
[05/30 19:32:22] Re-training INFO: iter: 70000/300480  CE: 2.8099  
[05/30 19:33:35] Re-training INFO: --> epoch:  56/240  avg CE: 2.8963  lr: 0.43578620636934856
[05/30 19:34:01] Re-training INFO: iter: 70125/300480  CE: 2.6731  
[05/30 19:35:26] Re-training INFO: iter: 70250/300480  CE: 2.9213  
[05/30 19:36:48] Re-training INFO: iter: 70375/300480  CE: 3.0893  
[05/30 19:38:12] Re-training INFO: iter: 70500/300480  CE: 3.1847  
[05/30 19:39:37] Re-training INFO: iter: 70625/300480  CE: 2.8743  
[05/30 19:41:02] Re-training INFO: iter: 70750/300480  CE: 3.0647  
[05/30 19:42:25] Re-training INFO: iter: 70875/300480  CE: 2.6937  
[05/30 19:43:49] Re-training INFO: iter: 71000/300480  CE: 2.9825  
[05/30 19:45:12] Re-training INFO: iter: 71125/300480  CE: 2.8378  
[05/30 19:46:37] Re-training INFO: iter: 71250/300480  CE: 2.9460  
[05/30 19:47:51] Re-training INFO: --> epoch:  57/240  avg CE: 2.9007  lr: 0.4335806273589214
[05/30 19:48:15] Re-training INFO: iter: 71375/300480  CE: 2.9142  
[05/30 19:49:40] Re-training INFO: iter: 71500/300480  CE: 2.7898  
[05/30 19:51:04] Re-training INFO: iter: 71625/300480  CE: 2.9665  
[05/30 19:52:28] Re-training INFO: iter: 71750/300480  CE: 2.6448  
[05/30 19:53:50] Re-training INFO: iter: 71875/300480  CE: 2.8903  
[05/30 19:55:15] Re-training INFO: iter: 72000/300480  CE: 2.7618  
[05/30 19:56:39] Re-training INFO: iter: 72125/300480  CE: 2.9528  
[05/30 19:58:03] Re-training INFO: iter: 72250/300480  CE: 3.0416  
[05/30 19:59:25] Re-training INFO: iter: 72375/300480  CE: 3.1124  
[05/30 20:00:49] Re-training INFO: iter: 72500/300480  CE: 3.0524  
[05/30 20:02:05] Re-training INFO: --> epoch:  58/240  avg CE: 2.8856  lr: 0.4313435927530719
[05/30 20:02:28] Re-training INFO: iter: 72625/300480  CE: 2.8732  
[05/30 20:03:51] Re-training INFO: iter: 72750/300480  CE: 2.9512  
[05/30 20:05:16] Re-training INFO: iter: 72875/300480  CE: 2.7050  
[05/30 20:06:39] Re-training INFO: iter: 73000/300480  CE: 2.9333  
[05/30 20:08:04] Re-training INFO: iter: 73125/300480  CE: 3.3296  
[05/30 20:09:28] Re-training INFO: iter: 73250/300480  CE: 2.5873  
[05/30 20:10:51] Re-training INFO: iter: 73375/300480  CE: 2.8576  
[05/30 20:12:15] Re-training INFO: iter: 73500/300480  CE: 3.1611  
[05/30 20:13:39] Re-training INFO: iter: 73625/300480  CE: 2.8753  
[05/30 20:15:01] Re-training INFO: iter: 73750/300480  CE: 2.9111  
[05/30 20:16:19] Re-training INFO: --> epoch:  59/240  avg CE: 2.8888  lr: 0.42907548585616356
[05/30 20:16:39] Re-training INFO: iter: 73875/300480  CE: 3.0849  
[05/30 20:18:03] Re-training INFO: iter: 74000/300480  CE: 2.8851  
[05/30 20:19:27] Re-training INFO: iter: 74125/300480  CE: 2.8943  
[05/30 20:20:51] Re-training INFO: iter: 74250/300480  CE: 2.7784  
[05/30 20:22:14] Re-training INFO: iter: 74375/300480  CE: 2.7157  
[05/30 20:23:38] Re-training INFO: iter: 74500/300480  CE: 3.0399  
[05/30 20:25:02] Re-training INFO: iter: 74625/300480  CE: 3.0269  
[05/30 20:26:26] Re-training INFO: iter: 74750/300480  CE: 3.0867  
[05/30 20:27:50] Re-training INFO: iter: 74875/300480  CE: 2.8095  
[05/30 20:29:14] Re-training INFO: iter: 75000/300480  CE: 3.1984  
[05/30 20:30:32] Re-training INFO: --> epoch:  60/240  avg CE: 2.8860  lr: 0.42677669529663687
[05/30 20:31:04] Re-training INFO: # of Test Samples: 50000.0
[05/30 20:31:04] Re-training INFO: Top-1/-5 acc: 57.40 / 81.48
[05/30 20:31:04] Re-training INFO: Top-1/-5 acc: 42.60 / 18.52
[05/30 20:31:04] Re-training INFO: 

[05/30 20:31:24] Re-training INFO: iter: 75125/300480  CE: 2.7610  
[05/30 20:32:48] Re-training INFO: iter: 75250/300480  CE: 2.7100  
[05/30 20:34:11] Re-training INFO: iter: 75375/300480  CE: 2.8736  
[05/30 20:35:35] Re-training INFO: iter: 75500/300480  CE: 2.9800  
[05/30 20:36:59] Re-training INFO: iter: 75625/300480  CE: 2.8115  
[05/30 20:38:23] Re-training INFO: iter: 75750/300480  CE: 2.6544  
[05/30 20:39:47] Re-training INFO: iter: 75875/300480  CE: 2.6754  
[05/30 20:41:10] Re-training INFO: iter: 76000/300480  CE: 2.8103  
[05/30 20:42:34] Re-training INFO: iter: 76125/300480  CE: 3.0576  
[05/30 20:43:58] Re-training INFO: iter: 76250/300480  CE: 2.4932  
[05/30 20:45:18] Re-training INFO: --> epoch:  61/240  avg CE: 2.8810  lr: 0.42444761496042005
[05/30 20:45:36] Re-training INFO: iter: 76375/300480  CE: 2.9323  
[05/30 20:47:00] Re-training INFO: iter: 76500/300480  CE: 2.8989  
[05/30 20:48:23] Re-training INFO: iter: 76625/300480  CE: 2.8488  
[05/30 20:49:47] Re-training INFO: iter: 76750/300480  CE: 2.8830  
[05/30 20:51:10] Re-training INFO: iter: 76875/300480  CE: 2.9249  
[05/30 20:52:35] Re-training INFO: iter: 77000/300480  CE: 3.0311  
[05/30 20:53:59] Re-training INFO: iter: 77125/300480  CE: 2.8109  
[05/30 20:55:22] Re-training INFO: iter: 77250/300480  CE: 2.8203  
[05/30 20:56:47] Re-training INFO: iter: 77375/300480  CE: 3.2490  
[05/30 20:58:10] Re-training INFO: iter: 77500/300480  CE: 3.0491  
[05/30 20:59:31] Re-training INFO: --> epoch:  62/240  avg CE: 2.8773  lr: 0.4220886439234385
[05/30 20:59:48] Re-training INFO: iter: 77625/300480  CE: 2.9384  
[05/30 21:01:12] Re-training INFO: iter: 77750/300480  CE: 2.9154  
[05/30 21:02:35] Re-training INFO: iter: 77875/300480  CE: 2.6717  
[05/30 21:03:59] Re-training INFO: iter: 78000/300480  CE: 2.7726  
[05/30 21:05:23] Re-training INFO: iter: 78125/300480  CE: 2.9966  
[05/30 21:06:47] Re-training INFO: iter: 78250/300480  CE: 2.7696  
[05/30 21:08:11] Re-training INFO: iter: 78375/300480  CE: 2.6211  
[05/30 21:09:34] Re-training INFO: iter: 78500/300480  CE: 2.8490  
[05/30 21:10:57] Re-training INFO: iter: 78625/300480  CE: 2.9310  
[05/30 21:12:22] Re-training INFO: iter: 78750/300480  CE: 3.0072  
[05/30 21:13:44] Re-training INFO: iter: 78875/300480  CE: 3.3405  
[05/30 21:13:44] Re-training INFO: --> epoch:  63/240  avg CE: 2.8764  lr: 0.4197001863832355
[05/30 21:15:23] Re-training INFO: iter: 79000/300480  CE: 3.1613  
[05/30 21:16:47] Re-training INFO: iter: 79125/300480  CE: 2.9058  
[05/30 21:18:11] Re-training INFO: iter: 79250/300480  CE: 2.7254  
[05/30 21:19:34] Re-training INFO: iter: 79375/300480  CE: 2.7328  
[05/30 21:20:59] Re-training INFO: iter: 79500/300480  CE: 3.1378  
[05/30 21:22:22] Re-training INFO: iter: 79625/300480  CE: 2.9467  
[05/30 21:23:46] Re-training INFO: iter: 79750/300480  CE: 2.9828  
[05/30 21:25:09] Re-training INFO: iter: 79875/300480  CE: 3.1834  
[05/30 21:26:32] Re-training INFO: iter: 80000/300480  CE: 2.8115  
[05/30 21:27:55] Re-training INFO: iter: 80125/300480  CE: 3.0624  
[05/30 21:27:56] Re-training INFO: --> epoch:  64/240  avg CE: 2.8696  lr: 0.41728265158971456
[05/30 21:29:34] Re-training INFO: iter: 80250/300480  CE: 2.9902  
[05/30 21:30:59] Re-training INFO: iter: 80375/300480  CE: 3.0399  
[05/30 21:32:23] Re-training INFO: iter: 80500/300480  CE: 2.6532  
[05/30 21:33:46] Re-training INFO: iter: 80625/300480  CE: 2.8992  
[05/30 21:35:11] Re-training INFO: iter: 80750/300480  CE: 2.6911  
[05/30 21:36:36] Re-training INFO: iter: 80875/300480  CE: 2.6828  
[05/30 21:37:59] Re-training INFO: iter: 81000/300480  CE: 2.8881  
[05/30 21:39:23] Re-training INFO: iter: 81125/300480  CE: 2.6971  
[05/30 21:40:48] Re-training INFO: iter: 81250/300480  CE: 2.6204  
[05/30 21:42:10] Re-training INFO: iter: 81375/300480  CE: 2.9984  
[05/30 21:42:12] Re-training INFO: --> epoch:  65/240  avg CE: 2.8705  lr: 0.4148364537750172
[05/30 21:43:49] Re-training INFO: iter: 81500/300480  CE: 2.9596  
[05/30 21:45:13] Re-training INFO: iter: 81625/300480  CE: 2.7675  
[05/30 21:46:36] Re-training INFO: iter: 81750/300480  CE: 3.1485  
[05/30 21:47:59] Re-training INFO: iter: 81875/300480  CE: 2.9641  
[05/30 21:49:22] Re-training INFO: iter: 82000/300480  CE: 3.0178  
[05/30 21:50:47] Re-training INFO: iter: 82125/300480  CE: 2.8598  
[05/30 21:52:11] Re-training INFO: iter: 82250/300480  CE: 2.9740  
[05/30 21:53:34] Re-training INFO: iter: 82375/300480  CE: 2.7643  
[05/30 21:54:57] Re-training INFO: iter: 82500/300480  CE: 2.7910  
[05/30 21:56:20] Re-training INFO: iter: 82625/300480  CE: 2.7088  
[05/30 21:56:23] Re-training INFO: --> epoch:  66/240  avg CE: 2.8685  lr: 0.4123620120825459
[05/30 21:57:59] Re-training INFO: iter: 82750/300480  CE: 2.6980  
[05/30 21:59:23] Re-training INFO: iter: 82875/300480  CE: 2.5706  
[05/30 22:00:47] Re-training INFO: iter: 83000/300480  CE: 2.8452  
[05/30 22:02:11] Re-training INFO: iter: 83125/300480  CE: 2.8754  
[05/30 22:03:34] Re-training INFO: iter: 83250/300480  CE: 2.7098  
[05/30 22:04:58] Re-training INFO: iter: 83375/300480  CE: 3.1871  
[05/30 22:06:23] Re-training INFO: iter: 83500/300480  CE: 2.9701  
[05/30 22:07:45] Re-training INFO: iter: 83625/300480  CE: 2.8254  
[05/30 22:09:09] Re-training INFO: iter: 83750/300480  CE: 2.8679  
[05/30 22:10:33] Re-training INFO: iter: 83875/300480  CE: 2.7420  
[05/30 22:10:37] Re-training INFO: --> epoch:  67/240  avg CE: 2.8644  lr: 0.4098597504951462
[05/30 22:12:11] Re-training INFO: iter: 84000/300480  CE: 3.0472  
[05/30 22:13:35] Re-training INFO: iter: 84125/300480  CE: 3.0642  
[05/30 22:15:00] Re-training INFO: iter: 84250/300480  CE: 2.8994  
[05/30 22:16:22] Re-training INFO: iter: 84375/300480  CE: 2.8702  
[05/30 22:17:46] Re-training INFO: iter: 84500/300480  CE: 2.7784  
[05/30 22:19:11] Re-training INFO: iter: 84625/300480  CE: 2.7524  
[05/30 22:20:34] Re-training INFO: iter: 84750/300480  CE: 2.8881  
[05/30 22:21:58] Re-training INFO: iter: 84875/300480  CE: 2.7655  
[05/30 22:23:21] Re-training INFO: iter: 85000/300480  CE: 2.9182  
[05/30 22:24:45] Re-training INFO: iter: 85125/300480  CE: 2.9498  
[05/30 22:24:50] Re-training INFO: --> epoch:  68/240  avg CE: 2.8687  lr: 0.4073300977624594
[05/30 22:26:24] Re-training INFO: iter: 85250/300480  CE: 2.5839  
[05/30 22:27:47] Re-training INFO: iter: 85375/300480  CE: 3.1634  
[05/30 22:29:10] Re-training INFO: iter: 85500/300480  CE: 2.9376  
[05/30 22:30:34] Re-training INFO: iter: 85625/300480  CE: 2.7985  
[05/30 22:31:58] Re-training INFO: iter: 85750/300480  CE: 2.8068  
[05/30 22:33:22] Re-training INFO: iter: 85875/300480  CE: 2.9134  
[05/30 22:34:46] Re-training INFO: iter: 86000/300480  CE: 2.9607  
[05/30 22:36:09] Re-training INFO: iter: 86125/300480  CE: 2.6686  
[05/30 22:37:34] Re-training INFO: iter: 86250/300480  CE: 3.0563  
[05/30 22:38:57] Re-training INFO: iter: 86375/300480  CE: 2.8339  
[05/30 22:39:03] Re-training INFO: --> epoch:  69/240  avg CE: 2.8575  lr: 0.4047734873274585
[05/30 22:40:34] Re-training INFO: iter: 86500/300480  CE: 2.8408  
[05/30 22:41:58] Re-training INFO: iter: 86625/300480  CE: 2.7050  
[05/30 22:43:23] Re-training INFO: iter: 86750/300480  CE: 3.0027  
[05/30 22:44:46] Re-training INFO: iter: 86875/300480  CE: 2.7031  
[05/30 22:46:10] Re-training INFO: iter: 87000/300480  CE: 2.6125  
[05/30 22:47:33] Re-training INFO: iter: 87125/300480  CE: 3.1948  
[05/30 22:48:57] Re-training INFO: iter: 87250/300480  CE: 2.9308  
[05/30 22:50:21] Re-training INFO: iter: 87375/300480  CE: 2.6773  
[05/30 22:51:44] Re-training INFO: iter: 87500/300480  CE: 2.6481  
[05/30 22:53:08] Re-training INFO: iter: 87625/300480  CE: 3.0162  
[05/30 22:53:16] Re-training INFO: --> epoch:  70/240  avg CE: 2.8593  lr: 0.40219035725218016
[05/30 22:54:46] Re-training INFO: iter: 87750/300480  CE: 2.5611  
[05/30 22:56:11] Re-training INFO: iter: 87875/300480  CE: 2.9842  
[05/30 22:57:33] Re-training INFO: iter: 88000/300480  CE: 3.0056  
[05/30 22:58:57] Re-training INFO: iter: 88125/300480  CE: 2.9221  
[05/30 23:00:21] Re-training INFO: iter: 88250/300480  CE: 2.7390  
[05/30 23:01:45] Re-training INFO: iter: 88375/300480  CE: 3.0299  
[05/30 23:03:09] Re-training INFO: iter: 88500/300480  CE: 2.7540  
[05/30 23:04:33] Re-training INFO: iter: 88625/300480  CE: 3.0869  
[05/30 23:05:57] Re-training INFO: iter: 88750/300480  CE: 2.6329  
[05/30 23:07:20] Re-training INFO: iter: 88875/300480  CE: 2.8778  
[05/30 23:07:29] Re-training INFO: --> epoch:  71/240  avg CE: 2.8482  lr: 0.39958115014266476
[05/30 23:08:59] Re-training INFO: iter: 89000/300480  CE: 2.9039  
[05/30 23:10:23] Re-training INFO: iter: 89125/300480  CE: 2.9016  
[05/30 23:11:47] Re-training INFO: iter: 89250/300480  CE: 2.8267  
[05/30 23:13:11] Re-training INFO: iter: 89375/300480  CE: 2.5860  
[05/30 23:14:35] Re-training INFO: iter: 89500/300480  CE: 2.9325  
[05/30 23:15:59] Re-training INFO: iter: 89625/300480  CE: 2.9483  
[05/30 23:17:21] Re-training INFO: iter: 89750/300480  CE: 2.8154  
[05/30 23:18:46] Re-training INFO: iter: 89875/300480  CE: 2.7675  
[05/30 23:20:09] Re-training INFO: iter: 90000/300480  CE: 2.7350  
[05/30 23:21:34] Re-training INFO: iter: 90125/300480  CE: 3.1420  
[05/30 23:21:44] Re-training INFO: --> epoch:  72/240  avg CE: 2.8537  lr: 0.39694631307311834
[05/30 23:23:13] Re-training INFO: iter: 90250/300480  CE: 3.0057  
[05/30 23:24:37] Re-training INFO: iter: 90375/300480  CE: 2.7813  
[05/30 23:26:00] Re-training INFO: iter: 90500/300480  CE: 2.9596  
[05/30 23:27:24] Re-training INFO: iter: 90625/300480  CE: 3.1194  
[05/30 23:28:48] Re-training INFO: iter: 90750/300480  CE: 2.9732  
[05/30 23:30:12] Re-training INFO: iter: 90875/300480  CE: 2.9856  
[05/30 23:31:36] Re-training INFO: iter: 91000/300480  CE: 2.9445  
[05/30 23:33:00] Re-training INFO: iter: 91125/300480  CE: 2.8004  
[05/30 23:34:24] Re-training INFO: iter: 91250/300480  CE: 2.5986  
[05/30 23:35:48] Re-training INFO: iter: 91375/300480  CE: 2.6565  
[05/30 23:36:00] Re-training INFO: --> epoch:  73/240  avg CE: 2.8464  lr: 0.39428629750930844
[05/30 23:37:26] Re-training INFO: iter: 91500/300480  CE: 2.6498  
[05/30 23:38:50] Re-training INFO: iter: 91625/300480  CE: 3.0081  
[05/30 23:40:14] Re-training INFO: iter: 91750/300480  CE: 2.9495  
[05/30 23:41:39] Re-training INFO: iter: 91875/300480  CE: 2.7872  
[05/30 23:43:02] Re-training INFO: iter: 92000/300480  CE: 2.7480  
[05/30 23:44:26] Re-training INFO: iter: 92125/300480  CE: 2.7976  
[05/30 23:45:50] Re-training INFO: iter: 92250/300480  CE: 2.9268  
[05/30 23:47:14] Re-training INFO: iter: 92375/300480  CE: 2.8092  
[05/30 23:48:38] Re-training INFO: iter: 92500/300480  CE: 2.8828  
[05/30 23:50:02] Re-training INFO: iter: 92625/300480  CE: 2.6665  
[05/30 23:50:15] Re-training INFO: --> epoch:  74/240  avg CE: 2.8434  lr: 0.3916015592312082
[05/30 23:51:40] Re-training INFO: iter: 92750/300480  CE: 2.6765  
[05/30 23:53:03] Re-training INFO: iter: 92875/300480  CE: 2.6173  
[05/30 23:54:26] Re-training INFO: iter: 93000/300480  CE: 2.9785  
[05/30 23:55:51] Re-training INFO: iter: 93125/300480  CE: 2.8226  
[05/30 23:57:14] Re-training INFO: iter: 93250/300480  CE: 2.7115  
[05/30 23:58:37] Re-training INFO: iter: 93375/300480  CE: 2.9002  
[05/31 00:00:01] Re-training INFO: iter: 93500/300480  CE: 2.9688  
[05/31 00:01:25] Re-training INFO: iter: 93625/300480  CE: 2.7169  
[05/31 00:02:49] Re-training INFO: iter: 93750/300480  CE: 2.9867  
[05/31 00:04:13] Re-training INFO: iter: 93875/300480  CE: 2.6888  
[05/31 00:04:28] Re-training INFO: --> epoch:  75/240  avg CE: 2.8472  lr: 0.38889255825490054
[05/31 00:05:52] Re-training INFO: iter: 94000/300480  CE: 2.9309  
[05/31 00:07:17] Re-training INFO: iter: 94125/300480  CE: 2.8108  
[05/31 00:08:42] Re-training INFO: iter: 94250/300480  CE: 2.6700  
[05/31 00:10:07] Re-training INFO: iter: 94375/300480  CE: 2.6379  
[05/31 00:11:32] Re-training INFO: iter: 94500/300480  CE: 2.7315  
[05/31 00:12:57] Re-training INFO: iter: 94625/300480  CE: 2.9177  
[05/31 00:14:21] Re-training INFO: iter: 94750/300480  CE: 3.0022  
[05/31 00:15:45] Re-training INFO: iter: 94875/300480  CE: 2.7148  
[05/31 00:17:11] Re-training INFO: iter: 95000/300480  CE: 2.9153  
[05/31 00:18:35] Re-training INFO: iter: 95125/300480  CE: 2.5539  
[05/31 00:18:51] Re-training INFO: --> epoch:  76/240  avg CE: 2.8411  lr: 0.3861597587537568
[05/31 00:20:13] Re-training INFO: iter: 95250/300480  CE: 3.0628  
[05/31 00:21:37] Re-training INFO: iter: 95375/300480  CE: 2.9818  
[05/31 00:23:01] Re-training INFO: iter: 95500/300480  CE: 2.8147  
[05/31 00:24:25] Re-training INFO: iter: 95625/300480  CE: 3.0085  
[05/31 00:25:48] Re-training INFO: iter: 95750/300480  CE: 2.8424  
[05/31 00:27:12] Re-training INFO: iter: 95875/300480  CE: 2.8409  
[05/31 00:28:36] Re-training INFO: iter: 96000/300480  CE: 2.7760  
[05/31 00:30:01] Re-training INFO: iter: 96125/300480  CE: 3.0107  
[05/31 00:31:24] Re-training INFO: iter: 96250/300480  CE: 3.1753  
[05/31 00:32:47] Re-training INFO: iter: 96375/300480  CE: 2.7448  
[05/31 00:33:04] Re-training INFO: --> epoch:  77/240  avg CE: 2.8396  lr: 0.3834036289789029
[05/31 00:34:27] Re-training INFO: iter: 96500/300480  CE: 2.8596  
[05/31 00:35:49] Re-training INFO: iter: 96625/300480  CE: 2.6591  
[05/31 00:37:14] Re-training INFO: iter: 96750/300480  CE: 2.8403  
[05/31 00:38:37] Re-training INFO: iter: 96875/300480  CE: 3.2448  
[05/31 00:40:01] Re-training INFO: iter: 97000/300480  CE: 2.9565  
[05/31 00:41:26] Re-training INFO: iter: 97125/300480  CE: 2.8126  
[05/31 00:42:51] Re-training INFO: iter: 97250/300480  CE: 3.0803  
[05/31 00:44:17] Re-training INFO: iter: 97375/300480  CE: 2.9100  
[05/31 00:45:42] Re-training INFO: iter: 97500/300480  CE: 3.0458  
[05/31 00:47:06] Re-training INFO: iter: 97625/300480  CE: 2.7921  
[05/31 00:47:25] Re-training INFO: --> epoch:  78/240  avg CE: 2.8264  lr: 0.3806246411789872
[05/31 00:48:46] Re-training INFO: iter: 97750/300480  CE: 3.0540  
[05/31 00:50:10] Re-training INFO: iter: 97875/300480  CE: 2.7336  
[05/31 00:51:33] Re-training INFO: iter: 98000/300480  CE: 2.7726  
[05/31 00:52:57] Re-training INFO: iter: 98125/300480  CE: 2.7225  
[05/31 00:54:22] Re-training INFO: iter: 98250/300480  CE: 2.9281  
[05/31 00:55:46] Re-training INFO: iter: 98375/300480  CE: 3.0455  
[05/31 00:57:11] Re-training INFO: iter: 98500/300480  CE: 2.7727  
[05/31 00:58:35] Re-training INFO: iter: 98625/300480  CE: 2.7329  
[05/31 01:00:01] Re-training INFO: iter: 98750/300480  CE: 2.7837  
[05/31 01:01:25] Re-training INFO: iter: 98875/300480  CE: 3.0006  
[05/31 01:01:46] Re-training INFO: --> epoch:  79/240  avg CE: 2.8289  lr: 0.3778232715192631
[05/31 01:03:03] Re-training INFO: iter: 99000/300480  CE: 2.7067  
[05/31 01:04:27] Re-training INFO: iter: 99125/300480  CE: 2.7506  
[05/31 01:05:50] Re-training INFO: iter: 99250/300480  CE: 2.6152  
[05/31 01:07:14] Re-training INFO: iter: 99375/300480  CE: 2.9584  
[05/31 01:08:37] Re-training INFO: iter: 99500/300480  CE: 2.7339  
[05/31 01:10:02] Re-training INFO: iter: 99625/300480  CE: 2.9678  
[05/31 01:11:26] Re-training INFO: iter: 99750/300480  CE: 2.5606  
[05/31 01:12:49] Re-training INFO: iter: 99875/300480  CE: 2.9652  
[05/31 01:14:14] Re-training INFO: iter: 100000/300480  CE: 2.7960  
[05/31 01:15:38] Re-training INFO: iter: 100125/300480  CE: 2.9422  
[05/31 01:15:59] Re-training INFO: --> epoch:  80/240  avg CE: 2.8216  lr: 0.375
[05/31 01:16:30] Re-training INFO: # of Test Samples: 50000.0
[05/31 01:16:30] Re-training INFO: Top-1/-5 acc: 59.40 / 82.93
[05/31 01:16:30] Re-training INFO: Top-1/-5 acc: 40.60 / 17.07
[05/31 01:16:30] Re-training INFO: 

[05/31 01:17:47] Re-training INFO: iter: 100250/300480  CE: 2.6503  
[05/31 01:19:10] Re-training INFO: iter: 100375/300480  CE: 2.6682  
[05/31 01:20:33] Re-training INFO: iter: 100500/300480  CE: 2.7305  
[05/31 01:21:58] Re-training INFO: iter: 100625/300480  CE: 2.6976  
[05/31 01:23:20] Re-training INFO: iter: 100750/300480  CE: 2.8217  
[05/31 01:24:44] Re-training INFO: iter: 100875/300480  CE: 2.8030  
[05/31 01:26:08] Re-training INFO: iter: 101000/300480  CE: 3.0474  
[05/31 01:27:32] Re-training INFO: iter: 101125/300480  CE: 3.0447  
[05/31 01:28:55] Re-training INFO: iter: 101250/300480  CE: 2.9330  
[05/31 01:30:19] Re-training INFO: iter: 101375/300480  CE: 2.9525  
[05/31 01:30:42] Re-training INFO: --> epoch:  81/240  avg CE: 2.8161  lr: 0.37215531037423877
[05/31 01:31:57] Re-training INFO: iter: 101500/300480  CE: 2.8621  
[05/31 01:33:23] Re-training INFO: iter: 101625/300480  CE: 2.6897  
[05/31 01:34:45] Re-training INFO: iter: 101750/300480  CE: 2.9737  
[05/31 01:36:10] Re-training INFO: iter: 101875/300480  CE: 2.8179  
[05/31 01:37:34] Re-training INFO: iter: 102000/300480  CE: 2.8166  
[05/31 01:38:58] Re-training INFO: iter: 102125/300480  CE: 3.0214  
[05/31 01:40:24] Re-training INFO: iter: 102250/300480  CE: 2.8672  
[05/31 01:41:48] Re-training INFO: iter: 102375/300480  CE: 2.5383  
[05/31 01:43:12] Re-training INFO: iter: 102500/300480  CE: 3.0666  
[05/31 01:44:36] Re-training INFO: iter: 102625/300480  CE: 3.0705  
[05/31 01:45:00] Re-training INFO: --> epoch:  82/240  avg CE: 2.8188  lr: 0.3692896900649021
[05/31 01:46:14] Re-training INFO: iter: 102750/300480  CE: 2.5702  
[05/31 01:47:38] Re-training INFO: iter: 102875/300480  CE: 2.6668  
[05/31 01:49:00] Re-training INFO: iter: 103000/300480  CE: 2.9231  
[05/31 01:50:24] Re-training INFO: iter: 103125/300480  CE: 2.5485  
[05/31 01:51:48] Re-training INFO: iter: 103250/300480  CE: 2.6631  
[05/31 01:53:11] Re-training INFO: iter: 103375/300480  CE: 2.7394  
[05/31 01:54:35] Re-training INFO: iter: 103500/300480  CE: 2.7281  
[05/31 01:55:58] Re-training INFO: iter: 103625/300480  CE: 2.4949  
[05/31 01:57:22] Re-training INFO: iter: 103750/300480  CE: 2.9801  
[05/31 01:58:45] Re-training INFO: iter: 103875/300480  CE: 2.7064  
[05/31 01:59:11] Re-training INFO: --> epoch:  83/240  avg CE: 2.8164  lr: 0.36640363008127785
[05/31 02:00:25] Re-training INFO: iter: 104000/300480  CE: 2.7686  
[05/31 02:01:48] Re-training INFO: iter: 104125/300480  CE: 2.4781  
[05/31 02:03:10] Re-training INFO: iter: 104250/300480  CE: 2.8484  
[05/31 02:04:35] Re-training INFO: iter: 104375/300480  CE: 3.0715  
[05/31 02:05:58] Re-training INFO: iter: 104500/300480  CE: 2.9063  
[05/31 02:07:21] Re-training INFO: iter: 104625/300480  CE: 2.8068  
[05/31 02:08:46] Re-training INFO: iter: 104750/300480  CE: 2.5620  
[05/31 02:10:10] Re-training INFO: iter: 104875/300480  CE: 2.9168  
[05/31 02:11:35] Re-training INFO: iter: 105000/300480  CE: 2.8272  
[05/31 02:12:59] Re-training INFO: iter: 105125/300480  CE: 2.9160  
[05/31 02:13:25] Re-training INFO: --> epoch:  84/240  avg CE: 2.8181  lr: 0.3634976249348867
[05/31 02:14:38] Re-training INFO: iter: 105250/300480  CE: 2.6313  
[05/31 02:16:01] Re-training INFO: iter: 105375/300480  CE: 3.0535  
[05/31 02:17:25] Re-training INFO: iter: 105500/300480  CE: 2.9316  
[05/31 02:18:49] Re-training INFO: iter: 105625/300480  CE: 2.7077  
[05/31 02:20:12] Re-training INFO: iter: 105750/300480  CE: 2.6004  
[05/31 02:21:36] Re-training INFO: iter: 105875/300480  CE: 2.4747  
[05/31 02:23:01] Re-training INFO: iter: 106000/300480  CE: 2.8926  
[05/31 02:24:25] Re-training INFO: iter: 106125/300480  CE: 2.7768  
[05/31 02:25:48] Re-training INFO: iter: 106250/300480  CE: 2.5869  
[05/31 02:27:13] Re-training INFO: iter: 106375/300480  CE: 3.1370  
[05/31 02:27:41] Re-training INFO: --> epoch:  85/240  avg CE: 2.8006  lr: 0.3605721725547503
[05/31 02:28:52] Re-training INFO: iter: 106500/300480  CE: 2.6095  
[05/31 02:30:16] Re-training INFO: iter: 106625/300480  CE: 2.7656  
[05/31 02:31:39] Re-training INFO: iter: 106750/300480  CE: 2.6651  
[05/31 02:33:02] Re-training INFO: iter: 106875/300480  CE: 2.6579  
[05/31 02:34:25] Re-training INFO: iter: 107000/300480  CE: 2.7114  
[05/31 02:35:49] Re-training INFO: iter: 107125/300480  CE: 2.6982  
[05/31 02:37:13] Re-training INFO: iter: 107250/300480  CE: 3.0874  
[05/31 02:38:37] Re-training INFO: iter: 107375/300480  CE: 2.8339  
[05/31 02:40:00] Re-training INFO: iter: 107500/300480  CE: 3.1568  
[05/31 02:41:25] Re-training INFO: iter: 107625/300480  CE: 2.7039  
[05/31 02:41:54] Re-training INFO: --> epoch:  86/240  avg CE: 2.7976  lr: 0.3576277742020738
[05/31 02:43:03] Re-training INFO: iter: 107750/300480  CE: 2.6393  
[05/31 02:44:27] Re-training INFO: iter: 107875/300480  CE: 2.5605  
[05/31 02:45:50] Re-training INFO: iter: 108000/300480  CE: 2.7764  
[05/31 02:47:14] Re-training INFO: iter: 108125/300480  CE: 2.8952  
[05/31 02:48:37] Re-training INFO: iter: 108250/300480  CE: 2.8467  
[05/31 02:50:02] Re-training INFO: iter: 108375/300480  CE: 3.0620  
[05/31 02:51:24] Re-training INFO: iter: 108500/300480  CE: 2.8303  
[05/31 02:52:48] Re-training INFO: iter: 108625/300480  CE: 2.7683  
[05/31 02:54:12] Re-training INFO: iter: 108750/300480  CE: 2.8167  
[05/31 02:55:35] Re-training INFO: iter: 108875/300480  CE: 2.9383  
[05/31 02:56:06] Re-training INFO: --> epoch:  87/240  avg CE: 2.8162  lr: 0.35466493438435703
[05/31 02:57:15] Re-training INFO: iter: 109000/300480  CE: 2.8359  
[05/31 02:58:38] Re-training INFO: iter: 109125/300480  CE: 2.6465  
[05/31 03:00:02] Re-training INFO: iter: 109250/300480  CE: 2.9211  
[05/31 03:01:25] Re-training INFO: iter: 109375/300480  CE: 2.7218  
[05/31 03:02:48] Re-training INFO: iter: 109500/300480  CE: 2.4219  
[05/31 03:04:12] Re-training INFO: iter: 109625/300480  CE: 2.7507  
[05/31 03:05:34] Re-training INFO: iter: 109750/300480  CE: 2.9616  
[05/31 03:06:59] Re-training INFO: iter: 109875/300480  CE: 2.9156  
[05/31 03:08:22] Re-training INFO: iter: 110000/300480  CE: 2.5474  
[05/31 03:09:46] Re-training INFO: iter: 110125/300480  CE: 2.7573  
[05/31 03:10:18] Re-training INFO: --> epoch:  88/240  avg CE: 2.7875  lr: 0.35168416076895004
[05/31 03:11:24] Re-training INFO: iter: 110250/300480  CE: 2.8917  
[05/31 03:12:46] Re-training INFO: iter: 110375/300480  CE: 3.0257  
[05/31 03:14:11] Re-training INFO: iter: 110500/300480  CE: 2.8600  
[05/31 03:15:34] Re-training INFO: iter: 110625/300480  CE: 2.6721  
[05/31 03:16:57] Re-training INFO: iter: 110750/300480  CE: 2.9115  
[05/31 03:18:21] Re-training INFO: iter: 110875/300480  CE: 2.8444  
[05/31 03:19:47] Re-training INFO: iter: 111000/300480  CE: 2.7027  
[05/31 03:21:10] Re-training INFO: iter: 111125/300480  CE: 2.7534  
[05/31 03:22:34] Re-training INFO: iter: 111250/300480  CE: 2.6545  
[05/31 03:23:57] Re-training INFO: iter: 111375/300480  CE: 2.9454  
[05/31 03:24:30] Re-training INFO: --> epoch:  89/240  avg CE: 2.7985  lr: 0.34868596409606684
[05/31 03:25:36] Re-training INFO: iter: 111500/300480  CE: 2.7688  
[05/31 03:26:59] Re-training INFO: iter: 111625/300480  CE: 2.4656  
[05/31 03:28:23] Re-training INFO: iter: 111750/300480  CE: 2.7750  
[05/31 03:29:47] Re-training INFO: iter: 111875/300480  CE: 2.5922  
[05/31 03:31:10] Re-training INFO: iter: 112000/300480  CE: 3.1510  
[05/31 03:32:34] Re-training INFO: iter: 112125/300480  CE: 2.7929  
[05/31 03:33:58] Re-training INFO: iter: 112250/300480  CE: 2.7644  
[05/31 03:35:21] Re-training INFO: iter: 112375/300480  CE: 2.7978  
[05/31 03:36:45] Re-training INFO: iter: 112500/300480  CE: 2.9012  
[05/31 03:38:09] Re-training INFO: iter: 112625/300480  CE: 3.0048  
[05/31 03:38:44] Re-training INFO: --> epoch:  90/240  avg CE: 2.7976  lr: 0.34567085809127246
[05/31 03:39:47] Re-training INFO: iter: 112750/300480  CE: 2.8224  
[05/31 03:41:09] Re-training INFO: iter: 112875/300480  CE: 2.8261  
[05/31 03:42:34] Re-training INFO: iter: 113000/300480  CE: 3.1461  
[05/31 03:43:57] Re-training INFO: iter: 113125/300480  CE: 2.9181  
[05/31 03:45:20] Re-training INFO: iter: 113250/300480  CE: 2.9947  
[05/31 03:46:43] Re-training INFO: iter: 113375/300480  CE: 2.7794  
[05/31 03:48:07] Re-training INFO: iter: 113500/300480  CE: 2.4027  
[05/31 03:49:31] Re-training INFO: iter: 113625/300480  CE: 2.9493  
[05/31 03:50:54] Re-training INFO: iter: 113750/300480  CE: 2.9638  
[05/31 03:52:18] Re-training INFO: iter: 113875/300480  CE: 2.7559  
[05/31 03:52:55] Re-training INFO: --> epoch:  91/240  avg CE: 2.7961  lr: 0.3426393593774591
[05/31 03:53:56] Re-training INFO: iter: 114000/300480  CE: 3.0893  
[05/31 03:55:21] Re-training INFO: iter: 114125/300480  CE: 2.6899  
[05/31 03:56:45] Re-training INFO: iter: 114250/300480  CE: 2.6196  
[05/31 03:58:07] Re-training INFO: iter: 114375/300480  CE: 2.4749  
[05/31 03:59:32] Re-training INFO: iter: 114500/300480  CE: 2.5464  
[05/31 04:00:56] Re-training INFO: iter: 114625/300480  CE: 3.3033  
[05/31 04:02:19] Re-training INFO: iter: 114750/300480  CE: 3.0192  
[05/31 04:03:42] Re-training INFO: iter: 114875/300480  CE: 2.7719  
[05/31 04:05:06] Re-training INFO: iter: 115000/300480  CE: 2.5279  
[05/31 04:06:30] Re-training INFO: iter: 115125/300480  CE: 2.7144  
[05/31 04:07:07] Re-training INFO: --> epoch:  92/240  avg CE: 2.7847  lr: 0.339591987386325
[05/31 04:08:07] Re-training INFO: iter: 115250/300480  CE: 2.7181  
[05/31 04:09:31] Re-training INFO: iter: 115375/300480  CE: 2.4666  
[05/31 04:10:55] Re-training INFO: iter: 115500/300480  CE: 2.8155  
[05/31 04:12:19] Re-training INFO: iter: 115625/300480  CE: 2.7848  
[05/31 04:13:42] Re-training INFO: iter: 115750/300480  CE: 2.7485  
[05/31 04:15:06] Re-training INFO: iter: 115875/300480  CE: 2.6108  
[05/31 04:16:30] Re-training INFO: iter: 116000/300480  CE: 3.1482  
[05/31 04:17:54] Re-training INFO: iter: 116125/300480  CE: 2.9294  
[05/31 04:19:17] Re-training INFO: iter: 116250/300480  CE: 2.8453  
[05/31 04:20:41] Re-training INFO: iter: 116375/300480  CE: 2.7800  
[05/31 04:21:20] Re-training INFO: --> epoch:  93/240  avg CE: 2.7865  lr: 0.33652926426937324
[05/31 04:22:19] Re-training INFO: iter: 116500/300480  CE: 2.7883  
[05/31 04:23:43] Re-training INFO: iter: 116625/300480  CE: 2.7116  
[05/31 04:25:07] Re-training INFO: iter: 116750/300480  CE: 2.8968  
[05/31 04:26:32] Re-training INFO: iter: 116875/300480  CE: 2.7922  
[05/31 04:27:56] Re-training INFO: iter: 117000/300480  CE: 2.7349  
[05/31 04:29:21] Re-training INFO: iter: 117125/300480  CE: 2.7589  
[05/31 04:30:44] Re-training INFO: iter: 117250/300480  CE: 2.8600  
[05/31 04:32:08] Re-training INFO: iter: 117375/300480  CE: 2.7384  
[05/31 04:33:33] Re-training INFO: iter: 117500/300480  CE: 3.0000  
[05/31 04:34:57] Re-training INFO: iter: 117625/300480  CE: 2.7217  
[05/31 04:35:38] Re-training INFO: --> epoch:  94/240  avg CE: 2.7780  lr: 0.33345171480844277
[05/31 04:36:35] Re-training INFO: iter: 117750/300480  CE: 2.5480  
[05/31 04:38:00] Re-training INFO: iter: 117875/300480  CE: 2.4837  
[05/31 04:39:24] Re-training INFO: iter: 118000/300480  CE: 2.8750  
[05/31 04:40:48] Re-training INFO: iter: 118125/300480  CE: 2.5031  
[05/31 04:42:13] Re-training INFO: iter: 118250/300480  CE: 2.9176  
[05/31 04:43:36] Re-training INFO: iter: 118375/300480  CE: 2.3976  
[05/31 04:44:59] Re-training INFO: iter: 118500/300480  CE: 2.6444  
[05/31 04:46:23] Re-training INFO: iter: 118625/300480  CE: 2.8824  
[05/31 04:47:47] Re-training INFO: iter: 118750/300480  CE: 2.7023  
[05/31 04:49:09] Re-training INFO: iter: 118875/300480  CE: 2.7506  
[05/31 04:49:52] Re-training INFO: --> epoch:  95/240  avg CE: 2.7762  lr: 0.3303598663257904
[05/31 04:50:48] Re-training INFO: iter: 119000/300480  CE: 2.5833  
[05/31 04:52:11] Re-training INFO: iter: 119125/300480  CE: 3.0415  
[05/31 04:53:34] Re-training INFO: iter: 119250/300480  CE: 2.7441  
[05/31 04:54:58] Re-training INFO: iter: 119375/300480  CE: 2.9666  
[05/31 04:56:21] Re-training INFO: iter: 119500/300480  CE: 2.7854  
[05/31 04:57:46] Re-training INFO: iter: 119625/300480  CE: 2.7716  
[05/31 04:59:09] Re-training INFO: iter: 119750/300480  CE: 2.9552  
[05/31 05:00:33] Re-training INFO: iter: 119875/300480  CE: 2.6228  
[05/31 05:01:58] Re-training INFO: iter: 120000/300480  CE: 2.8965  
[05/31 05:03:21] Re-training INFO: iter: 120125/300480  CE: 2.8583  
[05/31 05:04:04] Re-training INFO: --> epoch:  96/240  avg CE: 2.7769  lr: 0.32725424859373686
[05/31 05:04:59] Re-training INFO: iter: 120250/300480  CE: 2.7498  
[05/31 05:06:23] Re-training INFO: iter: 120375/300480  CE: 2.7151  
[05/31 05:07:47] Re-training INFO: iter: 120500/300480  CE: 3.1833  
[05/31 05:09:11] Re-training INFO: iter: 120625/300480  CE: 2.7984  
[05/31 05:10:34] Re-training INFO: iter: 120750/300480  CE: 2.7067  
[05/31 05:11:59] Re-training INFO: iter: 120875/300480  CE: 2.8252  
[05/31 05:13:23] Re-training INFO: iter: 121000/300480  CE: 2.4558  
[05/31 05:14:46] Re-training INFO: iter: 121125/300480  CE: 3.0236  
[05/31 05:16:11] Re-training INFO: iter: 121250/300480  CE: 2.8023  
[05/31 05:17:36] Re-training INFO: iter: 121375/300480  CE: 3.0571  
[05/31 05:18:20] Re-training INFO: --> epoch:  97/240  avg CE: 2.7703  lr: 0.3241353937438927
[05/31 05:19:14] Re-training INFO: iter: 121500/300480  CE: 2.6546  
[05/31 05:20:39] Re-training INFO: iter: 121625/300480  CE: 2.6333  
[05/31 05:22:03] Re-training INFO: iter: 121750/300480  CE: 2.7854  
[05/31 05:23:27] Re-training INFO: iter: 121875/300480  CE: 2.6319  
[05/31 05:24:51] Re-training INFO: iter: 122000/300480  CE: 2.9440  
[05/31 05:26:14] Re-training INFO: iter: 122125/300480  CE: 2.9940  
[05/31 05:27:39] Re-training INFO: iter: 122250/300480  CE: 2.6509  
[05/31 05:29:03] Re-training INFO: iter: 122375/300480  CE: 3.0664  
[05/31 05:30:28] Re-training INFO: iter: 122500/300480  CE: 2.7895  
[05/31 05:31:51] Re-training INFO: iter: 122625/300480  CE: 2.8546  
[05/31 05:32:37] Re-training INFO: --> epoch:  98/240  avg CE: 2.7694  lr: 0.3210038361759807
[05/31 05:33:30] Re-training INFO: iter: 122750/300480  CE: 3.0200  
[05/31 05:34:54] Re-training INFO: iter: 122875/300480  CE: 2.6067  
[05/31 05:36:17] Re-training INFO: iter: 123000/300480  CE: 2.4543  
[05/31 05:37:42] Re-training INFO: iter: 123125/300480  CE: 2.7550  
[05/31 05:39:06] Re-training INFO: iter: 123250/300480  CE: 2.6908  
[05/31 05:40:30] Re-training INFO: iter: 123375/300480  CE: 2.8019  
[05/31 05:41:55] Re-training INFO: iter: 123500/300480  CE: 2.9479  
[05/31 05:43:19] Re-training INFO: iter: 123625/300480  CE: 2.5753  
[05/31 05:44:44] Re-training INFO: iter: 123750/300480  CE: 2.6584  
[05/31 05:46:07] Re-training INFO: iter: 123875/300480  CE: 2.6978  
[05/31 05:46:55] Re-training INFO: --> epoch:  99/240  avg CE: 2.7629  lr: 0.31786011246626855
[05/31 05:47:46] Re-training INFO: iter: 124000/300480  CE: 2.9883  
[05/31 05:49:11] Re-training INFO: iter: 124125/300480  CE: 2.6935  
[05/31 05:50:35] Re-training INFO: iter: 124250/300480  CE: 2.6881  
[05/31 05:52:00] Re-training INFO: iter: 124375/300480  CE: 2.8106  
[05/31 05:53:25] Re-training INFO: iter: 124500/300480  CE: 2.8018  
[05/31 05:54:50] Re-training INFO: iter: 124625/300480  CE: 2.8002  
[05/31 05:56:14] Re-training INFO: iter: 124750/300480  CE: 3.0592  
[05/31 05:57:39] Re-training INFO: iter: 124875/300480  CE: 2.9793  
[05/31 05:59:02] Re-training INFO: iter: 125000/300480  CE: 2.6118  
[05/31 06:00:27] Re-training INFO: iter: 125125/300480  CE: 2.8250  
[05/31 06:01:16] Re-training INFO: --> epoch: 100/240  avg CE: 2.7602  lr: 0.3147047612756302
[05/31 06:01:47] Re-training INFO: # of Test Samples: 50000.0
[05/31 06:01:47] Re-training INFO: Top-1/-5 acc: 59.83 / 83.62
[05/31 06:01:47] Re-training INFO: Top-1/-5 acc: 40.17 / 16.38
[05/31 06:01:47] Re-training INFO: 

[05/31 06:02:37] Re-training INFO: iter: 125250/300480  CE: 3.0013  
[05/31 06:04:01] Re-training INFO: iter: 125375/300480  CE: 2.7265  
[05/31 06:05:24] Re-training INFO: iter: 125500/300480  CE: 2.7754  
[05/31 06:06:48] Re-training INFO: iter: 125625/300480  CE: 2.6801  
[05/31 06:08:13] Re-training INFO: iter: 125750/300480  CE: 2.5710  
[05/31 06:09:37] Re-training INFO: iter: 125875/300480  CE: 2.8429  
[05/31 06:11:01] Re-training INFO: iter: 126000/300480  CE: 2.9920  
[05/31 06:12:24] Re-training INFO: iter: 126125/300480  CE: 2.7371  
[05/31 06:13:49] Re-training INFO: iter: 126250/300480  CE: 2.6798  
[05/31 06:15:14] Re-training INFO: iter: 126375/300480  CE: 2.7656  
[05/31 06:16:04] Re-training INFO: --> epoch: 101/240  avg CE: 2.7617  lr: 0.3115383232572483
[05/31 06:16:52] Re-training INFO: iter: 126500/300480  CE: 2.7110  
[05/31 06:18:17] Re-training INFO: iter: 126625/300480  CE: 2.7255  
[05/31 06:19:40] Re-training INFO: iter: 126750/300480  CE: 2.6776  
[05/31 06:21:04] Re-training INFO: iter: 126875/300480  CE: 2.5805  
[05/31 06:22:27] Re-training INFO: iter: 127000/300480  CE: 2.6267  
[05/31 06:23:51] Re-training INFO: iter: 127125/300480  CE: 2.7955  
[05/31 06:25:15] Re-training INFO: iter: 127250/300480  CE: 2.8200  
[05/31 06:26:39] Re-training INFO: iter: 127375/300480  CE: 2.4967  
[05/31 06:28:02] Re-training INFO: iter: 127500/300480  CE: 2.6802  
[05/31 06:29:25] Re-training INFO: iter: 127625/300480  CE: 2.5471  
[05/31 06:30:16] Re-training INFO: --> epoch: 102/240  avg CE: 2.7496  lr: 0.3083613409639764
[05/31 06:31:03] Re-training INFO: iter: 127750/300480  CE: 2.6494  
[05/31 06:32:28] Re-training INFO: iter: 127875/300480  CE: 2.7582  
[05/31 06:33:52] Re-training INFO: iter: 128000/300480  CE: 2.8739  
[05/31 06:35:15] Re-training INFO: iter: 128125/300480  CE: 2.5454  
[05/31 06:36:40] Re-training INFO: iter: 128250/300480  CE: 2.6292  
[05/31 06:38:06] Re-training INFO: iter: 128375/300480  CE: 2.7848  
[05/31 06:39:30] Re-training INFO: iter: 128500/300480  CE: 2.8864  
[05/31 06:40:54] Re-training INFO: iter: 128625/300480  CE: 2.9257  
[05/31 06:42:17] Re-training INFO: iter: 128750/300480  CE: 2.7045  
[05/31 06:43:42] Re-training INFO: iter: 128875/300480  CE: 2.8358  
[05/31 06:44:34] Re-training INFO: --> epoch: 103/240  avg CE: 2.7452  lr: 0.30517435875537524
[05/31 06:45:21] Re-training INFO: iter: 129000/300480  CE: 2.7114  
[05/31 06:46:45] Re-training INFO: iter: 129125/300480  CE: 2.7956  
[05/31 06:48:10] Re-training INFO: iter: 129250/300480  CE: 2.6475  
[05/31 06:49:34] Re-training INFO: iter: 129375/300480  CE: 2.8792  
[05/31 06:50:57] Re-training INFO: iter: 129500/300480  CE: 2.9260  
[05/31 06:52:22] Re-training INFO: iter: 129625/300480  CE: 2.8495  
[05/31 06:53:46] Re-training INFO: iter: 129750/300480  CE: 2.9073  
[05/31 06:55:11] Re-training INFO: iter: 129875/300480  CE: 2.9347  
[05/31 06:56:35] Re-training INFO: iter: 130000/300480  CE: 2.9260  
[05/31 06:58:00] Re-training INFO: iter: 130125/300480  CE: 2.8684  
[05/31 06:58:54] Re-training INFO: --> epoch: 104/240  avg CE: 2.7433  lr: 0.30197792270443985
[05/31 06:59:41] Re-training INFO: iter: 130250/300480  CE: 2.5770  
[05/31 07:01:03] Re-training INFO: iter: 130375/300480  CE: 2.7947  
[05/31 07:02:27] Re-training INFO: iter: 130500/300480  CE: 2.6225  
[05/31 07:03:52] Re-training INFO: iter: 130625/300480  CE: 2.6615  
[05/31 07:05:15] Re-training INFO: iter: 130750/300480  CE: 2.3902  
[05/31 07:06:37] Re-training INFO: iter: 130875/300480  CE: 2.6713  
[05/31 07:08:02] Re-training INFO: iter: 131000/300480  CE: 2.7004  
[05/31 07:09:25] Re-training INFO: iter: 131125/300480  CE: 2.7420  
[05/31 07:10:49] Re-training INFO: iter: 131250/300480  CE: 2.8894  
[05/31 07:12:14] Re-training INFO: iter: 131375/300480  CE: 2.6169  
[05/31 07:13:09] Re-training INFO: --> epoch: 105/240  avg CE: 2.7484  lr: 0.2987725805040321
[05/31 07:13:53] Re-training INFO: iter: 131500/300480  CE: 2.7878  
[05/31 07:15:18] Re-training INFO: iter: 131625/300480  CE: 2.6857  
[05/31 07:16:42] Re-training INFO: iter: 131750/300480  CE: 2.7828  
[05/31 07:18:05] Re-training INFO: iter: 131875/300480  CE: 2.7043  
[05/31 07:19:28] Re-training INFO: iter: 132000/300480  CE: 2.7529  
[05/31 07:20:52] Re-training INFO: iter: 132125/300480  CE: 2.5637  
[05/31 07:22:15] Re-training INFO: iter: 132250/300480  CE: 2.6417  
[05/31 07:23:40] Re-training INFO: iter: 132375/300480  CE: 2.7307  
[05/31 07:25:02] Re-training INFO: iter: 132500/300480  CE: 2.6586  
[05/31 07:26:25] Re-training INFO: iter: 132625/300480  CE: 2.5349  
[05/31 07:27:23] Re-training INFO: --> epoch: 106/240  avg CE: 2.7417  lr: 0.29555888137303693
[05/31 07:28:05] Re-training INFO: iter: 132750/300480  CE: 2.7637  
[05/31 07:29:28] Re-training INFO: iter: 132875/300480  CE: 2.8473  
[05/31 07:30:52] Re-training INFO: iter: 133000/300480  CE: 2.6795  
[05/31 07:32:16] Re-training INFO: iter: 133125/300480  CE: 2.7373  
[05/31 07:33:40] Re-training INFO: iter: 133250/300480  CE: 2.5755  
[05/31 07:35:04] Re-training INFO: iter: 133375/300480  CE: 2.7183  
[05/31 07:36:28] Re-training INFO: iter: 133500/300480  CE: 2.8946  
[05/31 07:37:53] Re-training INFO: iter: 133625/300480  CE: 2.5728  
[05/31 07:39:16] Re-training INFO: iter: 133750/300480  CE: 2.6092  
[05/31 07:40:39] Re-training INFO: iter: 133875/300480  CE: 2.6738  
[05/31 07:41:38] Re-training INFO: --> epoch: 107/240  avg CE: 2.7365  lr: 0.2923373759622561
[05/31 07:42:17] Re-training INFO: iter: 134000/300480  CE: 2.6430  
[05/31 07:43:43] Re-training INFO: iter: 134125/300480  CE: 2.9232  
[05/31 07:45:06] Re-training INFO: iter: 134250/300480  CE: 2.7446  
[05/31 07:46:29] Re-training INFO: iter: 134375/300480  CE: 2.6381  
[05/31 07:47:54] Re-training INFO: iter: 134500/300480  CE: 2.5367  
[05/31 07:49:18] Re-training INFO: iter: 134625/300480  CE: 2.6644  
[05/31 07:50:42] Re-training INFO: iter: 134750/300480  CE: 2.5929  
[05/31 07:52:05] Re-training INFO: iter: 134875/300480  CE: 2.5403  
[05/31 07:53:29] Re-training INFO: iter: 135000/300480  CE: 3.0247  
[05/31 07:54:54] Re-training INFO: iter: 135125/300480  CE: 2.6806  
[05/31 07:55:52] Re-training INFO: --> epoch: 108/240  avg CE: 2.7350  lr: 0.28910861626005774
[05/31 07:56:31] Re-training INFO: iter: 135250/300480  CE: 2.6525  
[05/31 07:57:56] Re-training INFO: iter: 135375/300480  CE: 2.5426  
[05/31 07:59:19] Re-training INFO: iter: 135500/300480  CE: 2.8463  
[05/31 08:00:42] Re-training INFO: iter: 135625/300480  CE: 2.6948  
[05/31 08:02:07] Re-training INFO: iter: 135750/300480  CE: 2.7006  
[05/31 08:03:31] Re-training INFO: iter: 135875/300480  CE: 2.5639  
[05/31 08:04:55] Re-training INFO: iter: 136000/300480  CE: 2.4753  
[05/31 08:06:19] Re-training INFO: iter: 136125/300480  CE: 2.7892  
[05/31 08:07:44] Re-training INFO: iter: 136250/300480  CE: 3.0241  
[05/31 08:09:07] Re-training INFO: iter: 136375/300480  CE: 2.8736  
[05/31 08:10:08] Re-training INFO: --> epoch: 109/240  avg CE: 2.7294  lr: 0.2858731554977949
[05/31 08:10:46] Re-training INFO: iter: 136500/300480  CE: 2.6779  
[05/31 08:12:10] Re-training INFO: iter: 136625/300480  CE: 2.6858  
[05/31 08:13:34] Re-training INFO: iter: 136750/300480  CE: 2.6260  
[05/31 08:14:59] Re-training INFO: iter: 136875/300480  CE: 2.5359  
[05/31 08:16:22] Re-training INFO: iter: 137000/300480  CE: 2.6926  
[05/31 08:17:46] Re-training INFO: iter: 137125/300480  CE: 2.6399  
[05/31 08:19:11] Re-training INFO: iter: 137250/300480  CE: 3.1810  
[05/31 08:20:36] Re-training INFO: iter: 137375/300480  CE: 2.5635  
[05/31 08:22:00] Re-training INFO: iter: 137500/300480  CE: 2.9850  
[05/31 08:23:24] Re-training INFO: iter: 137625/300480  CE: 2.8736  
[05/31 08:24:26] Re-training INFO: --> epoch: 110/240  avg CE: 2.7191  lr: 0.2826315480550129
[05/31 08:25:04] Re-training INFO: iter: 137750/300480  CE: 2.9834  
[05/31 08:26:32] Re-training INFO: iter: 137875/300480  CE: 2.5390  
[05/31 08:27:58] Re-training INFO: iter: 138000/300480  CE: 3.1253  
[05/31 08:29:21] Re-training INFO: iter: 138125/300480  CE: 2.8419  
[05/31 08:30:44] Re-training INFO: iter: 138250/300480  CE: 2.9881  
[05/31 08:32:09] Re-training INFO: iter: 138375/300480  CE: 2.5958  
[05/31 08:33:34] Re-training INFO: iter: 138500/300480  CE: 2.6939  
[05/31 08:34:59] Re-training INFO: iter: 138625/300480  CE: 2.7724  
[05/31 08:36:25] Re-training INFO: iter: 138750/300480  CE: 2.4910  
[05/31 08:37:47] Re-training INFO: iter: 138875/300480  CE: 2.5326  
[05/31 08:38:50] Re-training INFO: --> epoch: 111/240  avg CE: 2.7205  lr: 0.27938434936445944
[05/31 08:39:26] Re-training INFO: iter: 139000/300480  CE: 2.6654  
[05/31 08:40:51] Re-training INFO: iter: 139125/300480  CE: 2.8167  
[05/31 08:42:15] Re-training INFO: iter: 139250/300480  CE: 2.6735  
[05/31 08:43:39] Re-training INFO: iter: 139375/300480  CE: 2.9560  
[05/31 08:45:03] Re-training INFO: iter: 139500/300480  CE: 2.8359  
[05/31 08:46:27] Re-training INFO: iter: 139625/300480  CE: 2.8896  
[05/31 08:47:50] Re-training INFO: iter: 139750/300480  CE: 2.9275  
[05/31 08:49:14] Re-training INFO: iter: 139875/300480  CE: 2.6995  
[05/31 08:50:38] Re-training INFO: iter: 140000/300480  CE: 2.8663  
[05/31 08:52:04] Re-training INFO: iter: 140125/300480  CE: 2.9035  
[05/31 08:53:08] Re-training INFO: --> epoch: 112/240  avg CE: 2.7189  lr: 0.2761321158169134
[05/31 08:53:43] Re-training INFO: iter: 140250/300480  CE: 2.5927  
[05/31 08:55:06] Re-training INFO: iter: 140375/300480  CE: 2.7519  
[05/31 08:56:30] Re-training INFO: iter: 140500/300480  CE: 2.4905  
[05/31 08:57:54] Re-training INFO: iter: 140625/300480  CE: 2.8819  
[05/31 08:59:17] Re-training INFO: iter: 140750/300480  CE: 2.6824  
[05/31 09:00:42] Re-training INFO: iter: 140875/300480  CE: 2.5200  
[05/31 09:02:05] Re-training INFO: iter: 141000/300480  CE: 2.9358  
[05/31 09:03:29] Re-training INFO: iter: 141125/300480  CE: 2.4692  
[05/31 09:04:53] Re-training INFO: iter: 141250/300480  CE: 2.6164  
[05/31 09:06:16] Re-training INFO: iter: 141375/300480  CE: 2.7294  
[05/31 09:07:22] Re-training INFO: --> epoch: 113/240  avg CE: 2.7135  lr: 0.27287540466585064
[05/31 09:07:55] Re-training INFO: iter: 141500/300480  CE: 2.6312  
[05/31 09:09:19] Re-training INFO: iter: 141625/300480  CE: 2.8442  
[05/31 09:10:43] Re-training INFO: iter: 141750/300480  CE: 2.5710  
[05/31 09:12:07] Re-training INFO: iter: 141875/300480  CE: 2.8481  
[05/31 09:13:30] Re-training INFO: iter: 142000/300480  CE: 2.6064  
[05/31 09:14:54] Re-training INFO: iter: 142125/300480  CE: 2.7551  
[05/31 09:16:17] Re-training INFO: iter: 142250/300480  CE: 2.5604  
[05/31 09:17:41] Re-training INFO: iter: 142375/300480  CE: 2.6123  
[05/31 09:19:05] Re-training INFO: iter: 142500/300480  CE: 2.8266  
[05/31 09:20:29] Re-training INFO: iter: 142625/300480  CE: 2.5218  
[05/31 09:21:36] Re-training INFO: --> epoch: 114/240  avg CE: 2.7032  lr: 0.26961477393196126
[05/31 09:22:07] Re-training INFO: iter: 142750/300480  CE: 2.4647  
[05/31 09:23:31] Re-training INFO: iter: 142875/300480  CE: 2.6362  
[05/31 09:24:57] Re-training INFO: iter: 143000/300480  CE: 2.7098  
[05/31 09:26:20] Re-training INFO: iter: 143125/300480  CE: 2.9017  
[05/31 09:27:45] Re-training INFO: iter: 143250/300480  CE: 2.9667  
[05/31 09:29:08] Re-training INFO: iter: 143375/300480  CE: 2.5013  
[05/31 09:30:32] Re-training INFO: iter: 143500/300480  CE: 2.6822  
[05/31 09:31:57] Re-training INFO: iter: 143625/300480  CE: 2.5098  
[05/31 09:33:20] Re-training INFO: iter: 143750/300480  CE: 2.4808  
[05/31 09:34:43] Re-training INFO: iter: 143875/300480  CE: 2.6920  
[05/31 09:35:52] Re-training INFO: --> epoch: 115/240  avg CE: 2.7024  lr: 0.2663507823075358
[05/31 09:36:22] Re-training INFO: iter: 144000/300480  CE: 2.5509  
[05/31 09:37:47] Re-training INFO: iter: 144125/300480  CE: 2.6951  
[05/31 09:39:13] Re-training INFO: iter: 144250/300480  CE: 2.7723  
[05/31 09:40:37] Re-training INFO: iter: 144375/300480  CE: 2.6505  
[05/31 09:42:00] Re-training INFO: iter: 144500/300480  CE: 2.7652  
[05/31 09:43:24] Re-training INFO: iter: 144625/300480  CE: 2.7694  
[05/31 09:44:50] Re-training INFO: iter: 144750/300480  CE: 2.6508  
[05/31 09:46:13] Re-training INFO: iter: 144875/300480  CE: 2.9598  
[05/31 09:47:37] Re-training INFO: iter: 145000/300480  CE: 2.3152  
[05/31 09:49:02] Re-training INFO: iter: 145125/300480  CE: 2.5590  
[05/31 09:50:11] Re-training INFO: --> epoch: 116/240  avg CE: 2.6981  lr: 0.263083989060736
[05/31 09:50:40] Re-training INFO: iter: 145250/300480  CE: 2.7710  
[05/31 09:52:08] Re-training INFO: iter: 145375/300480  CE: 2.6808  
[05/31 09:53:35] Re-training INFO: iter: 145500/300480  CE: 2.8735  
[05/31 09:55:00] Re-training INFO: iter: 145625/300480  CE: 2.7823  
[05/31 09:56:26] Re-training INFO: iter: 145750/300480  CE: 2.6270  
[05/31 09:57:52] Re-training INFO: iter: 145875/300480  CE: 2.5022  
[05/31 09:59:15] Re-training INFO: iter: 146000/300480  CE: 2.6715  
[05/31 10:00:38] Re-training INFO: iter: 146125/300480  CE: 2.8077  
[05/31 10:02:03] Re-training INFO: iter: 146250/300480  CE: 2.4353  
[05/31 10:03:27] Re-training INFO: iter: 146375/300480  CE: 2.5024  
[05/31 10:04:38] Re-training INFO: --> epoch: 117/240  avg CE: 2.7033  lr: 0.25981495393976717
[05/31 10:05:05] Re-training INFO: iter: 146500/300480  CE: 2.8659  
[05/31 10:06:31] Re-training INFO: iter: 146625/300480  CE: 2.4996  
[05/31 10:07:55] Re-training INFO: iter: 146750/300480  CE: 2.9068  
[05/31 10:09:19] Re-training INFO: iter: 146875/300480  CE: 2.6257  
[05/31 10:10:43] Re-training INFO: iter: 147000/300480  CE: 2.7614  
[05/31 10:12:06] Re-training INFO: iter: 147125/300480  CE: 2.6677  
[05/31 10:13:31] Re-training INFO: iter: 147250/300480  CE: 2.8050  
[05/31 10:14:54] Re-training INFO: iter: 147375/300480  CE: 2.7564  
[05/31 10:16:18] Re-training INFO: iter: 147500/300480  CE: 2.5840  
[05/31 10:17:41] Re-training INFO: iter: 147625/300480  CE: 2.5987  
[05/31 10:18:55] Re-training INFO: --> epoch: 118/240  avg CE: 2.6954  lr: 0.2565442370769683
[05/31 10:19:21] Re-training INFO: iter: 147750/300480  CE: 2.6495  
[05/31 10:20:47] Re-training INFO: iter: 147875/300480  CE: 2.6983  
[05/31 10:22:13] Re-training INFO: iter: 148000/300480  CE: 2.8734  
[05/31 10:23:36] Re-training INFO: iter: 148125/300480  CE: 2.7289  
[05/31 10:25:00] Re-training INFO: iter: 148250/300480  CE: 2.6032  
[05/31 10:26:25] Re-training INFO: iter: 148375/300480  CE: 2.5967  
[05/31 10:27:48] Re-training INFO: iter: 148500/300480  CE: 2.9098  
[05/31 10:29:12] Re-training INFO: iter: 148625/300480  CE: 2.8031  
[05/31 10:30:37] Re-training INFO: iter: 148750/300480  CE: 2.3829  
[05/31 10:32:01] Re-training INFO: iter: 148875/300480  CE: 2.6135  
[05/31 10:33:15] Re-training INFO: --> epoch: 119/240  avg CE: 2.6879  lr: 0.25327239889283615
[05/31 10:33:39] Re-training INFO: iter: 149000/300480  CE: 2.5969  
[05/31 10:35:05] Re-training INFO: iter: 149125/300480  CE: 2.8177  
[05/31 10:36:29] Re-training INFO: iter: 149250/300480  CE: 2.6209  
[05/31 10:37:53] Re-training INFO: iter: 149375/300480  CE: 2.6885  
[05/31 10:39:18] Re-training INFO: iter: 149500/300480  CE: 2.4884  
[05/31 10:40:41] Re-training INFO: iter: 149625/300480  CE: 2.5966  
[05/31 10:42:06] Re-training INFO: iter: 149750/300480  CE: 2.7242  
[05/31 10:43:29] Re-training INFO: iter: 149875/300480  CE: 2.7606  
[05/31 10:44:52] Re-training INFO: iter: 150000/300480  CE: 2.5560  
[05/31 10:46:17] Re-training INFO: iter: 150125/300480  CE: 2.4647  
[05/31 10:47:32] Re-training INFO: --> epoch: 120/240  avg CE: 2.6823  lr: 0.25
[05/31 10:48:04] Re-training INFO: # of Test Samples: 50000.0
[05/31 10:48:04] Re-training INFO: Top-1/-5 acc: 60.75 / 83.97
[05/31 10:48:04] Re-training INFO: Top-1/-5 acc: 39.25 / 16.03
[05/31 10:48:04] Re-training INFO: 

[05/31 10:48:27] Re-training INFO: iter: 150250/300480  CE: 2.7807  
[05/31 10:49:51] Re-training INFO: iter: 150375/300480  CE: 3.0292  
[05/31 10:51:15] Re-training INFO: iter: 150500/300480  CE: 2.4077  
[05/31 10:52:38] Re-training INFO: iter: 150625/300480  CE: 2.6392  
[05/31 10:54:02] Re-training INFO: iter: 150750/300480  CE: 2.9197  
[05/31 10:55:26] Re-training INFO: iter: 150875/300480  CE: 2.7457  
[05/31 10:56:50] Re-training INFO: iter: 151000/300480  CE: 2.7835  
[05/31 10:58:15] Re-training INFO: iter: 151125/300480  CE: 2.5828  
[05/31 10:59:39] Re-training INFO: iter: 151250/300480  CE: 2.6579  
[05/31 11:01:02] Re-training INFO: iter: 151375/300480  CE: 2.8975  
[05/31 11:02:19] Re-training INFO: --> epoch: 121/240  avg CE: 2.6790  lr: 0.24672760110716394
[05/31 11:02:40] Re-training INFO: iter: 151500/300480  CE: 2.5050  
[05/31 11:04:05] Re-training INFO: iter: 151625/300480  CE: 2.3215  
[05/31 11:05:29] Re-training INFO: iter: 151750/300480  CE: 2.7305  
[05/31 11:06:52] Re-training INFO: iter: 151875/300480  CE: 2.7613  
[05/31 11:08:15] Re-training INFO: iter: 152000/300480  CE: 2.5455  
[05/31 11:09:39] Re-training INFO: iter: 152125/300480  CE: 2.7751  
[05/31 11:11:04] Re-training INFO: iter: 152250/300480  CE: 2.4003  
[05/31 11:12:26] Re-training INFO: iter: 152375/300480  CE: 2.7580  
[05/31 11:13:50] Re-training INFO: iter: 152500/300480  CE: 2.7351  
[05/31 11:15:14] Re-training INFO: iter: 152625/300480  CE: 2.5058  
[05/31 11:16:32] Re-training INFO: --> epoch: 122/240  avg CE: 2.6707  lr: 0.2434557629230317
[05/31 11:16:53] Re-training INFO: iter: 152750/300480  CE: 2.5317  
[05/31 11:18:16] Re-training INFO: iter: 152875/300480  CE: 2.4911  
[05/31 11:19:40] Re-training INFO: iter: 153000/300480  CE: 2.5668  
[05/31 11:21:03] Re-training INFO: iter: 153125/300480  CE: 2.3357  
[05/31 11:22:27] Re-training INFO: iter: 153250/300480  CE: 2.7057  
[05/31 11:23:51] Re-training INFO: iter: 153375/300480  CE: 2.6745  
[05/31 11:25:15] Re-training INFO: iter: 153500/300480  CE: 2.4467  
[05/31 11:26:38] Re-training INFO: iter: 153625/300480  CE: 2.6854  
[05/31 11:28:01] Re-training INFO: iter: 153750/300480  CE: 2.9485  
[05/31 11:29:26] Re-training INFO: iter: 153875/300480  CE: 2.7529  
[05/31 11:30:44] Re-training INFO: --> epoch: 123/240  avg CE: 2.6682  lr: 0.24018504606023286
[05/31 11:31:03] Re-training INFO: iter: 154000/300480  CE: 2.6844  
[05/31 11:32:27] Re-training INFO: iter: 154125/300480  CE: 2.6790  
[05/31 11:33:52] Re-training INFO: iter: 154250/300480  CE: 2.6805  
[05/31 11:35:16] Re-training INFO: iter: 154375/300480  CE: 2.8168  
[05/31 11:36:39] Re-training INFO: iter: 154500/300480  CE: 2.5715  
[05/31 11:38:03] Re-training INFO: iter: 154625/300480  CE: 2.6978  
[05/31 11:39:26] Re-training INFO: iter: 154750/300480  CE: 2.6950  
[05/31 11:40:51] Re-training INFO: iter: 154875/300480  CE: 2.4925  
[05/31 11:42:15] Re-training INFO: iter: 155000/300480  CE: 2.7771  
[05/31 11:43:38] Re-training INFO: iter: 155125/300480  CE: 2.6208  
[05/31 11:44:58] Re-training INFO: --> epoch: 124/240  avg CE: 2.6717  lr: 0.2369160109392641
[05/31 11:45:16] Re-training INFO: iter: 155250/300480  CE: 2.7368  
[05/31 11:46:41] Re-training INFO: iter: 155375/300480  CE: 2.6182  
[05/31 11:48:05] Re-training INFO: iter: 155500/300480  CE: 2.5549  
[05/31 11:49:29] Re-training INFO: iter: 155625/300480  CE: 2.9042  
[05/31 11:50:53] Re-training INFO: iter: 155750/300480  CE: 2.7767  
[05/31 11:52:17] Re-training INFO: iter: 155875/300480  CE: 2.6523  
[05/31 11:53:40] Re-training INFO: iter: 156000/300480  CE: 2.5089  
[05/31 11:55:04] Re-training INFO: iter: 156125/300480  CE: 2.4330  
[05/31 11:56:28] Re-training INFO: iter: 156250/300480  CE: 2.7908  
[05/31 11:57:52] Re-training INFO: iter: 156375/300480  CE: 2.8213  
[05/31 11:59:14] Re-training INFO: iter: 156500/300480  CE: 2.8664  
[05/31 11:59:14] Re-training INFO: --> epoch: 125/240  avg CE: 2.6581  lr: 0.23364921769246422
[05/31 12:00:56] Re-training INFO: iter: 156625/300480  CE: 2.5852  
[05/31 12:02:19] Re-training INFO: iter: 156750/300480  CE: 2.5052  
[05/31 12:03:42] Re-training INFO: iter: 156875/300480  CE: 2.7739  
[05/31 12:05:06] Re-training INFO: iter: 157000/300480  CE: 2.4654  
[05/31 12:06:30] Re-training INFO: iter: 157125/300480  CE: 2.7732  
[05/31 12:07:53] Re-training INFO: iter: 157250/300480  CE: 2.7401  
[05/31 12:09:17] Re-training INFO: iter: 157375/300480  CE: 2.7746  
[05/31 12:10:40] Re-training INFO: iter: 157500/300480  CE: 2.8277  
[05/31 12:12:03] Re-training INFO: iter: 157625/300480  CE: 2.8899  
[05/31 12:13:26] Re-training INFO: iter: 157750/300480  CE: 2.5916  
[05/31 12:13:27] Re-training INFO: --> epoch: 126/240  avg CE: 2.6577  lr: 0.2303852260680388
[05/31 12:15:07] Re-training INFO: iter: 157875/300480  CE: 2.3190  
[05/31 12:16:31] Re-training INFO: iter: 158000/300480  CE: 2.4868  
[05/31 12:17:56] Re-training INFO: iter: 158125/300480  CE: 2.6420  
[05/31 12:19:19] Re-training INFO: iter: 158250/300480  CE: 2.7474  
[05/31 12:20:43] Re-training INFO: iter: 158375/300480  CE: 2.8058  
[05/31 12:22:09] Re-training INFO: iter: 158500/300480  CE: 2.8333  
[05/31 12:23:32] Re-training INFO: iter: 158625/300480  CE: 2.6294  
[05/31 12:24:57] Re-training INFO: iter: 158750/300480  CE: 2.8456  
[05/31 12:26:21] Re-training INFO: iter: 158875/300480  CE: 2.5542  
[05/31 12:27:45] Re-training INFO: iter: 159000/300480  CE: 2.8126  
[05/31 12:27:47] Re-training INFO: --> epoch: 127/240  avg CE: 2.6563  lr: 0.22712459533414942
[05/31 12:29:26] Re-training INFO: iter: 159125/300480  CE: 2.6775  
[05/31 12:30:49] Re-training INFO: iter: 159250/300480  CE: 2.7999  
[05/31 12:32:13] Re-training INFO: iter: 159375/300480  CE: 2.5757  
[05/31 12:33:37] Re-training INFO: iter: 159500/300480  CE: 2.7553  
[05/31 12:35:01] Re-training INFO: iter: 159625/300480  CE: 2.6381  
[05/31 12:36:25] Re-training INFO: iter: 159750/300480  CE: 2.4412  
[05/31 12:37:49] Re-training INFO: iter: 159875/300480  CE: 2.3864  
[05/31 12:39:13] Re-training INFO: iter: 160000/300480  CE: 2.8411  
[05/31 12:40:38] Re-training INFO: iter: 160125/300480  CE: 3.0532  
[05/31 12:42:01] Re-training INFO: iter: 160250/300480  CE: 2.4060  
[05/31 12:42:04] Re-training INFO: --> epoch: 128/240  avg CE: 2.6502  lr: 0.22386788418308667
[05/31 12:43:43] Re-training INFO: iter: 160375/300480  CE: 2.5539  
[05/31 12:45:07] Re-training INFO: iter: 160500/300480  CE: 2.5505  
[05/31 12:46:32] Re-training INFO: iter: 160625/300480  CE: 2.7748  
[05/31 12:47:56] Re-training INFO: iter: 160750/300480  CE: 2.5377  
[05/31 12:49:19] Re-training INFO: iter: 160875/300480  CE: 2.8006  
[05/31 12:50:42] Re-training INFO: iter: 161000/300480  CE: 2.6581  
[05/31 12:52:06] Re-training INFO: iter: 161125/300480  CE: 2.5738  
[05/31 12:53:29] Re-training INFO: iter: 161250/300480  CE: 2.5425  
[05/31 12:54:55] Re-training INFO: iter: 161375/300480  CE: 2.9047  
[05/31 12:56:18] Re-training INFO: iter: 161500/300480  CE: 2.6824  
[05/31 12:56:21] Re-training INFO: --> epoch: 129/240  avg CE: 2.6445  lr: 0.22061565063554062
[05/31 12:57:57] Re-training INFO: iter: 161625/300480  CE: 2.6728  
[05/31 12:59:20] Re-training INFO: iter: 161750/300480  CE: 2.5185  
[05/31 13:00:44] Re-training INFO: iter: 161875/300480  CE: 2.6242  
[05/31 13:02:08] Re-training INFO: iter: 162000/300480  CE: 2.5840  
[05/31 13:03:31] Re-training INFO: iter: 162125/300480  CE: 2.5977  
[05/31 13:04:54] Re-training INFO: iter: 162250/300480  CE: 2.6830  
[05/31 13:06:18] Re-training INFO: iter: 162375/300480  CE: 2.4378  
[05/31 13:07:41] Re-training INFO: iter: 162500/300480  CE: 2.4566  
[05/31 13:09:06] Re-training INFO: iter: 162625/300480  CE: 2.9056  
[05/31 13:10:29] Re-training INFO: iter: 162750/300480  CE: 2.5321  
[05/31 13:10:34] Re-training INFO: --> epoch: 130/240  avg CE: 2.6468  lr: 0.2173684519449871
[05/31 13:12:07] Re-training INFO: iter: 162875/300480  CE: 2.5997  
[05/31 13:13:31] Re-training INFO: iter: 163000/300480  CE: 2.5894  
[05/31 13:14:54] Re-training INFO: iter: 163125/300480  CE: 2.6653  
[05/31 13:16:18] Re-training INFO: iter: 163250/300480  CE: 2.8080  
[05/31 13:17:41] Re-training INFO: iter: 163375/300480  CE: 2.6903  
[05/31 13:19:04] Re-training INFO: iter: 163500/300480  CE: 2.4959  
[05/31 13:20:30] Re-training INFO: iter: 163625/300480  CE: 2.8456  
[05/31 13:21:54] Re-training INFO: iter: 163750/300480  CE: 2.4468  
[05/31 13:23:17] Re-training INFO: iter: 163875/300480  CE: 2.7807  
[05/31 13:24:42] Re-training INFO: iter: 164000/300480  CE: 2.4605  
[05/31 13:24:48] Re-training INFO: --> epoch: 131/240  avg CE: 2.6361  lr: 0.2141268445022052
[05/31 13:26:21] Re-training INFO: iter: 164125/300480  CE: 2.8427  
[05/31 13:27:45] Re-training INFO: iter: 164250/300480  CE: 2.6460  
[05/31 13:29:08] Re-training INFO: iter: 164375/300480  CE: 2.4959  
[05/31 13:30:33] Re-training INFO: iter: 164500/300480  CE: 2.8420  
[05/31 13:31:57] Re-training INFO: iter: 164625/300480  CE: 2.8050  
[05/31 13:33:22] Re-training INFO: iter: 164750/300480  CE: 2.6978  
[05/31 13:34:44] Re-training INFO: iter: 164875/300480  CE: 2.7130  
[05/31 13:36:07] Re-training INFO: iter: 165000/300480  CE: 2.4373  
[05/31 13:37:32] Re-training INFO: iter: 165125/300480  CE: 2.8242  
[05/31 13:38:57] Re-training INFO: iter: 165250/300480  CE: 2.6864  
[05/31 13:39:04] Re-training INFO: --> epoch: 132/240  avg CE: 2.6259  lr: 0.2108913837399423
[05/31 13:40:36] Re-training INFO: iter: 165375/300480  CE: 2.3753  
[05/31 13:41:59] Re-training INFO: iter: 165500/300480  CE: 2.4909  
[05/31 13:43:22] Re-training INFO: iter: 165625/300480  CE: 2.7935  
[05/31 13:44:45] Re-training INFO: iter: 165750/300480  CE: 2.6438  
[05/31 13:46:09] Re-training INFO: iter: 165875/300480  CE: 2.5019  
[05/31 13:47:33] Re-training INFO: iter: 166000/300480  CE: 2.8390  
[05/31 13:48:59] Re-training INFO: iter: 166125/300480  CE: 2.4818  
[05/31 13:50:22] Re-training INFO: iter: 166250/300480  CE: 2.7902  
[05/31 13:51:45] Re-training INFO: iter: 166375/300480  CE: 2.2758  
[05/31 13:53:09] Re-training INFO: iter: 166500/300480  CE: 2.5722  
[05/31 13:53:18] Re-training INFO: --> epoch: 133/240  avg CE: 2.6323  lr: 0.20766262403774385
[05/31 13:54:47] Re-training INFO: iter: 166625/300480  CE: 2.7342  
[05/31 13:56:11] Re-training INFO: iter: 166750/300480  CE: 2.8157  
[05/31 13:57:34] Re-training INFO: iter: 166875/300480  CE: 2.5285  
[05/31 13:58:59] Re-training INFO: iter: 167000/300480  CE: 2.3355  
[05/31 14:00:22] Re-training INFO: iter: 167125/300480  CE: 2.8981  
[05/31 14:01:45] Re-training INFO: iter: 167250/300480  CE: 2.4411  
[05/31 14:03:10] Re-training INFO: iter: 167375/300480  CE: 2.5525  
[05/31 14:04:34] Re-training INFO: iter: 167500/300480  CE: 2.8005  
[05/31 14:05:58] Re-training INFO: iter: 167625/300480  CE: 2.6359  
[05/31 14:07:22] Re-training INFO: iter: 167750/300480  CE: 2.8795  
[05/31 14:07:33] Re-training INFO: --> epoch: 134/240  avg CE: 2.6206  lr: 0.20444111862696318
[05/31 14:09:01] Re-training INFO: iter: 167875/300480  CE: 2.9321  
[05/31 14:10:24] Re-training INFO: iter: 168000/300480  CE: 2.8522  
[05/31 14:11:49] Re-training INFO: iter: 168125/300480  CE: 2.5372  
[05/31 14:13:12] Re-training INFO: iter: 168250/300480  CE: 2.7733  
[05/31 14:14:36] Re-training INFO: iter: 168375/300480  CE: 2.6428  
[05/31 14:16:01] Re-training INFO: iter: 168500/300480  CE: 2.5711  
[05/31 14:17:24] Re-training INFO: iter: 168625/300480  CE: 2.6041  
[05/31 14:18:48] Re-training INFO: iter: 168750/300480  CE: 2.3375  
[05/31 14:20:12] Re-training INFO: iter: 168875/300480  CE: 2.9724  
[05/31 14:21:35] Re-training INFO: iter: 169000/300480  CE: 2.7498  
[05/31 14:21:46] Re-training INFO: --> epoch: 135/240  avg CE: 2.6189  lr: 0.20122741949596795
[05/31 14:23:14] Re-training INFO: iter: 169125/300480  CE: 2.7817  
[05/31 14:24:38] Re-training INFO: iter: 169250/300480  CE: 2.3865  
[05/31 14:26:02] Re-training INFO: iter: 169375/300480  CE: 2.5327  
[05/31 14:27:27] Re-training INFO: iter: 169500/300480  CE: 2.7510  
[05/31 14:28:51] Re-training INFO: iter: 169625/300480  CE: 2.7157  
[05/31 14:30:15] Re-training INFO: iter: 169750/300480  CE: 2.7925  
[05/31 14:31:39] Re-training INFO: iter: 169875/300480  CE: 2.5532  
[05/31 14:33:05] Re-training INFO: iter: 170000/300480  CE: 2.7403  
[05/31 14:34:29] Re-training INFO: iter: 170125/300480  CE: 2.3556  
[05/31 14:35:53] Re-training INFO: iter: 170250/300480  CE: 2.6471  
[05/31 14:36:06] Re-training INFO: --> epoch: 136/240  avg CE: 2.6150  lr: 0.1980220772955602
[05/31 14:37:33] Re-training INFO: iter: 170375/300480  CE: 2.4481  
[05/31 14:38:59] Re-training INFO: iter: 170500/300480  CE: 2.3820  
[05/31 14:40:24] Re-training INFO: iter: 170625/300480  CE: 2.5928  
[05/31 14:41:48] Re-training INFO: iter: 170750/300480  CE: 2.6523  
[05/31 14:43:13] Re-training INFO: iter: 170875/300480  CE: 2.4959  
[05/31 14:44:37] Re-training INFO: iter: 171000/300480  CE: 2.9118  
[05/31 14:46:04] Re-training INFO: iter: 171125/300480  CE: 2.6662  
[05/31 14:47:28] Re-training INFO: iter: 171250/300480  CE: 2.7089  
[05/31 14:48:53] Re-training INFO: iter: 171375/300480  CE: 2.7266  
[05/31 14:50:17] Re-training INFO: iter: 171500/300480  CE: 2.9024  
[05/31 14:50:32] Re-training INFO: --> epoch: 137/240  avg CE: 2.6116  lr: 0.19482564124462476
[05/31 14:51:56] Re-training INFO: iter: 171625/300480  CE: 2.7699  
[05/31 14:53:20] Re-training INFO: iter: 171750/300480  CE: 2.9009  
[05/31 14:54:44] Re-training INFO: iter: 171875/300480  CE: 2.6813  
[05/31 14:56:09] Re-training INFO: iter: 172000/300480  CE: 2.5864  
[05/31 14:57:32] Re-training INFO: iter: 172125/300480  CE: 3.0820  
[05/31 14:58:57] Re-training INFO: iter: 172250/300480  CE: 2.5874  
[05/31 15:00:21] Re-training INFO: iter: 172375/300480  CE: 2.7448  
[05/31 15:01:45] Re-training INFO: iter: 172500/300480  CE: 2.9203  
[05/31 15:03:08] Re-training INFO: iter: 172625/300480  CE: 2.4994  
[05/31 15:04:32] Re-training INFO: iter: 172750/300480  CE: 2.6115  
[05/31 15:04:48] Re-training INFO: --> epoch: 138/240  avg CE: 2.6098  lr: 0.19163865903602362
[05/31 15:06:13] Re-training INFO: iter: 172875/300480  CE: 2.7714  
[05/31 15:07:36] Re-training INFO: iter: 173000/300480  CE: 2.4947  
[05/31 15:09:00] Re-training INFO: iter: 173125/300480  CE: 2.5398  
[05/31 15:10:24] Re-training INFO: iter: 173250/300480  CE: 2.5108  
[05/31 15:11:47] Re-training INFO: iter: 173375/300480  CE: 2.7286  
[05/31 15:13:10] Re-training INFO: iter: 173500/300480  CE: 2.6628  
[05/31 15:14:35] Re-training INFO: iter: 173625/300480  CE: 2.6208  
[05/31 15:15:58] Re-training INFO: iter: 173750/300480  CE: 2.6371  
[05/31 15:17:22] Re-training INFO: iter: 173875/300480  CE: 2.9037  
[05/31 15:18:46] Re-training INFO: iter: 174000/300480  CE: 2.6403  
[05/31 15:19:02] Re-training INFO: --> epoch: 139/240  avg CE: 2.5974  lr: 0.18846167674275174
[05/31 15:20:28] Re-training INFO: iter: 174125/300480  CE: 2.6293  
[05/31 15:21:56] Re-training INFO: iter: 174250/300480  CE: 2.7541  
[05/31 15:23:23] Re-training INFO: iter: 174375/300480  CE: 2.4649  
[05/31 15:24:48] Re-training INFO: iter: 174500/300480  CE: 2.5805  
[05/31 15:26:13] Re-training INFO: iter: 174625/300480  CE: 2.7663  
[05/31 15:27:38] Re-training INFO: iter: 174750/300480  CE: 2.5001  
[05/31 15:29:04] Re-training INFO: iter: 174875/300480  CE: 2.5431  
[05/31 15:30:28] Re-training INFO: iter: 175000/300480  CE: 2.9617  
[05/31 15:31:51] Re-training INFO: iter: 175125/300480  CE: 2.4723  
[05/31 15:33:15] Re-training INFO: iter: 175250/300480  CE: 2.7667  
[05/31 15:33:33] Re-training INFO: --> epoch: 140/240  avg CE: 2.5962  lr: 0.1852952387243698
[05/31 15:34:05] Re-training INFO: # of Test Samples: 50000.0
[05/31 15:34:05] Re-training INFO: Top-1/-5 acc: 65.88 / 87.36
[05/31 15:34:05] Re-training INFO: Top-1/-5 acc: 34.12 / 12.64
[05/31 15:34:05] Re-training INFO: 

[05/31 15:35:28] Re-training INFO: iter: 175375/300480  CE: 2.6976  
[05/31 15:36:50] Re-training INFO: iter: 175500/300480  CE: 2.5042  
[05/31 15:38:15] Re-training INFO: iter: 175625/300480  CE: 2.6093  
[05/31 15:39:38] Re-training INFO: iter: 175750/300480  CE: 2.7830  
[05/31 15:41:02] Re-training INFO: iter: 175875/300480  CE: 2.5383  
[05/31 15:42:25] Re-training INFO: iter: 176000/300480  CE: 2.6221  
[05/31 15:43:50] Re-training INFO: iter: 176125/300480  CE: 2.6112  
[05/31 15:45:13] Re-training INFO: iter: 176250/300480  CE: 2.7302  
[05/31 15:46:37] Re-training INFO: iter: 176375/300480  CE: 2.6419  
[05/31 15:48:02] Re-training INFO: iter: 176500/300480  CE: 2.6306  
[05/31 15:48:21] Re-training INFO: --> epoch: 141/240  avg CE: 2.5964  lr: 0.18213988753373145
[05/31 15:49:41] Re-training INFO: iter: 176625/300480  CE: 2.5983  
[05/31 15:51:04] Re-training INFO: iter: 176750/300480  CE: 2.5428  
[05/31 15:52:28] Re-training INFO: iter: 176875/300480  CE: 2.7266  
[05/31 15:53:51] Re-training INFO: iter: 177000/300480  CE: 2.5870  
[05/31 15:55:16] Re-training INFO: iter: 177125/300480  CE: 2.4951  
[05/31 15:56:38] Re-training INFO: iter: 177250/300480  CE: 2.6010  
[05/31 15:58:02] Re-training INFO: iter: 177375/300480  CE: 2.6671  
[05/31 15:59:25] Re-training INFO: iter: 177500/300480  CE: 2.6845  
[05/31 16:00:48] Re-training INFO: iter: 177625/300480  CE: 2.8374  
[05/31 16:02:12] Re-training INFO: iter: 177750/300480  CE: 2.6444  
[05/31 16:02:33] Re-training INFO: --> epoch: 142/240  avg CE: 2.5901  lr: 0.17899616382401934
[05/31 16:03:52] Re-training INFO: iter: 177875/300480  CE: 2.4264  
[05/31 16:05:16] Re-training INFO: iter: 178000/300480  CE: 2.6245  
[05/31 16:06:40] Re-training INFO: iter: 178125/300480  CE: 2.3776  
[05/31 16:08:04] Re-training INFO: iter: 178250/300480  CE: 2.5095  
[05/31 16:09:27] Re-training INFO: iter: 178375/300480  CE: 2.4439  
[05/31 16:10:51] Re-training INFO: iter: 178500/300480  CE: 3.1584  
[05/31 16:12:15] Re-training INFO: iter: 178625/300480  CE: 2.4811  
[05/31 16:13:39] Re-training INFO: iter: 178750/300480  CE: 2.7079  
[05/31 16:15:03] Re-training INFO: iter: 178875/300480  CE: 2.7082  
[05/31 16:16:26] Re-training INFO: iter: 179000/300480  CE: 2.7324  
[05/31 16:16:49] Re-training INFO: --> epoch: 143/240  avg CE: 2.5908  lr: 0.17586460625610728
[05/31 16:18:05] Re-training INFO: iter: 179125/300480  CE: 2.4537  
[05/31 16:19:30] Re-training INFO: iter: 179250/300480  CE: 2.4295  
[05/31 16:20:54] Re-training INFO: iter: 179375/300480  CE: 2.6466  
[05/31 16:22:16] Re-training INFO: iter: 179500/300480  CE: 2.5149  
[05/31 16:23:40] Re-training INFO: iter: 179625/300480  CE: 2.2705  
[05/31 16:25:05] Re-training INFO: iter: 179750/300480  CE: 2.3824  
[05/31 16:26:30] Re-training INFO: iter: 179875/300480  CE: 2.6866  
[05/31 16:27:52] Re-training INFO: iter: 180000/300480  CE: 2.6279  
[05/31 16:29:17] Re-training INFO: iter: 180125/300480  CE: 2.4690  
[05/31 16:30:40] Re-training INFO: iter: 180250/300480  CE: 2.6245  
[05/31 16:31:04] Re-training INFO: --> epoch: 144/240  avg CE: 2.5835  lr: 0.17274575140626322
[05/31 16:32:19] Re-training INFO: iter: 180375/300480  CE: 2.7899  
[05/31 16:33:43] Re-training INFO: iter: 180500/300480  CE: 2.5370  
[05/31 16:35:06] Re-training INFO: iter: 180625/300480  CE: 2.4721  
[05/31 16:36:30] Re-training INFO: iter: 180750/300480  CE: 2.6214  
[05/31 16:37:54] Re-training INFO: iter: 180875/300480  CE: 2.4692  
[05/31 16:39:17] Re-training INFO: iter: 181000/300480  CE: 2.8013  
[05/31 16:40:41] Re-training INFO: iter: 181125/300480  CE: 2.3008  
[05/31 16:42:05] Re-training INFO: iter: 181250/300480  CE: 2.4639  
[05/31 16:43:29] Re-training INFO: iter: 181375/300480  CE: 2.7907  
[05/31 16:44:52] Re-training INFO: iter: 181500/300480  CE: 2.6380  
[05/31 16:45:18] Re-training INFO: --> epoch: 145/240  avg CE: 2.5754  lr: 0.16964013367420966
[05/31 16:46:31] Re-training INFO: iter: 181625/300480  CE: 2.5078  
[05/31 16:47:55] Re-training INFO: iter: 181750/300480  CE: 2.5240  
[05/31 16:49:20] Re-training INFO: iter: 181875/300480  CE: 2.4424  
[05/31 16:50:44] Re-training INFO: iter: 182000/300480  CE: 2.5784  
[05/31 16:52:09] Re-training INFO: iter: 182125/300480  CE: 2.2940  
[05/31 16:53:33] Re-training INFO: iter: 182250/300480  CE: 2.5326  
[05/31 16:54:57] Re-training INFO: iter: 182375/300480  CE: 2.5636  
[05/31 16:56:21] Re-training INFO: iter: 182500/300480  CE: 2.3012  
[05/31 16:57:47] Re-training INFO: iter: 182625/300480  CE: 2.7697  
[05/31 16:59:10] Re-training INFO: iter: 182750/300480  CE: 2.5870  
[05/31 16:59:36] Re-training INFO: --> epoch: 146/240  avg CE: 2.5669  lr: 0.16654828519155723
[05/31 17:00:48] Re-training INFO: iter: 182875/300480  CE: 2.5681  
[05/31 17:02:12] Re-training INFO: iter: 183000/300480  CE: 2.3431  
[05/31 17:03:36] Re-training INFO: iter: 183125/300480  CE: 2.6220  
[05/31 17:05:00] Re-training INFO: iter: 183250/300480  CE: 2.4612  
[05/31 17:06:25] Re-training INFO: iter: 183375/300480  CE: 2.6143  
[05/31 17:07:49] Re-training INFO: iter: 183500/300480  CE: 2.6769  
[05/31 17:09:13] Re-training INFO: iter: 183625/300480  CE: 2.4899  
[05/31 17:10:37] Re-training INFO: iter: 183750/300480  CE: 2.7928  
[05/31 17:12:02] Re-training INFO: iter: 183875/300480  CE: 2.8273  
[05/31 17:13:26] Re-training INFO: iter: 184000/300480  CE: 2.4911  
[05/31 17:13:55] Re-training INFO: --> epoch: 147/240  avg CE: 2.5531  lr: 0.16347073573062676
[05/31 17:15:06] Re-training INFO: iter: 184125/300480  CE: 2.7795  
[05/31 17:16:30] Re-training INFO: iter: 184250/300480  CE: 2.5296  
[05/31 17:17:53] Re-training INFO: iter: 184375/300480  CE: 2.5189  
[05/31 17:19:17] Re-training INFO: iter: 184500/300480  CE: 2.7280  
[05/31 17:20:41] Re-training INFO: iter: 184625/300480  CE: 2.4855  
[05/31 17:22:04] Re-training INFO: iter: 184750/300480  CE: 2.5857  
[05/31 17:23:28] Re-training INFO: iter: 184875/300480  CE: 2.5777  
[05/31 17:24:52] Re-training INFO: iter: 185000/300480  CE: 2.2849  
[05/31 17:26:15] Re-training INFO: iter: 185125/300480  CE: 2.4199  
[05/31 17:27:40] Re-training INFO: iter: 185250/300480  CE: 2.5020  
[05/31 17:28:08] Re-training INFO: --> epoch: 148/240  avg CE: 2.5503  lr: 0.16040801261367493
[05/31 17:29:19] Re-training INFO: iter: 185375/300480  CE: 2.5095  
[05/31 17:30:42] Re-training INFO: iter: 185500/300480  CE: 2.3080  
[05/31 17:32:06] Re-training INFO: iter: 185625/300480  CE: 2.7992  
[05/31 17:33:31] Re-training INFO: iter: 185750/300480  CE: 2.5767  
[05/31 17:34:54] Re-training INFO: iter: 185875/300480  CE: 2.5019  
[05/31 17:36:18] Re-training INFO: iter: 186000/300480  CE: 2.3191  
[05/31 17:37:41] Re-training INFO: iter: 186125/300480  CE: 2.5758  
[05/31 17:39:04] Re-training INFO: iter: 186250/300480  CE: 2.5207  
[05/31 17:40:28] Re-training INFO: iter: 186375/300480  CE: 2.2892  
[05/31 17:41:51] Re-training INFO: iter: 186500/300480  CE: 2.3654  
[05/31 17:42:22] Re-training INFO: --> epoch: 149/240  avg CE: 2.5578  lr: 0.15736064062254096
[05/31 17:43:30] Re-training INFO: iter: 186625/300480  CE: 2.4582  
[05/31 17:44:53] Re-training INFO: iter: 186750/300480  CE: 2.4639  
[05/31 17:46:16] Re-training INFO: iter: 186875/300480  CE: 2.4108  
[05/31 17:47:40] Re-training INFO: iter: 187000/300480  CE: 2.3931  
[05/31 17:49:02] Re-training INFO: iter: 187125/300480  CE: 2.7021  
[05/31 17:50:26] Re-training INFO: iter: 187250/300480  CE: 2.8929  
[05/31 17:51:50] Re-training INFO: iter: 187375/300480  CE: 2.7075  
[05/31 17:53:15] Re-training INFO: iter: 187500/300480  CE: 2.6796  
[05/31 17:54:38] Re-training INFO: iter: 187625/300480  CE: 2.8346  
[05/31 17:56:01] Re-training INFO: iter: 187750/300480  CE: 2.5982  
[05/31 17:56:33] Re-training INFO: --> epoch: 150/240  avg CE: 2.5521  lr: 0.15432914190872757
[05/31 17:57:40] Re-training INFO: iter: 187875/300480  CE: 2.6551  
[05/31 17:59:05] Re-training INFO: iter: 188000/300480  CE: 2.4379  
[05/31 18:00:29] Re-training INFO: iter: 188125/300480  CE: 2.5075  
[05/31 18:01:51] Re-training INFO: iter: 188250/300480  CE: 2.2685  
[05/31 18:03:16] Re-training INFO: iter: 188375/300480  CE: 2.5908  
[05/31 18:04:39] Re-training INFO: iter: 188500/300480  CE: 2.6111  
[05/31 18:06:03] Re-training INFO: iter: 188625/300480  CE: 2.4723  
[05/31 18:07:26] Re-training INFO: iter: 188750/300480  CE: 2.4340  
[05/31 18:08:50] Re-training INFO: iter: 188875/300480  CE: 2.1818  
[05/31 18:10:13] Re-training INFO: iter: 189000/300480  CE: 2.3841  
[05/31 18:10:46] Re-training INFO: --> epoch: 151/240  avg CE: 2.5498  lr: 0.15131403590393322
[05/31 18:11:51] Re-training INFO: iter: 189125/300480  CE: 2.1493  
[05/31 18:13:14] Re-training INFO: iter: 189250/300480  CE: 2.6507  
[05/31 18:14:38] Re-training INFO: iter: 189375/300480  CE: 2.4754  
[05/31 18:16:01] Re-training INFO: iter: 189500/300480  CE: 2.7180  
[05/31 18:17:25] Re-training INFO: iter: 189625/300480  CE: 2.3981  
[05/31 18:18:49] Re-training INFO: iter: 189750/300480  CE: 2.5722  
[05/31 18:20:12] Re-training INFO: iter: 189875/300480  CE: 2.4861  
[05/31 18:21:35] Re-training INFO: iter: 190000/300480  CE: 2.7305  
[05/31 18:22:59] Re-training INFO: iter: 190125/300480  CE: 2.3760  
[05/31 18:24:23] Re-training INFO: iter: 190250/300480  CE: 2.8270  
[05/31 18:24:57] Re-training INFO: --> epoch: 152/240  avg CE: 2.5392  lr: 0.14831583923105
[05/31 18:26:02] Re-training INFO: iter: 190375/300480  CE: 2.4768  
[05/31 18:27:26] Re-training INFO: iter: 190500/300480  CE: 2.6394  
[05/31 18:28:50] Re-training INFO: iter: 190625/300480  CE: 2.6759  
[05/31 18:30:14] Re-training INFO: iter: 190750/300480  CE: 2.3276  
[05/31 18:31:37] Re-training INFO: iter: 190875/300480  CE: 2.4651  
[05/31 18:33:02] Re-training INFO: iter: 191000/300480  CE: 2.3698  
[05/31 18:34:25] Re-training INFO: iter: 191125/300480  CE: 2.4832  
[05/31 18:35:50] Re-training INFO: iter: 191250/300480  CE: 2.4937  
[05/31 18:37:13] Re-training INFO: iter: 191375/300480  CE: 2.6798  
[05/31 18:38:37] Re-training INFO: iter: 191500/300480  CE: 2.6123  
[05/31 18:39:13] Re-training INFO: --> epoch: 153/240  avg CE: 2.5326  lr: 0.14533506561564294
[05/31 18:40:16] Re-training INFO: iter: 191625/300480  CE: 2.5456  
[05/31 18:41:40] Re-training INFO: iter: 191750/300480  CE: 2.6175  
[05/31 18:43:05] Re-training INFO: iter: 191875/300480  CE: 2.4118  
[05/31 18:44:27] Re-training INFO: iter: 192000/300480  CE: 2.5516  
[05/31 18:45:51] Re-training INFO: iter: 192125/300480  CE: 2.6265  
[05/31 18:47:15] Re-training INFO: iter: 192250/300480  CE: 2.4858  
[05/31 18:48:38] Re-training INFO: iter: 192375/300480  CE: 2.7349  
[05/31 18:50:04] Re-training INFO: iter: 192500/300480  CE: 2.5334  
[05/31 18:51:28] Re-training INFO: iter: 192625/300480  CE: 2.7589  
[05/31 18:52:51] Re-training INFO: iter: 192750/300480  CE: 2.6994  
[05/31 18:53:29] Re-training INFO: --> epoch: 154/240  avg CE: 2.5383  lr: 0.14237222579792616
[05/31 18:54:30] Re-training INFO: iter: 192875/300480  CE: 2.5156  
[05/31 18:55:55] Re-training INFO: iter: 193000/300480  CE: 2.4252  
[05/31 18:57:20] Re-training INFO: iter: 193125/300480  CE: 2.3304  
[05/31 18:58:46] Re-training INFO: iter: 193250/300480  CE: 2.7586  
[05/31 19:00:10] Re-training INFO: iter: 193375/300480  CE: 2.4260  
[05/31 19:01:34] Re-training INFO: iter: 193500/300480  CE: 2.5745  
[05/31 19:02:58] Re-training INFO: iter: 193625/300480  CE: 2.6542  
[05/31 19:04:22] Re-training INFO: iter: 193750/300480  CE: 2.4622  
[05/31 19:05:47] Re-training INFO: iter: 193875/300480  CE: 2.6186  
[05/31 19:07:10] Re-training INFO: iter: 194000/300480  CE: 2.5883  
[05/31 19:07:49] Re-training INFO: --> epoch: 155/240  avg CE: 2.5218  lr: 0.13942782744524973
[05/31 19:08:49] Re-training INFO: iter: 194125/300480  CE: 2.6495  
[05/31 19:10:13] Re-training INFO: iter: 194250/300480  CE: 2.5599  
[05/31 19:11:37] Re-training INFO: iter: 194375/300480  CE: 2.5879  
[05/31 19:13:01] Re-training INFO: iter: 194500/300480  CE: 2.4269  
[05/31 19:14:24] Re-training INFO: iter: 194625/300480  CE: 2.5389  
[05/31 19:15:48] Re-training INFO: iter: 194750/300480  CE: 2.5599  
[05/31 19:17:12] Re-training INFO: iter: 194875/300480  CE: 2.7330  
[05/31 19:18:35] Re-training INFO: iter: 195000/300480  CE: 2.5662  
[05/31 19:20:00] Re-training INFO: iter: 195125/300480  CE: 2.3445  
[05/31 19:21:24] Re-training INFO: iter: 195250/300480  CE: 2.6772  
[05/31 19:22:03] Re-training INFO: --> epoch: 156/240  avg CE: 2.5261  lr: 0.1365023750651133
[05/31 19:23:01] Re-training INFO: iter: 195375/300480  CE: 2.5129  
[05/31 19:24:26] Re-training INFO: iter: 195500/300480  CE: 2.7207  
[05/31 19:25:48] Re-training INFO: iter: 195625/300480  CE: 2.4667  
[05/31 19:27:13] Re-training INFO: iter: 195750/300480  CE: 2.4880  
[05/31 19:28:37] Re-training INFO: iter: 195875/300480  CE: 2.5705  
[05/31 19:30:01] Re-training INFO: iter: 196000/300480  CE: 2.5633  
[05/31 19:31:24] Re-training INFO: iter: 196125/300480  CE: 2.7395  
[05/31 19:32:47] Re-training INFO: iter: 196250/300480  CE: 2.7066  
[05/31 19:34:11] Re-training INFO: iter: 196375/300480  CE: 2.4325  
[05/31 19:35:34] Re-training INFO: iter: 196500/300480  CE: 2.4420  
[05/31 19:36:16] Re-training INFO: --> epoch: 157/240  avg CE: 2.5126  lr: 0.13359636991872215
[05/31 19:37:13] Re-training INFO: iter: 196625/300480  CE: 2.3743  
[05/31 19:38:39] Re-training INFO: iter: 196750/300480  CE: 2.4194  
[05/31 19:40:02] Re-training INFO: iter: 196875/300480  CE: 2.5032  
[05/31 19:41:27] Re-training INFO: iter: 197000/300480  CE: 2.6745  
[05/31 19:42:51] Re-training INFO: iter: 197125/300480  CE: 2.3526  
[05/31 19:44:14] Re-training INFO: iter: 197250/300480  CE: 2.4578  
[05/31 19:45:39] Re-training INFO: iter: 197375/300480  CE: 2.4584  
[05/31 19:47:03] Re-training INFO: iter: 197500/300480  CE: 2.2334  
[05/31 19:48:28] Re-training INFO: iter: 197625/300480  CE: 2.7008  
[05/31 19:49:52] Re-training INFO: iter: 197750/300480  CE: 2.5566  
[05/31 19:50:34] Re-training INFO: --> epoch: 158/240  avg CE: 2.5054  lr: 0.13071030993509797
[05/31 19:51:29] Re-training INFO: iter: 197875/300480  CE: 2.7161  
[05/31 19:52:53] Re-training INFO: iter: 198000/300480  CE: 2.3572  
[05/31 19:54:17] Re-training INFO: iter: 198125/300480  CE: 2.5348  
[05/31 19:55:40] Re-training INFO: iter: 198250/300480  CE: 2.3576  
[05/31 19:57:04] Re-training INFO: iter: 198375/300480  CE: 2.8073  
[05/31 19:58:28] Re-training INFO: iter: 198500/300480  CE: 2.1562  
[05/31 19:59:51] Re-training INFO: iter: 198625/300480  CE: 2.4064  
[05/31 20:01:14] Re-training INFO: iter: 198750/300480  CE: 2.1340  
[05/31 20:02:37] Re-training INFO: iter: 198875/300480  CE: 2.7991  
[05/31 20:04:02] Re-training INFO: iter: 199000/300480  CE: 2.6870  
[05/31 20:04:46] Re-training INFO: --> epoch: 159/240  avg CE: 2.5037  lr: 0.12784468962576134
[05/31 20:05:40] Re-training INFO: iter: 199125/300480  CE: 2.7699  
[05/31 20:07:05] Re-training INFO: iter: 199250/300480  CE: 2.4594  
[05/31 20:08:28] Re-training INFO: iter: 199375/300480  CE: 2.8071  
[05/31 20:09:53] Re-training INFO: iter: 199500/300480  CE: 2.3600  
[05/31 20:11:17] Re-training INFO: iter: 199625/300480  CE: 2.5371  
[05/31 20:12:42] Re-training INFO: iter: 199750/300480  CE: 2.3356  
[05/31 20:14:06] Re-training INFO: iter: 199875/300480  CE: 2.4866  
[05/31 20:15:29] Re-training INFO: iter: 200000/300480  CE: 2.6416  
[05/31 20:16:53] Re-training INFO: iter: 200125/300480  CE: 2.5516  
[05/31 20:18:19] Re-training INFO: iter: 200250/300480  CE: 2.4325  
[05/31 20:19:04] Re-training INFO: --> epoch: 160/240  avg CE: 2.5050  lr: 0.12500000000000006
[05/31 20:19:35] Re-training INFO: # of Test Samples: 50000.0
[05/31 20:19:35] Re-training INFO: Top-1/-5 acc: 67.66 / 88.35
[05/31 20:19:35] Re-training INFO: Top-1/-5 acc: 32.34 / 11.65
[05/31 20:19:35] Re-training INFO: 

[05/31 20:20:28] Re-training INFO: iter: 200375/300480  CE: 2.2702  
[05/31 20:21:52] Re-training INFO: iter: 200500/300480  CE: 2.4811  
[05/31 20:23:16] Re-training INFO: iter: 200625/300480  CE: 2.5349  
[05/31 20:24:40] Re-training INFO: iter: 200750/300480  CE: 2.6529  
[05/31 20:26:03] Re-training INFO: iter: 200875/300480  CE: 2.3758  
[05/31 20:27:26] Re-training INFO: iter: 201000/300480  CE: 2.4764  
[05/31 20:28:51] Re-training INFO: iter: 201125/300480  CE: 2.5597  
[05/31 20:30:13] Re-training INFO: iter: 201250/300480  CE: 2.6150  
[05/31 20:31:38] Re-training INFO: iter: 201375/300480  CE: 2.4247  
[05/31 20:33:02] Re-training INFO: iter: 201500/300480  CE: 2.5278  
[05/31 20:33:48] Re-training INFO: --> epoch: 161/240  avg CE: 2.4923  lr: 0.12217672848073691
[05/31 20:34:41] Re-training INFO: iter: 201625/300480  CE: 2.7081  
[05/31 20:36:06] Re-training INFO: iter: 201750/300480  CE: 2.6428  
[05/31 20:37:29] Re-training INFO: iter: 201875/300480  CE: 2.3490  
[05/31 20:38:52] Re-training INFO: iter: 202000/300480  CE: 2.6729  
[05/31 20:40:16] Re-training INFO: iter: 202125/300480  CE: 2.5072  
[05/31 20:41:38] Re-training INFO: iter: 202250/300480  CE: 2.3301  
[05/31 20:43:03] Re-training INFO: iter: 202375/300480  CE: 2.4835  
[05/31 20:44:26] Re-training INFO: iter: 202500/300480  CE: 2.3051  
[05/31 20:45:49] Re-training INFO: iter: 202625/300480  CE: 2.5187  
[05/31 20:47:12] Re-training INFO: iter: 202750/300480  CE: 2.2870  
[05/31 20:48:00] Re-training INFO: --> epoch: 162/240  avg CE: 2.4798  lr: 0.1193753588210128
[05/31 20:48:51] Re-training INFO: iter: 202875/300480  CE: 2.1629  
[05/31 20:50:15] Re-training INFO: iter: 203000/300480  CE: 2.8066  
[05/31 20:51:40] Re-training INFO: iter: 203125/300480  CE: 2.2736  
[05/31 20:53:05] Re-training INFO: iter: 203250/300480  CE: 2.3650  
[05/31 20:54:27] Re-training INFO: iter: 203375/300480  CE: 2.5062  
[05/31 20:55:52] Re-training INFO: iter: 203500/300480  CE: 2.4461  
[05/31 20:57:15] Re-training INFO: iter: 203625/300480  CE: 2.4037  
[05/31 20:58:39] Re-training INFO: iter: 203750/300480  CE: 2.5465  
[05/31 21:00:04] Re-training INFO: iter: 203875/300480  CE: 2.6134  
[05/31 21:01:30] Re-training INFO: iter: 204000/300480  CE: 2.7378  
[05/31 21:02:19] Re-training INFO: --> epoch: 163/240  avg CE: 2.4814  lr: 0.11659637102109713
[05/31 21:03:09] Re-training INFO: iter: 204125/300480  CE: 2.3602  
[05/31 21:04:32] Re-training INFO: iter: 204250/300480  CE: 2.4403  
[05/31 21:05:55] Re-training INFO: iter: 204375/300480  CE: 2.4889  
[05/31 21:07:19] Re-training INFO: iter: 204500/300480  CE: 2.4858  
[05/31 21:08:45] Re-training INFO: iter: 204625/300480  CE: 2.4784  
[05/31 21:10:09] Re-training INFO: iter: 204750/300480  CE: 2.3121  
[05/31 21:11:33] Re-training INFO: iter: 204875/300480  CE: 2.3451  
[05/31 21:12:57] Re-training INFO: iter: 205000/300480  CE: 2.6752  
[05/31 21:14:22] Re-training INFO: iter: 205125/300480  CE: 2.4821  
[05/31 21:15:46] Re-training INFO: iter: 205250/300480  CE: 2.4450  
[05/31 21:16:36] Re-training INFO: --> epoch: 164/240  avg CE: 2.4737  lr: 0.11384024124624323
[05/31 21:17:26] Re-training INFO: iter: 205375/300480  CE: 2.3753  
[05/31 21:18:50] Re-training INFO: iter: 205500/300480  CE: 2.4302  
[05/31 21:20:14] Re-training INFO: iter: 205625/300480  CE: 2.6013  
[05/31 21:21:39] Re-training INFO: iter: 205750/300480  CE: 2.5133  
[05/31 21:23:02] Re-training INFO: iter: 205875/300480  CE: 2.1223  
[05/31 21:24:27] Re-training INFO: iter: 206000/300480  CE: 2.2835  
[05/31 21:25:50] Re-training INFO: iter: 206125/300480  CE: 2.5171  
[05/31 21:27:14] Re-training INFO: iter: 206250/300480  CE: 2.3774  
[05/31 21:28:37] Re-training INFO: iter: 206375/300480  CE: 2.6824  
[05/31 21:30:02] Re-training INFO: iter: 206500/300480  CE: 2.2162  
[05/31 21:30:53] Re-training INFO: --> epoch: 165/240  avg CE: 2.4703  lr: 0.11110744174509951
[05/31 21:31:40] Re-training INFO: iter: 206625/300480  CE: 2.3405  
[05/31 21:33:05] Re-training INFO: iter: 206750/300480  CE: 2.3916  
[05/31 21:34:27] Re-training INFO: iter: 206875/300480  CE: 2.3211  
[05/31 21:35:52] Re-training INFO: iter: 207000/300480  CE: 2.3162  
[05/31 21:37:15] Re-training INFO: iter: 207125/300480  CE: 2.3732  
[05/31 21:38:38] Re-training INFO: iter: 207250/300480  CE: 2.4905  
[05/31 21:40:02] Re-training INFO: iter: 207375/300480  CE: 2.4795  
[05/31 21:41:25] Re-training INFO: iter: 207500/300480  CE: 2.4056  
[05/31 21:42:49] Re-training INFO: iter: 207625/300480  CE: 2.4023  
[05/31 21:44:13] Re-training INFO: iter: 207750/300480  CE: 2.4986  
[05/31 21:45:05] Re-training INFO: --> epoch: 166/240  avg CE: 2.4633  lr: 0.10839844076879185
[05/31 21:45:50] Re-training INFO: iter: 207875/300480  CE: 2.4926  
[05/31 21:47:14] Re-training INFO: iter: 208000/300480  CE: 2.4493  
[05/31 21:48:37] Re-training INFO: iter: 208125/300480  CE: 2.4252  
[05/31 21:50:01] Re-training INFO: iter: 208250/300480  CE: 2.6835  
[05/31 21:51:24] Re-training INFO: iter: 208375/300480  CE: 2.3722  
[05/31 21:52:49] Re-training INFO: iter: 208500/300480  CE: 2.5434  
[05/31 21:54:12] Re-training INFO: iter: 208625/300480  CE: 2.4377  
[05/31 21:55:37] Re-training INFO: iter: 208750/300480  CE: 2.4827  
[05/31 21:57:00] Re-training INFO: iter: 208875/300480  CE: 2.6253  
[05/31 21:58:24] Re-training INFO: iter: 209000/300480  CE: 2.3869  
[05/31 21:59:18] Re-training INFO: --> epoch: 167/240  avg CE: 2.4559  lr: 0.10571370249069162
[05/31 22:00:03] Re-training INFO: iter: 209125/300480  CE: 2.3837  
[05/31 22:01:26] Re-training INFO: iter: 209250/300480  CE: 2.5162  
[05/31 22:02:50] Re-training INFO: iter: 209375/300480  CE: 2.2466  
[05/31 22:04:13] Re-training INFO: iter: 209500/300480  CE: 2.4554  
[05/31 22:05:38] Re-training INFO: iter: 209625/300480  CE: 2.4847  
[05/31 22:07:02] Re-training INFO: iter: 209750/300480  CE: 2.3210  
[05/31 22:08:25] Re-training INFO: iter: 209875/300480  CE: 2.4797  
[05/31 22:09:48] Re-training INFO: iter: 210000/300480  CE: 2.4716  
[05/31 22:11:12] Re-training INFO: iter: 210125/300480  CE: 2.6904  
[05/31 22:12:34] Re-training INFO: iter: 210250/300480  CE: 2.3882  
[05/31 22:13:30] Re-training INFO: --> epoch: 168/240  avg CE: 2.4509  lr: 0.10305368692688174
[05/31 22:14:12] Re-training INFO: iter: 210375/300480  CE: 2.2553  
[05/31 22:15:38] Re-training INFO: iter: 210500/300480  CE: 2.2401  
[05/31 22:17:01] Re-training INFO: iter: 210625/300480  CE: 2.3631  
[05/31 22:18:25] Re-training INFO: iter: 210750/300480  CE: 2.2472  
[05/31 22:19:48] Re-training INFO: iter: 210875/300480  CE: 2.1624  
[05/31 22:21:11] Re-training INFO: iter: 211000/300480  CE: 2.3453  
[05/31 22:22:35] Re-training INFO: iter: 211125/300480  CE: 2.4555  
[05/31 22:23:59] Re-training INFO: iter: 211250/300480  CE: 2.5037  
[05/31 22:25:23] Re-training INFO: iter: 211375/300480  CE: 2.5224  
[05/31 22:26:47] Re-training INFO: iter: 211500/300480  CE: 2.3170  
[05/31 22:27:44] Re-training INFO: --> epoch: 169/240  avg CE: 2.4456  lr: 0.10041884985733524
[05/31 22:28:26] Re-training INFO: iter: 211625/300480  CE: 2.3567  
[05/31 22:29:50] Re-training INFO: iter: 211750/300480  CE: 2.6164  
[05/31 22:31:14] Re-training INFO: iter: 211875/300480  CE: 2.4954  
[05/31 22:32:38] Re-training INFO: iter: 212000/300480  CE: 2.5864  
[05/31 22:34:01] Re-training INFO: iter: 212125/300480  CE: 2.4626  
[05/31 22:35:24] Re-training INFO: iter: 212250/300480  CE: 2.6133  
[05/31 22:36:48] Re-training INFO: iter: 212375/300480  CE: 2.3685  
[05/31 22:38:12] Re-training INFO: iter: 212500/300480  CE: 2.5923  
[05/31 22:39:36] Re-training INFO: iter: 212625/300480  CE: 2.4757  
[05/31 22:40:59] Re-training INFO: iter: 212750/300480  CE: 2.4177  
[05/31 22:41:57] Re-training INFO: --> epoch: 170/240  avg CE: 2.4422  lr: 0.09780964274781984
[05/31 22:42:36] Re-training INFO: iter: 212875/300480  CE: 2.4353  
[05/31 22:44:01] Re-training INFO: iter: 213000/300480  CE: 2.4201  
[05/31 22:45:24] Re-training INFO: iter: 213125/300480  CE: 2.3730  
[05/31 22:46:48] Re-training INFO: iter: 213250/300480  CE: 2.3846  
[05/31 22:48:12] Re-training INFO: iter: 213375/300480  CE: 2.5253  
[05/31 22:49:37] Re-training INFO: iter: 213500/300480  CE: 2.7350  
[05/31 22:51:00] Re-training INFO: iter: 213625/300480  CE: 2.2833  
[05/31 22:52:24] Re-training INFO: iter: 213750/300480  CE: 2.5155  
[05/31 22:53:47] Re-training INFO: iter: 213875/300480  CE: 2.3806  
[05/31 22:55:11] Re-training INFO: iter: 214000/300480  CE: 2.4062  
[05/31 22:56:10] Re-training INFO: --> epoch: 171/240  avg CE: 2.4368  lr: 0.09522651267254148
[05/31 22:56:49] Re-training INFO: iter: 214125/300480  CE: 2.4325  
[05/31 22:58:12] Re-training INFO: iter: 214250/300480  CE: 2.4562  
[05/31 22:59:36] Re-training INFO: iter: 214375/300480  CE: 2.3647  
[05/31 23:00:58] Re-training INFO: iter: 214500/300480  CE: 2.2435  
[05/31 23:02:23] Re-training INFO: iter: 214625/300480  CE: 2.3787  
[05/31 23:03:46] Re-training INFO: iter: 214750/300480  CE: 2.7342  
[05/31 23:05:10] Re-training INFO: iter: 214875/300480  CE: 2.3496  
[05/31 23:06:34] Re-training INFO: iter: 215000/300480  CE: 2.4832  
[05/31 23:07:57] Re-training INFO: iter: 215125/300480  CE: 2.2512  
[05/31 23:09:21] Re-training INFO: iter: 215250/300480  CE: 2.2848  
[05/31 23:10:22] Re-training INFO: --> epoch: 172/240  avg CE: 2.4311  lr: 0.09266990223754068
[05/31 23:11:00] Re-training INFO: iter: 215375/300480  CE: 2.5955  
[05/31 23:12:25] Re-training INFO: iter: 215500/300480  CE: 2.3812  
[05/31 23:13:49] Re-training INFO: iter: 215625/300480  CE: 2.4828  
[05/31 23:15:14] Re-training INFO: iter: 215750/300480  CE: 2.1899  
[05/31 23:16:38] Re-training INFO: iter: 215875/300480  CE: 2.6066  
[05/31 23:18:01] Re-training INFO: iter: 216000/300480  CE: 2.0853  
[05/31 23:19:25] Re-training INFO: iter: 216125/300480  CE: 2.4687  
[05/31 23:20:49] Re-training INFO: iter: 216250/300480  CE: 2.3078  
[05/31 23:22:13] Re-training INFO: iter: 216375/300480  CE: 2.2886  
[05/31 23:23:37] Re-training INFO: iter: 216500/300480  CE: 2.5122  
[05/31 23:24:39] Re-training INFO: --> epoch: 173/240  avg CE: 2.4262  lr: 0.09014024950485383
[05/31 23:25:15] Re-training INFO: iter: 216625/300480  CE: 2.6421  
[05/31 23:26:38] Re-training INFO: iter: 216750/300480  CE: 2.4429  
[05/31 23:28:02] Re-training INFO: iter: 216875/300480  CE: 2.8222  
[05/31 23:29:25] Re-training INFO: iter: 217000/300480  CE: 2.4472  
[05/31 23:30:49] Re-training INFO: iter: 217125/300480  CE: 2.3617  
[05/31 23:32:14] Re-training INFO: iter: 217250/300480  CE: 2.5322  
[05/31 23:33:38] Re-training INFO: iter: 217375/300480  CE: 2.7190  
[05/31 23:35:03] Re-training INFO: iter: 217500/300480  CE: 2.6673  
[05/31 23:36:27] Re-training INFO: iter: 217625/300480  CE: 2.3423  
[05/31 23:37:51] Re-training INFO: iter: 217750/300480  CE: 2.3601  
[05/31 23:38:55] Re-training INFO: --> epoch: 174/240  avg CE: 2.4159  lr: 0.08763798791745411
[05/31 23:39:30] Re-training INFO: iter: 217875/300480  CE: 2.4194  
[05/31 23:40:53] Re-training INFO: iter: 218000/300480  CE: 2.5423  
[05/31 23:42:18] Re-training INFO: iter: 218125/300480  CE: 2.3998  
[05/31 23:43:42] Re-training INFO: iter: 218250/300480  CE: 2.3769  
[05/31 23:45:08] Re-training INFO: iter: 218375/300480  CE: 2.0785  
[05/31 23:46:32] Re-training INFO: iter: 218500/300480  CE: 2.7056  
[05/31 23:47:57] Re-training INFO: iter: 218625/300480  CE: 2.4376  
[05/31 23:49:21] Re-training INFO: iter: 218750/300480  CE: 2.5758  
[05/31 23:50:46] Re-training INFO: iter: 218875/300480  CE: 2.6980  
[05/31 23:52:11] Re-training INFO: iter: 219000/300480  CE: 2.3904  
[05/31 23:53:16] Re-training INFO: --> epoch: 175/240  avg CE: 2.4135  lr: 0.08516354622498287
[05/31 23:53:50] Re-training INFO: iter: 219125/300480  CE: 2.3441  
[05/31 23:55:15] Re-training INFO: iter: 219250/300480  CE: 2.4013  
[05/31 23:56:40] Re-training INFO: iter: 219375/300480  CE: 2.3971  
[05/31 23:58:04] Re-training INFO: iter: 219500/300480  CE: 2.5405  
[05/31 23:59:29] Re-training INFO: iter: 219625/300480  CE: 2.4325  
[06/01 00:00:54] Re-training INFO: iter: 219750/300480  CE: 2.5090  
[06/01 00:02:19] Re-training INFO: iter: 219875/300480  CE: 2.1753  
[06/01 00:03:42] Re-training INFO: iter: 220000/300480  CE: 2.4365  
[06/01 00:05:06] Re-training INFO: iter: 220125/300480  CE: 2.3333  
[06/01 00:06:30] Re-training INFO: iter: 220250/300480  CE: 2.2251  
[06/01 00:07:37] Re-training INFO: --> epoch: 176/240  avg CE: 2.4082  lr: 0.08271734841028544
[06/01 00:08:10] Re-training INFO: iter: 220375/300480  CE: 2.2552  
[06/01 00:09:35] Re-training INFO: iter: 220500/300480  CE: 2.4422  
[06/01 00:10:59] Re-training INFO: iter: 220625/300480  CE: 2.1029  
[06/01 00:12:23] Re-training INFO: iter: 220750/300480  CE: 2.3786  
[06/01 00:13:46] Re-training INFO: iter: 220875/300480  CE: 2.4716  
[06/01 00:15:10] Re-training INFO: iter: 221000/300480  CE: 2.4928  
[06/01 00:16:34] Re-training INFO: iter: 221125/300480  CE: 2.2720  
[06/01 00:17:57] Re-training INFO: iter: 221250/300480  CE: 2.5688  
[06/01 00:19:21] Re-training INFO: iter: 221375/300480  CE: 2.6923  
[06/01 00:20:46] Re-training INFO: iter: 221500/300480  CE: 2.5378  
[06/01 00:21:53] Re-training INFO: --> epoch: 177/240  avg CE: 2.4031  lr: 0.08029981361676455
[06/01 00:22:24] Re-training INFO: iter: 221625/300480  CE: 2.3740  
[06/01 00:23:48] Re-training INFO: iter: 221750/300480  CE: 2.3810  
[06/01 00:25:12] Re-training INFO: iter: 221875/300480  CE: 2.2059  
[06/01 00:26:35] Re-training INFO: iter: 222000/300480  CE: 2.2521  
[06/01 00:28:00] Re-training INFO: iter: 222125/300480  CE: 2.3000  
[06/01 00:29:24] Re-training INFO: iter: 222250/300480  CE: 2.4818  
[06/01 00:30:48] Re-training INFO: iter: 222375/300480  CE: 2.4090  
[06/01 00:32:12] Re-training INFO: iter: 222500/300480  CE: 2.6002  
[06/01 00:33:36] Re-training INFO: iter: 222625/300480  CE: 2.3846  
[06/01 00:34:59] Re-training INFO: iter: 222750/300480  CE: 2.3486  
[06/01 00:36:09] Re-training INFO: --> epoch: 178/240  avg CE: 2.3961  lr: 0.07791135607656155
[06/01 00:36:38] Re-training INFO: iter: 222875/300480  CE: 2.3814  
[06/01 00:38:02] Re-training INFO: iter: 223000/300480  CE: 2.3599  
[06/01 00:39:26] Re-training INFO: iter: 223125/300480  CE: 2.2107  
[06/01 00:40:51] Re-training INFO: iter: 223250/300480  CE: 2.9399  
[06/01 00:42:15] Re-training INFO: iter: 223375/300480  CE: 2.1486  
[06/01 00:43:38] Re-training INFO: iter: 223500/300480  CE: 2.5661  
[06/01 00:45:02] Re-training INFO: iter: 223625/300480  CE: 2.4842  
[06/01 00:46:27] Re-training INFO: iter: 223750/300480  CE: 2.3648  
[06/01 00:47:52] Re-training INFO: iter: 223875/300480  CE: 2.3887  
[06/01 00:49:16] Re-training INFO: iter: 224000/300480  CE: 2.6348  
[06/01 00:50:27] Re-training INFO: --> epoch: 179/240  avg CE: 2.3921  lr: 0.07555238503958
[06/01 00:50:56] Re-training INFO: iter: 224125/300480  CE: 2.2492  
[06/01 00:52:20] Re-training INFO: iter: 224250/300480  CE: 2.4403  
[06/01 00:53:43] Re-training INFO: iter: 224375/300480  CE: 2.2854  
[06/01 00:55:07] Re-training INFO: iter: 224500/300480  CE: 2.4411  
[06/01 00:56:32] Re-training INFO: iter: 224625/300480  CE: 2.2428  
[06/01 00:57:57] Re-training INFO: iter: 224750/300480  CE: 2.3867  
[06/01 00:59:21] Re-training INFO: iter: 224875/300480  CE: 2.3425  
[06/01 01:00:45] Re-training INFO: iter: 225000/300480  CE: 2.2493  
[06/01 01:02:08] Re-training INFO: iter: 225125/300480  CE: 2.4901  
[06/01 01:03:33] Re-training INFO: iter: 225250/300480  CE: 2.2924  
[06/01 01:04:46] Re-training INFO: --> epoch: 180/240  avg CE: 2.3896  lr: 0.07322330470336313
[06/01 01:05:18] Re-training INFO: # of Test Samples: 50000.0
[06/01 01:05:18] Re-training INFO: Top-1/-5 acc: 68.57 / 89.04
[06/01 01:05:18] Re-training INFO: Top-1/-5 acc: 31.43 / 10.96
[06/01 01:05:18] Re-training INFO: 

[06/01 01:05:43] Re-training INFO: iter: 225375/300480  CE: 2.4645  
[06/01 01:07:09] Re-training INFO: iter: 225500/300480  CE: 2.5941  
[06/01 01:08:32] Re-training INFO: iter: 225625/300480  CE: 2.4912  
[06/01 01:09:56] Re-training INFO: iter: 225750/300480  CE: 2.5087  
[06/01 01:11:18] Re-training INFO: iter: 225875/300480  CE: 2.5249  
[06/01 01:12:42] Re-training INFO: iter: 226000/300480  CE: 2.5812  
[06/01 01:14:05] Re-training INFO: iter: 226125/300480  CE: 2.3631  
[06/01 01:15:30] Re-training INFO: iter: 226250/300480  CE: 2.2210  
[06/01 01:16:54] Re-training INFO: iter: 226375/300480  CE: 2.6777  
[06/01 01:18:19] Re-training INFO: iter: 226500/300480  CE: 2.2775  
[06/01 01:19:32] Re-training INFO: --> epoch: 181/240  avg CE: 2.3899  lr: 0.07092451414383644
[06/01 01:19:57] Re-training INFO: iter: 226625/300480  CE: 2.1512  
[06/01 01:21:22] Re-training INFO: iter: 226750/300480  CE: 2.4034  
[06/01 01:22:45] Re-training INFO: iter: 226875/300480  CE: 2.4381  
[06/01 01:24:09] Re-training INFO: iter: 227000/300480  CE: 2.1268  
[06/01 01:25:33] Re-training INFO: iter: 227125/300480  CE: 2.4808  
[06/01 01:26:57] Re-training INFO: iter: 227250/300480  CE: 2.5189  
[06/01 01:28:20] Re-training INFO: iter: 227375/300480  CE: 2.3763  
[06/01 01:29:45] Re-training INFO: iter: 227500/300480  CE: 2.4316  
[06/01 01:31:08] Re-training INFO: iter: 227625/300480  CE: 2.2883  
[06/01 01:32:33] Re-training INFO: iter: 227750/300480  CE: 2.2627  
[06/01 01:33:47] Re-training INFO: --> epoch: 182/240  avg CE: 2.3811  lr: 0.06865640724692815
[06/01 01:34:11] Re-training INFO: iter: 227875/300480  CE: 2.1847  
[06/01 01:35:35] Re-training INFO: iter: 228000/300480  CE: 2.3422  
[06/01 01:36:59] Re-training INFO: iter: 228125/300480  CE: 2.5053  
[06/01 01:38:23] Re-training INFO: iter: 228250/300480  CE: 2.1512  
[06/01 01:39:46] Re-training INFO: iter: 228375/300480  CE: 2.5126  
[06/01 01:41:10] Re-training INFO: iter: 228500/300480  CE: 2.2935  
[06/01 01:42:33] Re-training INFO: iter: 228625/300480  CE: 2.4613  
[06/01 01:43:58] Re-training INFO: iter: 228750/300480  CE: 2.2910  
[06/01 01:45:21] Re-training INFO: iter: 228875/300480  CE: 2.2447  
[06/01 01:46:45] Re-training INFO: iter: 229000/300480  CE: 2.3982  
[06/01 01:48:00] Re-training INFO: --> epoch: 183/240  avg CE: 2.3615  lr: 0.06641937264107858
[06/01 01:48:23] Re-training INFO: iter: 229125/300480  CE: 2.2451  
[06/01 01:49:47] Re-training INFO: iter: 229250/300480  CE: 2.3244  
[06/01 01:51:11] Re-training INFO: iter: 229375/300480  CE: 2.2784  
[06/01 01:52:34] Re-training INFO: iter: 229500/300480  CE: 2.5303  
[06/01 01:53:59] Re-training INFO: iter: 229625/300480  CE: 2.2478  
[06/01 01:55:23] Re-training INFO: iter: 229750/300480  CE: 2.3019  
[06/01 01:56:47] Re-training INFO: iter: 229875/300480  CE: 2.4159  
[06/01 01:58:12] Re-training INFO: iter: 230000/300480  CE: 2.4395  
[06/01 01:59:36] Re-training INFO: iter: 230125/300480  CE: 2.5088  
[06/01 02:01:01] Re-training INFO: iter: 230250/300480  CE: 2.5090  
[06/01 02:02:17] Re-training INFO: --> epoch: 184/240  avg CE: 2.3556  lr: 0.06421379363065141
[06/01 02:02:38] Re-training INFO: iter: 230375/300480  CE: 2.3815  
[06/01 02:04:03] Re-training INFO: iter: 230500/300480  CE: 2.2324  
[06/01 02:05:28] Re-training INFO: iter: 230625/300480  CE: 2.3547  
[06/01 02:06:52] Re-training INFO: iter: 230750/300480  CE: 2.3836  
[06/01 02:08:16] Re-training INFO: iter: 230875/300480  CE: 2.5957  
[06/01 02:09:40] Re-training INFO: iter: 231000/300480  CE: 2.4111  
[06/01 02:11:04] Re-training INFO: iter: 231125/300480  CE: 2.5617  
[06/01 02:12:27] Re-training INFO: iter: 231250/300480  CE: 2.2823  
[06/01 02:13:49] Re-training INFO: iter: 231375/300480  CE: 2.4526  
[06/01 02:15:13] Re-training INFO: iter: 231500/300480  CE: 2.2872  
[06/01 02:16:31] Re-training INFO: --> epoch: 185/240  avg CE: 2.3585  lr: 0.06204004813025568
[06/01 02:16:51] Re-training INFO: iter: 231625/300480  CE: 2.4481  
[06/01 02:18:14] Re-training INFO: iter: 231750/300480  CE: 2.3678  
[06/01 02:19:38] Re-training INFO: iter: 231875/300480  CE: 2.4373  
[06/01 02:21:01] Re-training INFO: iter: 232000/300480  CE: 2.2070  
[06/01 02:22:25] Re-training INFO: iter: 232125/300480  CE: 2.3578  
[06/01 02:23:48] Re-training INFO: iter: 232250/300480  CE: 2.1641  
[06/01 02:25:13] Re-training INFO: iter: 232375/300480  CE: 2.4364  
[06/01 02:26:36] Re-training INFO: iter: 232500/300480  CE: 2.3803  
[06/01 02:27:59] Re-training INFO: iter: 232625/300480  CE: 2.3326  
[06/01 02:29:23] Re-training INFO: iter: 232750/300480  CE: 2.5859  
[06/01 02:30:43] Re-training INFO: --> epoch: 186/240  avg CE: 2.3459  lr: 0.05989850859999227
[06/01 02:31:01] Re-training INFO: iter: 232875/300480  CE: 2.3755  
[06/01 02:32:25] Re-training INFO: iter: 233000/300480  CE: 2.4556  
[06/01 02:33:50] Re-training INFO: iter: 233125/300480  CE: 2.4168  
[06/01 02:35:13] Re-training INFO: iter: 233250/300480  CE: 2.3405  
[06/01 02:36:37] Re-training INFO: iter: 233375/300480  CE: 2.5111  
[06/01 02:38:00] Re-training INFO: iter: 233500/300480  CE: 2.3928  
[06/01 02:39:23] Re-training INFO: iter: 233625/300480  CE: 2.2694  
[06/01 02:40:48] Re-training INFO: iter: 233750/300480  CE: 2.5718  
[06/01 02:42:11] Re-training INFO: iter: 233875/300480  CE: 2.1351  
[06/01 02:43:35] Re-training INFO: iter: 234000/300480  CE: 2.5831  
[06/01 02:44:55] Re-training INFO: --> epoch: 187/240  avg CE: 2.3448  lr: 0.057789541981635134
[06/01 02:45:13] Re-training INFO: iter: 234125/300480  CE: 2.2639  
[06/01 02:46:38] Re-training INFO: iter: 234250/300480  CE: 2.3483  
[06/01 02:48:01] Re-training INFO: iter: 234375/300480  CE: 2.1439  
[06/01 02:49:26] Re-training INFO: iter: 234500/300480  CE: 2.6175  
[06/01 02:50:50] Re-training INFO: iter: 234625/300480  CE: 2.5912  
[06/01 02:52:14] Re-training INFO: iter: 234750/300480  CE: 2.1659  
[06/01 02:53:37] Re-training INFO: iter: 234875/300480  CE: 2.4953  
[06/01 02:55:01] Re-training INFO: iter: 235000/300480  CE: 2.5112  
[06/01 02:56:26] Re-training INFO: iter: 235125/300480  CE: 2.3405  
[06/01 02:57:50] Re-training INFO: iter: 235250/300480  CE: 2.3022  
[06/01 02:59:12] Re-training INFO: iter: 235375/300480  CE: 2.3433  
[06/01 02:59:12] Re-training INFO: --> epoch: 188/240  avg CE: 2.3409  lr: 0.05571350963575733
[06/01 03:00:52] Re-training INFO: iter: 235500/300480  CE: 2.1955  
[06/01 03:02:16] Re-training INFO: iter: 235625/300480  CE: 2.2211  
[06/01 03:03:41] Re-training INFO: iter: 235750/300480  CE: 2.3353  
[06/01 03:05:03] Re-training INFO: iter: 235875/300480  CE: 2.2408  
[06/01 03:06:27] Re-training INFO: iter: 236000/300480  CE: 2.1217  
[06/01 03:07:50] Re-training INFO: iter: 236125/300480  CE: 2.3299  
[06/01 03:09:14] Re-training INFO: iter: 236250/300480  CE: 2.2153  
[06/01 03:10:38] Re-training INFO: iter: 236375/300480  CE: 2.6487  
[06/01 03:12:01] Re-training INFO: iter: 236500/300480  CE: 2.3653  
[06/01 03:13:25] Re-training INFO: iter: 236625/300480  CE: 2.3265  
[06/01 03:13:26] Re-training INFO: --> epoch: 189/240  avg CE: 2.3232  lr: 0.05367076727981382
[06/01 03:15:05] Re-training INFO: iter: 236750/300480  CE: 2.1653  
[06/01 03:16:29] Re-training INFO: iter: 236875/300480  CE: 2.1760  
[06/01 03:17:52] Re-training INFO: iter: 237000/300480  CE: 2.2465  
[06/01 03:19:16] Re-training INFO: iter: 237125/300480  CE: 2.2103  
[06/01 03:20:40] Re-training INFO: iter: 237250/300480  CE: 2.3976  
[06/01 03:22:04] Re-training INFO: iter: 237375/300480  CE: 2.3875  
[06/01 03:23:28] Re-training INFO: iter: 237500/300480  CE: 2.4823  
[06/01 03:24:52] Re-training INFO: iter: 237625/300480  CE: 2.1780  
[06/01 03:26:15] Re-training INFO: iter: 237750/300480  CE: 2.3089  
[06/01 03:27:39] Re-training INFO: iter: 237875/300480  CE: 2.3333  
[06/01 03:27:41] Re-training INFO: --> epoch: 190/240  avg CE: 2.3192  lr: 0.051661664927191236
[06/01 03:29:22] Re-training INFO: iter: 238000/300480  CE: 2.1865  
[06/01 03:30:50] Re-training INFO: iter: 238125/300480  CE: 2.4493  
[06/01 03:32:16] Re-training INFO: iter: 238250/300480  CE: 1.8852  
[06/01 03:33:42] Re-training INFO: iter: 238375/300480  CE: 2.2720  
[06/01 03:35:08] Re-training INFO: iter: 238500/300480  CE: 2.4042  
[06/01 03:36:33] Re-training INFO: iter: 238625/300480  CE: 2.3768  
[06/01 03:37:58] Re-training INFO: iter: 238750/300480  CE: 2.4720  
[06/01 03:39:23] Re-training INFO: iter: 238875/300480  CE: 2.2212  
[06/01 03:40:49] Re-training INFO: iter: 239000/300480  CE: 2.3279  
[06/01 03:42:14] Re-training INFO: iter: 239125/300480  CE: 2.2652  
[06/01 03:42:18] Re-training INFO: --> epoch: 191/240  avg CE: 2.3111  lr: 0.04968654682723486
[06/01 03:43:55] Re-training INFO: iter: 239250/300480  CE: 2.2045  
[06/01 03:45:19] Re-training INFO: iter: 239375/300480  CE: 2.4337  
[06/01 03:46:43] Re-training INFO: iter: 239500/300480  CE: 2.4297  
[06/01 03:48:07] Re-training INFO: iter: 239625/300480  CE: 2.2471  
[06/01 03:49:31] Re-training INFO: iter: 239750/300480  CE: 2.3947  
[06/01 03:50:55] Re-training INFO: iter: 239875/300480  CE: 2.4721  
[06/01 03:52:19] Re-training INFO: iter: 240000/300480  CE: 2.3046  
[06/01 03:53:43] Re-training INFO: iter: 240125/300480  CE: 2.2653  
[06/01 03:55:06] Re-training INFO: iter: 240250/300480  CE: 2.6099  
[06/01 03:56:30] Re-training INFO: iter: 240375/300480  CE: 2.4352  
[06/01 03:56:34] Re-training INFO: --> epoch: 192/240  avg CE: 2.3160  lr: 0.047745751406263165
[06/01 03:58:08] Re-training INFO: iter: 240500/300480  CE: 2.2155  
[06/01 03:59:33] Re-training INFO: iter: 240625/300480  CE: 2.3403  
[06/01 04:00:55] Re-training INFO: iter: 240750/300480  CE: 2.2636  
[06/01 04:02:18] Re-training INFO: iter: 240875/300480  CE: 2.4623  
[06/01 04:03:42] Re-training INFO: iter: 241000/300480  CE: 2.1998  
[06/01 04:05:06] Re-training INFO: iter: 241125/300480  CE: 2.2838  
[06/01 04:06:30] Re-training INFO: iter: 241250/300480  CE: 2.3419  
[06/01 04:07:53] Re-training INFO: iter: 241375/300480  CE: 2.3064  
[06/01 04:09:17] Re-training INFO: iter: 241500/300480  CE: 2.3626  
[06/01 04:10:40] Re-training INFO: iter: 241625/300480  CE: 2.0910  
[06/01 04:10:46] Re-training INFO: --> epoch: 193/240  avg CE: 2.3058  lr: 0.04583961120958027
[06/01 04:12:20] Re-training INFO: iter: 241750/300480  CE: 2.1413  
[06/01 04:13:44] Re-training INFO: iter: 241875/300480  CE: 2.3152  
[06/01 04:15:07] Re-training INFO: iter: 242000/300480  CE: 2.1803  
[06/01 04:16:31] Re-training INFO: iter: 242125/300480  CE: 2.4839  
[06/01 04:17:55] Re-training INFO: iter: 242250/300480  CE: 2.3414  
[06/01 04:19:19] Re-training INFO: iter: 242375/300480  CE: 2.0850  
[06/01 04:20:43] Re-training INFO: iter: 242500/300480  CE: 2.3254  
[06/01 04:22:07] Re-training INFO: iter: 242625/300480  CE: 2.3296  
[06/01 04:23:30] Re-training INFO: iter: 242750/300480  CE: 2.1973  
[06/01 04:24:56] Re-training INFO: iter: 242875/300480  CE: 2.1993  
[06/01 04:25:02] Re-training INFO: --> epoch: 194/240  avg CE: 2.3033  lr: 0.043968452844496075
[06/01 04:26:34] Re-training INFO: iter: 243000/300480  CE: 2.5353  
[06/01 04:27:59] Re-training INFO: iter: 243125/300480  CE: 2.2583  
[06/01 04:29:23] Re-training INFO: iter: 243250/300480  CE: 2.2442  
[06/01 04:30:47] Re-training INFO: iter: 243375/300480  CE: 2.2578  
[06/01 04:32:10] Re-training INFO: iter: 243500/300480  CE: 2.4462  
[06/01 04:33:33] Re-training INFO: iter: 243625/300480  CE: 2.3254  
[06/01 04:34:58] Re-training INFO: iter: 243750/300480  CE: 2.3650  
[06/01 04:36:22] Re-training INFO: iter: 243875/300480  CE: 2.1814  
[06/01 04:37:46] Re-training INFO: iter: 244000/300480  CE: 2.2546  
[06/01 04:39:11] Re-training INFO: iter: 244125/300480  CE: 2.3425  
[06/01 04:39:19] Re-training INFO: --> epoch: 195/240  avg CE: 2.2904  lr: 0.04213259692436375
[06/01 04:40:51] Re-training INFO: iter: 244250/300480  CE: 2.3048  
[06/01 04:42:14] Re-training INFO: iter: 244375/300480  CE: 2.4710  
[06/01 04:43:38] Re-training INFO: iter: 244500/300480  CE: 2.3665  
[06/01 04:45:03] Re-training INFO: iter: 244625/300480  CE: 2.4908  
[06/01 04:46:29] Re-training INFO: iter: 244750/300480  CE: 2.2704  
[06/01 04:47:54] Re-training INFO: iter: 244875/300480  CE: 2.3875  
[06/01 04:49:19] Re-training INFO: iter: 245000/300480  CE: 2.3770  
[06/01 04:50:43] Re-training INFO: iter: 245125/300480  CE: 2.4532  
[06/01 04:52:07] Re-training INFO: iter: 245250/300480  CE: 2.1975  
[06/01 04:53:31] Re-training INFO: iter: 245375/300480  CE: 2.3835  
[06/01 04:53:41] Re-training INFO: --> epoch: 196/240  avg CE: 2.2833  lr: 0.040332358013644015
[06/01 04:55:13] Re-training INFO: iter: 245500/300480  CE: 2.3849  
[06/01 04:56:38] Re-training INFO: iter: 245625/300480  CE: 2.3005  
[06/01 04:58:05] Re-training INFO: iter: 245750/300480  CE: 2.2797  
[06/01 04:59:30] Re-training INFO: iter: 245875/300480  CE: 2.2457  
[06/01 05:00:54] Re-training INFO: iter: 246000/300480  CE: 2.3342  
[06/01 05:02:20] Re-training INFO: iter: 246125/300480  CE: 2.2077  
[06/01 05:03:44] Re-training INFO: iter: 246250/300480  CE: 2.2840  
[06/01 05:05:09] Re-training INFO: iter: 246375/300480  CE: 2.2303  
[06/01 05:06:34] Re-training INFO: iter: 246500/300480  CE: 2.2150  
[06/01 05:07:58] Re-training INFO: iter: 246625/300480  CE: 2.4255  
[06/01 05:08:10] Re-training INFO: --> epoch: 197/240  avg CE: 2.2718  lr: 0.0385680445740067
[06/01 05:09:38] Re-training INFO: iter: 246750/300480  CE: 2.2716  
[06/01 05:11:02] Re-training INFO: iter: 246875/300480  CE: 2.4178  
[06/01 05:12:25] Re-training INFO: iter: 247000/300480  CE: 2.2495  
[06/01 05:13:48] Re-training INFO: iter: 247125/300480  CE: 2.2641  
[06/01 05:15:13] Re-training INFO: iter: 247250/300480  CE: 2.2988  
[06/01 05:16:37] Re-training INFO: iter: 247375/300480  CE: 2.1733  
[06/01 05:18:00] Re-training INFO: iter: 247500/300480  CE: 2.3015  
[06/01 05:19:24] Re-training INFO: iter: 247625/300480  CE: 2.2673  
[06/01 05:20:48] Re-training INFO: iter: 247750/300480  CE: 2.2883  
[06/01 05:22:11] Re-training INFO: iter: 247875/300480  CE: 2.3852  
[06/01 05:22:23] Re-training INFO: --> epoch: 198/240  avg CE: 2.2724  lr: 0.036839958911476955
[06/01 05:23:50] Re-training INFO: iter: 248000/300480  CE: 2.1836  
[06/01 05:25:15] Re-training INFO: iter: 248125/300480  CE: 2.1471  
[06/01 05:26:38] Re-training INFO: iter: 248250/300480  CE: 2.2779  
[06/01 05:28:03] Re-training INFO: iter: 248375/300480  CE: 2.1260  
[06/01 05:29:26] Re-training INFO: iter: 248500/300480  CE: 2.3629  
[06/01 05:30:49] Re-training INFO: iter: 248625/300480  CE: 2.5794  
[06/01 05:32:13] Re-training INFO: iter: 248750/300480  CE: 2.1053  
[06/01 05:33:37] Re-training INFO: iter: 248875/300480  CE: 2.0703  
[06/01 05:35:01] Re-training INFO: iter: 249000/300480  CE: 2.5335  
[06/01 05:36:26] Re-training INFO: iter: 249125/300480  CE: 2.3831  
[06/01 05:36:39] Re-training INFO: --> epoch: 199/240  avg CE: 2.2672  lr: 0.035148397124636827
[06/01 05:38:04] Re-training INFO: iter: 249250/300480  CE: 2.1592  
[06/01 05:39:28] Re-training INFO: iter: 249375/300480  CE: 2.3163  
[06/01 05:40:52] Re-training INFO: iter: 249500/300480  CE: 2.1972  
[06/01 05:42:17] Re-training INFO: iter: 249625/300480  CE: 2.2147  
[06/01 05:43:41] Re-training INFO: iter: 249750/300480  CE: 2.3349  
[06/01 05:45:06] Re-training INFO: iter: 249875/300480  CE: 2.2846  
[06/01 05:46:31] Re-training INFO: iter: 250000/300480  CE: 2.3280  
[06/01 05:47:55] Re-training INFO: iter: 250125/300480  CE: 2.3409  
[06/01 05:49:21] Re-training INFO: iter: 250250/300480  CE: 2.2244  
[06/01 05:50:45] Re-training INFO: iter: 250375/300480  CE: 2.2969  
[06/01 05:50:59] Re-training INFO: --> epoch: 200/240  avg CE: 2.2547  lr: 0.03349364905389032
[06/01 05:51:31] Re-training INFO: # of Test Samples: 50000.0
[06/01 05:51:31] Re-training INFO: Top-1/-5 acc: 71.87 / 90.73
[06/01 05:51:31] Re-training INFO: Top-1/-5 acc: 28.13 /  9.27
[06/01 05:51:31] Re-training INFO: 

[06/01 05:52:55] Re-training INFO: iter: 250500/300480  CE: 2.4103  
[06/01 05:54:19] Re-training INFO: iter: 250625/300480  CE: 2.1569  
[06/01 05:55:42] Re-training INFO: iter: 250750/300480  CE: 2.1622  
[06/01 05:57:06] Re-training INFO: iter: 250875/300480  CE: 2.2891  
[06/01 05:58:29] Re-training INFO: iter: 251000/300480  CE: 2.2930  
[06/01 05:59:54] Re-training INFO: iter: 251125/300480  CE: 2.0213  
[06/01 06:01:17] Re-training INFO: iter: 251250/300480  CE: 2.3764  
[06/01 06:02:40] Re-training INFO: iter: 251375/300480  CE: 2.3881  
[06/01 06:04:04] Re-training INFO: iter: 251500/300480  CE: 2.4738  
[06/01 06:05:27] Re-training INFO: iter: 251625/300480  CE: 2.4833  
[06/01 06:05:44] Re-training INFO: --> epoch: 201/240  avg CE: 2.2512  lr: 0.031875998231800706
[06/01 06:07:07] Re-training INFO: iter: 251750/300480  CE: 2.1528  
[06/01 06:08:31] Re-training INFO: iter: 251875/300480  CE: 2.2651  
[06/01 06:09:54] Re-training INFO: iter: 252000/300480  CE: 2.4942  
[06/01 06:11:18] Re-training INFO: iter: 252125/300480  CE: 2.2204  
[06/01 06:12:42] Re-training INFO: iter: 252250/300480  CE: 2.2139  
[06/01 06:14:04] Re-training INFO: iter: 252375/300480  CE: 2.2966  
[06/01 06:15:27] Re-training INFO: iter: 252500/300480  CE: 1.9787  
[06/01 06:16:51] Re-training INFO: iter: 252625/300480  CE: 2.3009  
[06/01 06:18:14] Re-training INFO: iter: 252750/300480  CE: 2.0611  
[06/01 06:19:38] Re-training INFO: iter: 252875/300480  CE: 2.2946  
[06/01 06:19:56] Re-training INFO: --> epoch: 202/240  avg CE: 2.2476  lr: 0.030295721834508682
[06/01 06:21:18] Re-training INFO: iter: 253000/300480  CE: 2.1050  
[06/01 06:22:42] Re-training INFO: iter: 253125/300480  CE: 2.2278  
[06/01 06:24:06] Re-training INFO: iter: 253250/300480  CE: 2.2457  
[06/01 06:25:30] Re-training INFO: iter: 253375/300480  CE: 2.2884  
[06/01 06:26:54] Re-training INFO: iter: 253500/300480  CE: 2.2921  
[06/01 06:28:18] Re-training INFO: iter: 253625/300480  CE: 2.1504  
[06/01 06:29:43] Re-training INFO: iter: 253750/300480  CE: 2.0591  
[06/01 06:31:06] Re-training INFO: iter: 253875/300480  CE: 2.2041  
[06/01 06:32:31] Re-training INFO: iter: 254000/300480  CE: 2.1325  
[06/01 06:33:55] Re-training INFO: iter: 254125/300480  CE: 2.1501  
[06/01 06:34:13] Re-training INFO: --> epoch: 203/240  avg CE: 2.2306  lr: 0.02875309063423956
[06/01 06:35:34] Re-training INFO: iter: 254250/300480  CE: 2.2828  
[06/01 06:36:58] Re-training INFO: iter: 254375/300480  CE: 1.9629  
[06/01 06:38:21] Re-training INFO: iter: 254500/300480  CE: 2.1540  
[06/01 06:39:46] Re-training INFO: iter: 254625/300480  CE: 2.1681  
[06/01 06:41:09] Re-training INFO: iter: 254750/300480  CE: 2.2992  
[06/01 06:42:32] Re-training INFO: iter: 254875/300480  CE: 2.1343  
[06/01 06:43:56] Re-training INFO: iter: 255000/300480  CE: 1.9641  
[06/01 06:45:20] Re-training INFO: iter: 255125/300480  CE: 2.1827  
[06/01 06:46:44] Re-training INFO: iter: 255250/300480  CE: 2.4243  
[06/01 06:48:08] Re-training INFO: iter: 255375/300480  CE: 2.1700  
[06/01 06:48:28] Re-training INFO: --> epoch: 204/240  avg CE: 2.2376  lr: 0.027248368952908053
[06/01 06:49:47] Re-training INFO: iter: 255500/300480  CE: 2.0668  
[06/01 06:51:12] Re-training INFO: iter: 255625/300480  CE: 2.4165  
[06/01 06:52:35] Re-training INFO: iter: 255750/300480  CE: 2.1504  
[06/01 06:53:59] Re-training INFO: iter: 255875/300480  CE: 2.1894  
[06/01 06:55:23] Re-training INFO: iter: 256000/300480  CE: 2.1583  
[06/01 06:56:46] Re-training INFO: iter: 256125/300480  CE: 2.4998  
[06/01 06:58:10] Re-training INFO: iter: 256250/300480  CE: 2.3464  
[06/01 06:59:33] Re-training INFO: iter: 256375/300480  CE: 2.2643  
[06/01 07:00:57] Re-training INFO: iter: 256500/300480  CE: 2.0778  
[06/01 07:02:20] Re-training INFO: iter: 256625/300480  CE: 2.5414  
[06/01 07:02:42] Re-training INFO: --> epoch: 205/240  avg CE: 2.2206  lr: 0.025781814616827936
[06/01 07:04:00] Re-training INFO: iter: 256750/300480  CE: 2.0836  
[06/01 07:05:25] Re-training INFO: iter: 256875/300480  CE: 2.3744  
[06/01 07:06:49] Re-training INFO: iter: 257000/300480  CE: 2.3461  
[06/01 07:08:14] Re-training INFO: iter: 257125/300480  CE: 2.4231  
[06/01 07:09:37] Re-training INFO: iter: 257250/300480  CE: 2.0562  
[06/01 07:11:00] Re-training INFO: iter: 257375/300480  CE: 2.0930  
[06/01 07:12:24] Re-training INFO: iter: 257500/300480  CE: 2.1438  
[06/01 07:13:48] Re-training INFO: iter: 257625/300480  CE: 2.4585  
[06/01 07:15:12] Re-training INFO: iter: 257750/300480  CE: 2.2034  
[06/01 07:16:38] Re-training INFO: iter: 257875/300480  CE: 2.3059  
[06/01 07:17:01] Re-training INFO: --> epoch: 206/240  avg CE: 2.2132  lr: 0.024353678912534843
[06/01 07:18:17] Re-training INFO: iter: 258000/300480  CE: 2.2331  
[06/01 07:19:41] Re-training INFO: iter: 258125/300480  CE: 2.1120  
[06/01 07:21:04] Re-training INFO: iter: 258250/300480  CE: 2.2293  
[06/01 07:22:30] Re-training INFO: iter: 258375/300480  CE: 2.0004  
[06/01 07:23:54] Re-training INFO: iter: 258500/300480  CE: 2.2700  
[06/01 07:25:19] Re-training INFO: iter: 258625/300480  CE: 2.0608  
[06/01 07:26:43] Re-training INFO: iter: 258750/300480  CE: 2.0900  
[06/01 07:28:08] Re-training INFO: iter: 258875/300480  CE: 2.1974  
[06/01 07:29:32] Re-training INFO: iter: 259000/300480  CE: 2.1133  
[06/01 07:30:55] Re-training INFO: iter: 259125/300480  CE: 2.3386  
[06/01 07:31:19] Re-training INFO: --> epoch: 207/240  avg CE: 2.2120  lr: 0.02296420654372966
[06/01 07:32:35] Re-training INFO: iter: 259250/300480  CE: 2.1425  
[06/01 07:33:59] Re-training INFO: iter: 259375/300480  CE: 1.9469  
[06/01 07:35:22] Re-training INFO: iter: 259500/300480  CE: 2.2657  
[06/01 07:36:46] Re-training INFO: iter: 259625/300480  CE: 2.4293  
[06/01 07:38:10] Re-training INFO: iter: 259750/300480  CE: 2.2055  
[06/01 07:39:34] Re-training INFO: iter: 259875/300480  CE: 1.9826  
[06/01 07:40:58] Re-training INFO: iter: 260000/300480  CE: 2.0721  
[06/01 07:42:23] Re-training INFO: iter: 260125/300480  CE: 2.2419  
[06/01 07:43:47] Re-training INFO: iter: 260250/300480  CE: 2.1428  
[06/01 07:45:11] Re-training INFO: iter: 260375/300480  CE: 2.2649  
[06/01 07:45:37] Re-training INFO: --> epoch: 208/240  avg CE: 2.2032  lr: 0.02161363558934981
[06/01 07:46:50] Re-training INFO: iter: 260500/300480  CE: 2.1165  
[06/01 07:48:14] Re-training INFO: iter: 260625/300480  CE: 2.4782  
[06/01 07:49:38] Re-training INFO: iter: 260750/300480  CE: 2.1118  
[06/01 07:51:01] Re-training INFO: iter: 260875/300480  CE: 1.9615  
[06/01 07:52:24] Re-training INFO: iter: 261000/300480  CE: 2.3214  
[06/01 07:53:49] Re-training INFO: iter: 261125/300480  CE: 2.3875  
[06/01 07:55:14] Re-training INFO: iter: 261250/300480  CE: 2.3134  
[06/01 07:56:37] Re-training INFO: iter: 261375/300480  CE: 2.0237  
[06/01 07:58:00] Re-training INFO: iter: 261500/300480  CE: 2.1225  
[06/01 07:59:25] Re-training INFO: iter: 261625/300480  CE: 2.2314  
[06/01 07:59:52] Re-training INFO: --> epoch: 209/240  avg CE: 2.2004  lr: 0.02030219746277545
[06/01 08:01:04] Re-training INFO: iter: 261750/300480  CE: 2.4132  
[06/01 08:02:27] Re-training INFO: iter: 261875/300480  CE: 2.2008  
[06/01 08:03:50] Re-training INFO: iter: 262000/300480  CE: 1.9939  
[06/01 08:05:13] Re-training INFO: iter: 262125/300480  CE: 1.9891  
[06/01 08:06:37] Re-training INFO: iter: 262250/300480  CE: 2.2240  
[06/01 08:08:01] Re-training INFO: iter: 262375/300480  CE: 2.1557  
[06/01 08:09:24] Re-training INFO: iter: 262500/300480  CE: 2.3926  
[06/01 08:10:48] Re-training INFO: iter: 262625/300480  CE: 2.2375  
[06/01 08:12:13] Re-training INFO: iter: 262750/300480  CE: 2.4988  
[06/01 08:13:35] Re-training INFO: iter: 262875/300480  CE: 1.9614  
[06/01 08:14:04] Re-training INFO: --> epoch: 210/240  avg CE: 2.1978  lr: 0.019030116872178315
[06/01 08:15:14] Re-training INFO: iter: 263000/300480  CE: 2.2412  
[06/01 08:16:38] Re-training INFO: iter: 263125/300480  CE: 2.3501  
[06/01 08:18:03] Re-training INFO: iter: 263250/300480  CE: 2.3595  
[06/01 08:19:26] Re-training INFO: iter: 263375/300480  CE: 2.1913  
[06/01 08:20:51] Re-training INFO: iter: 263500/300480  CE: 2.2760  
[06/01 08:22:14] Re-training INFO: iter: 263625/300480  CE: 2.3676  
[06/01 08:23:38] Re-training INFO: iter: 263750/300480  CE: 1.9940  
[06/01 08:25:02] Re-training INFO: iter: 263875/300480  CE: 2.2458  
[06/01 08:26:28] Re-training INFO: iter: 264000/300480  CE: 2.0593  
[06/01 08:27:51] Re-training INFO: iter: 264125/300480  CE: 2.2377  
[06/01 08:28:21] Re-training INFO: --> epoch: 211/240  avg CE: 2.1868  lr: 0.01779761178201894
[06/01 08:29:29] Re-training INFO: iter: 264250/300480  CE: 2.0926  
[06/01 08:30:52] Re-training INFO: iter: 264375/300480  CE: 2.1161  
[06/01 08:32:17] Re-training INFO: iter: 264500/300480  CE: 2.1000  
[06/01 08:33:40] Re-training INFO: iter: 264625/300480  CE: 2.3148  
[06/01 08:35:03] Re-training INFO: iter: 264750/300480  CE: 2.1008  
[06/01 08:36:28] Re-training INFO: iter: 264875/300480  CE: 2.0207  
[06/01 08:37:52] Re-training INFO: iter: 265000/300480  CE: 2.2991  
[06/01 08:39:15] Re-training INFO: iter: 265125/300480  CE: 2.0325  
[06/01 08:40:38] Re-training INFO: iter: 265250/300480  CE: 2.0926  
[06/01 08:42:01] Re-training INFO: iter: 265375/300480  CE: 2.1028  
[06/01 08:42:32] Re-training INFO: --> epoch: 212/240  avg CE: 2.1775  lr: 0.016604893375699592
[06/01 08:43:39] Re-training INFO: iter: 265500/300480  CE: 2.3091  
[06/01 08:45:03] Re-training INFO: iter: 265625/300480  CE: 2.2040  
[06/01 08:46:26] Re-training INFO: iter: 265750/300480  CE: 2.1961  
[06/01 08:47:50] Re-training INFO: iter: 265875/300480  CE: 2.0571  
[06/01 08:49:13] Re-training INFO: iter: 266000/300480  CE: 2.0634  
[06/01 08:50:37] Re-training INFO: iter: 266125/300480  CE: 2.0792  
[06/01 08:52:02] Re-training INFO: iter: 266250/300480  CE: 2.2237  
[06/01 08:53:25] Re-training INFO: iter: 266375/300480  CE: 2.0785  
[06/01 08:54:48] Re-training INFO: iter: 266500/300480  CE: 2.1195  
[06/01 08:56:13] Re-training INFO: iter: 266625/300480  CE: 2.2844  
[06/01 08:56:45] Re-training INFO: --> epoch: 213/240  avg CE: 2.1731  lr: 0.01545216601937896
[06/01 08:57:51] Re-training INFO: iter: 266750/300480  CE: 2.1633  
[06/01 08:59:15] Re-training INFO: iter: 266875/300480  CE: 2.0633  
[06/01 09:00:38] Re-training INFO: iter: 267000/300480  CE: 2.3248  
[06/01 09:02:03] Re-training INFO: iter: 267125/300480  CE: 2.1353  
[06/01 09:03:27] Re-training INFO: iter: 267250/300480  CE: 2.1326  
[06/01 09:04:51] Re-training INFO: iter: 267375/300480  CE: 2.1561  
[06/01 09:06:15] Re-training INFO: iter: 267500/300480  CE: 2.2048  
[06/01 09:07:40] Re-training INFO: iter: 267625/300480  CE: 2.1627  
[06/01 09:09:03] Re-training INFO: iter: 267750/300480  CE: 2.2517  
[06/01 09:10:29] Re-training INFO: iter: 267875/300480  CE: 2.3600  
[06/01 09:11:02] Re-training INFO: --> epoch: 214/240  avg CE: 2.1594  lr: 0.014339627226955393
[06/01 09:12:07] Re-training INFO: iter: 268000/300480  CE: 2.2652  
[06/01 09:13:31] Re-training INFO: iter: 268125/300480  CE: 2.4340  
[06/01 09:14:55] Re-training INFO: iter: 268250/300480  CE: 2.3245  
[06/01 09:16:20] Re-training INFO: iter: 268375/300480  CE: 2.1176  
[06/01 09:17:42] Re-training INFO: iter: 268500/300480  CE: 2.3524  
[06/01 09:19:07] Re-training INFO: iter: 268625/300480  CE: 2.1186  
[06/01 09:20:31] Re-training INFO: iter: 268750/300480  CE: 2.2831  
[06/01 09:21:55] Re-training INFO: iter: 268875/300480  CE: 2.1614  
[06/01 09:23:19] Re-training INFO: iter: 269000/300480  CE: 2.0187  
[06/01 09:24:44] Re-training INFO: iter: 269125/300480  CE: 2.1958  
[06/01 09:25:18] Re-training INFO: --> epoch: 215/240  avg CE: 2.1617  lr: 0.013267467626223606
[06/01 09:26:24] Re-training INFO: iter: 269250/300480  CE: 1.9810  
[06/01 09:27:47] Re-training INFO: iter: 269375/300480  CE: 2.0821  
[06/01 09:29:13] Re-training INFO: iter: 269500/300480  CE: 2.1513  
[06/01 09:30:37] Re-training INFO: iter: 269625/300480  CE: 2.1615  
[06/01 09:32:01] Re-training INFO: iter: 269750/300480  CE: 2.1439  
[06/01 09:33:24] Re-training INFO: iter: 269875/300480  CE: 2.1612  
[06/01 09:34:48] Re-training INFO: iter: 270000/300480  CE: 2.0239  
[06/01 09:36:13] Re-training INFO: iter: 270125/300480  CE: 1.9767  
[06/01 09:37:37] Re-training INFO: iter: 270250/300480  CE: 1.9536  
[06/01 09:39:01] Re-training INFO: iter: 270375/300480  CE: 2.2146  
[06/01 09:39:37] Re-training INFO: --> epoch: 216/240  avg CE: 2.1505  lr: 0.012235870926211617
[06/01 09:40:39] Re-training INFO: iter: 270500/300480  CE: 2.5447  
[06/01 09:42:03] Re-training INFO: iter: 270625/300480  CE: 2.1351  
[06/01 09:43:26] Re-training INFO: iter: 270750/300480  CE: 2.1769  
[06/01 09:44:50] Re-training INFO: iter: 270875/300480  CE: 2.4518  
[06/01 09:46:14] Re-training INFO: iter: 271000/300480  CE: 2.1945  
[06/01 09:47:38] Re-training INFO: iter: 271125/300480  CE: 2.0758  
[06/01 09:49:02] Re-training INFO: iter: 271250/300480  CE: 2.1653  
[06/01 09:50:26] Re-training INFO: iter: 271375/300480  CE: 2.0673  
[06/01 09:51:49] Re-training INFO: iter: 271500/300480  CE: 2.1308  
[06/01 09:53:14] Re-training INFO: iter: 271625/300480  CE: 2.2446  
[06/01 09:53:53] Re-training INFO: --> epoch: 217/240  avg CE: 2.1464  lr: 0.011245013885703342
[06/01 09:54:53] Re-training INFO: iter: 271750/300480  CE: 1.8805  
[06/01 09:56:17] Re-training INFO: iter: 271875/300480  CE: 2.0760  
[06/01 09:57:40] Re-training INFO: iter: 272000/300480  CE: 2.1846  
[06/01 09:59:05] Re-training INFO: iter: 272125/300480  CE: 2.2676  
[06/01 10:00:29] Re-training INFO: iter: 272250/300480  CE: 2.2897  
[06/01 10:01:53] Re-training INFO: iter: 272375/300480  CE: 1.9946  
[06/01 10:03:17] Re-training INFO: iter: 272500/300480  CE: 2.0710  
[06/01 10:04:41] Re-training INFO: iter: 272625/300480  CE: 2.0518  
[06/01 10:06:06] Re-training INFO: iter: 272750/300480  CE: 2.2091  
[06/01 10:07:30] Re-training INFO: iter: 272875/300480  CE: 2.0262  
[06/01 10:08:09] Re-training INFO: --> epoch: 218/240  avg CE: 2.1356  lr: 0.010295066282951765
[06/01 10:09:09] Re-training INFO: iter: 273000/300480  CE: 2.0210  
[06/01 10:10:34] Re-training INFO: iter: 273125/300480  CE: 2.3277  
[06/01 10:11:59] Re-training INFO: iter: 273250/300480  CE: 2.2216  
[06/01 10:13:24] Re-training INFO: iter: 273375/300480  CE: 2.1737  
[06/01 10:14:46] Re-training INFO: iter: 273500/300480  CE: 2.1070  
[06/01 10:16:11] Re-training INFO: iter: 273625/300480  CE: 2.1183  
[06/01 10:17:34] Re-training INFO: iter: 273750/300480  CE: 2.2050  
[06/01 10:18:57] Re-training INFO: iter: 273875/300480  CE: 1.9379  
[06/01 10:20:21] Re-training INFO: iter: 274000/300480  CE: 2.3522  
[06/01 10:21:44] Re-training INFO: iter: 274125/300480  CE: 2.1988  
[06/01 10:22:25] Re-training INFO: --> epoch: 219/240  avg CE: 2.1390  lr: 0.009386190886588208
[06/01 10:23:23] Re-training INFO: iter: 274250/300480  CE: 1.9752  
[06/01 10:24:48] Re-training INFO: iter: 274375/300480  CE: 2.0126  
[06/01 10:26:11] Re-training INFO: iter: 274500/300480  CE: 2.2208  
[06/01 10:27:35] Re-training INFO: iter: 274625/300480  CE: 2.1951  
[06/01 10:28:58] Re-training INFO: iter: 274750/300480  CE: 2.2269  
[06/01 10:30:23] Re-training INFO: iter: 274875/300480  CE: 2.0206  
[06/01 10:31:48] Re-training INFO: iter: 275000/300480  CE: 2.2102  
[06/01 10:33:12] Re-training INFO: iter: 275125/300480  CE: 2.1703  
[06/01 10:34:36] Re-training INFO: iter: 275250/300480  CE: 2.0993  
[06/01 10:35:58] Re-training INFO: iter: 275375/300480  CE: 1.9599  
[06/01 10:36:40] Re-training INFO: --> epoch: 220/240  avg CE: 2.1322  lr: 0.008518543427732922
[06/01 10:37:12] Re-training INFO: # of Test Samples: 50000.0
[06/01 10:37:12] Re-training INFO: Top-1/-5 acc: 73.61 / 91.67
[06/01 10:37:12] Re-training INFO: Top-1/-5 acc: 26.39 /  8.33
[06/01 10:37:12] Re-training INFO: 

[06/01 10:38:08] Re-training INFO: iter: 275500/300480  CE: 2.1261  
[06/01 10:39:31] Re-training INFO: iter: 275625/300480  CE: 2.1519  
[06/01 10:40:54] Re-training INFO: iter: 275750/300480  CE: 2.0898  
[06/01 10:42:18] Re-training INFO: iter: 275875/300480  CE: 2.0955  
[06/01 10:43:42] Re-training INFO: iter: 276000/300480  CE: 2.3696  
[06/01 10:45:06] Re-training INFO: iter: 276125/300480  CE: 2.0227  
[06/01 10:46:30] Re-training INFO: iter: 276250/300480  CE: 2.1255  
[06/01 10:47:55] Re-training INFO: iter: 276375/300480  CE: 2.2591  
[06/01 10:49:18] Re-training INFO: iter: 276500/300480  CE: 1.9795  
[06/01 10:50:41] Re-training INFO: iter: 276625/300480  CE: 2.0700  
[06/01 10:51:24] Re-training INFO: --> epoch: 221/240  avg CE: 2.1253  lr: 0.007692272573311426
[06/01 10:52:21] Re-training INFO: iter: 276750/300480  CE: 1.9840  
[06/01 10:53:45] Re-training INFO: iter: 276875/300480  CE: 2.2271  
[06/01 10:55:11] Re-training INFO: iter: 277000/300480  CE: 2.2771  
[06/01 10:56:35] Re-training INFO: iter: 277125/300480  CE: 2.3481  
[06/01 10:57:59] Re-training INFO: iter: 277250/300480  CE: 2.1860  
[06/01 10:59:23] Re-training INFO: iter: 277375/300480  CE: 2.0486  
[06/01 11:00:49] Re-training INFO: iter: 277500/300480  CE: 2.2812  
[06/01 11:02:12] Re-training INFO: iter: 277625/300480  CE: 2.2043  
[06/01 11:03:38] Re-training INFO: iter: 277750/300480  CE: 1.8967  
[06/01 11:05:02] Re-training INFO: iter: 277875/300480  CE: 1.9480  
[06/01 11:05:46] Re-training INFO: --> epoch: 222/240  avg CE: 2.1161  lr: 0.006907519900580861
[06/01 11:06:41] Re-training INFO: iter: 278000/300480  CE: 2.5004  
[06/01 11:08:05] Re-training INFO: iter: 278125/300480  CE: 1.9596  
[06/01 11:09:29] Re-training INFO: iter: 278250/300480  CE: 1.9994  
[06/01 11:10:54] Re-training INFO: iter: 278375/300480  CE: 2.2656  
[06/01 11:12:17] Re-training INFO: iter: 278500/300480  CE: 2.0118  
[06/01 11:13:40] Re-training INFO: iter: 278625/300480  CE: 2.1254  
[06/01 11:15:04] Re-training INFO: iter: 278750/300480  CE: 2.0269  
[06/01 11:16:27] Re-training INFO: iter: 278875/300480  CE: 2.0075  
[06/01 11:17:51] Re-training INFO: iter: 279000/300480  CE: 1.9891  
[06/01 11:19:14] Re-training INFO: iter: 279125/300480  CE: 2.1655  
[06/01 11:20:00] Re-training INFO: --> epoch: 223/240  avg CE: 2.1126  lr: 0.006164419872871835
[06/01 11:20:53] Re-training INFO: iter: 279250/300480  CE: 1.9551  
[06/01 11:22:16] Re-training INFO: iter: 279375/300480  CE: 2.0409  
[06/01 11:23:40] Re-training INFO: iter: 279500/300480  CE: 2.1020  
[06/01 11:25:04] Re-training INFO: iter: 279625/300480  CE: 2.1949  
[06/01 11:26:28] Re-training INFO: iter: 279750/300480  CE: 2.0446  
[06/01 11:27:53] Re-training INFO: iter: 279875/300480  CE: 1.9291  
[06/01 11:29:16] Re-training INFO: iter: 280000/300480  CE: 2.1150  
[06/01 11:30:40] Re-training INFO: iter: 280125/300480  CE: 1.9710  
[06/01 11:32:05] Re-training INFO: iter: 280250/300480  CE: 2.2111  
[06/01 11:33:30] Re-training INFO: iter: 280375/300480  CE: 2.0546  
[06/01 11:34:17] Re-training INFO: --> epoch: 224/240  avg CE: 2.1091  lr: 0.005463099816548578
[06/01 11:35:09] Re-training INFO: iter: 280500/300480  CE: 2.4207  
[06/01 11:36:32] Re-training INFO: iter: 280625/300480  CE: 2.2349  
[06/01 11:37:56] Re-training INFO: iter: 280750/300480  CE: 2.1278  
[06/01 11:39:20] Re-training INFO: iter: 280875/300480  CE: 1.7843  
[06/01 11:40:44] Re-training INFO: iter: 281000/300480  CE: 2.0327  
[06/01 11:42:08] Re-training INFO: iter: 281125/300480  CE: 2.0327  
[06/01 11:43:32] Re-training INFO: iter: 281250/300480  CE: 2.0976  
[06/01 11:44:57] Re-training INFO: iter: 281375/300480  CE: 2.0571  
[06/01 11:46:20] Re-training INFO: iter: 281500/300480  CE: 2.0728  
[06/01 11:47:45] Re-training INFO: iter: 281625/300480  CE: 1.9987  
[06/01 11:48:33] Re-training INFO: --> epoch: 225/240  avg CE: 2.1098  lr: 0.004803679899192392
[06/01 11:49:24] Re-training INFO: iter: 281750/300480  CE: 2.2357  
[06/01 11:50:47] Re-training INFO: iter: 281875/300480  CE: 2.0640  
[06/01 11:52:11] Re-training INFO: iter: 282000/300480  CE: 2.3620  
[06/01 11:53:34] Re-training INFO: iter: 282125/300480  CE: 2.2802  
[06/01 11:54:58] Re-training INFO: iter: 282250/300480  CE: 2.1108  
[06/01 11:56:23] Re-training INFO: iter: 282375/300480  CE: 2.0745  
[06/01 11:57:47] Re-training INFO: iter: 282500/300480  CE: 1.9776  
[06/01 11:59:10] Re-training INFO: iter: 282625/300480  CE: 2.1807  
[06/01 12:00:34] Re-training INFO: iter: 282750/300480  CE: 2.1585  
[06/01 12:01:58] Re-training INFO: iter: 282875/300480  CE: 2.0479  
[06/01 12:02:48] Re-training INFO: --> epoch: 226/240  avg CE: 2.1075  lr: 0.004186273109011374
[06/01 12:03:37] Re-training INFO: iter: 283000/300480  CE: 2.1527  
[06/01 12:05:03] Re-training INFO: iter: 283125/300480  CE: 2.2405  
[06/01 12:06:26] Re-training INFO: iter: 283250/300480  CE: 2.0676  
[06/01 12:07:50] Re-training INFO: iter: 283375/300480  CE: 2.1707  
[06/01 12:09:13] Re-training INFO: iter: 283500/300480  CE: 2.1563  
[06/01 12:10:37] Re-training INFO: iter: 283625/300480  CE: 2.2101  
[06/01 12:12:01] Re-training INFO: iter: 283750/300480  CE: 2.0983  
[06/01 12:13:25] Re-training INFO: iter: 283875/300480  CE: 2.0174  
[06/01 12:14:50] Re-training INFO: iter: 284000/300480  CE: 1.9971  
[06/01 12:16:13] Re-training INFO: iter: 284125/300480  CE: 2.0239  
[06/01 12:17:03] Re-training INFO: --> epoch: 227/240  avg CE: 2.0997  lr: 0.0036109852354805627
[06/01 12:17:51] Re-training INFO: iter: 284250/300480  CE: 1.9622  
[06/01 12:19:15] Re-training INFO: iter: 284375/300480  CE: 2.1204  
[06/01 12:20:39] Re-training INFO: iter: 284500/300480  CE: 2.0933  
[06/01 12:22:04] Re-training INFO: iter: 284625/300480  CE: 1.9507  
[06/01 12:23:27] Re-training INFO: iter: 284750/300480  CE: 2.0406  
[06/01 12:24:51] Re-training INFO: iter: 284875/300480  CE: 2.0795  
[06/01 12:26:16] Re-training INFO: iter: 285000/300480  CE: 2.1166  
[06/01 12:27:40] Re-training INFO: iter: 285125/300480  CE: 2.1566  
[06/01 12:29:04] Re-training INFO: iter: 285250/300480  CE: 2.3201  
[06/01 12:30:28] Re-training INFO: iter: 285375/300480  CE: 2.2207  
[06/01 12:31:20] Re-training INFO: --> epoch: 228/240  avg CE: 2.0969  lr: 0.003077914851215585
[06/01 12:32:06] Re-training INFO: iter: 285500/300480  CE: 2.0686  
[06/01 12:33:33] Re-training INFO: iter: 285625/300480  CE: 2.2258  
[06/01 12:34:56] Re-training INFO: iter: 285750/300480  CE: 2.0639  
[06/01 12:36:20] Re-training INFO: iter: 285875/300480  CE: 2.0814  
[06/01 12:37:44] Re-training INFO: iter: 286000/300480  CE: 2.0196  
[06/01 12:39:08] Re-training INFO: iter: 286125/300480  CE: 2.1027  
[06/01 12:40:32] Re-training INFO: iter: 286250/300480  CE: 2.3701  
[06/01 12:41:55] Re-training INFO: iter: 286375/300480  CE: 2.2110  
[06/01 12:43:18] Re-training INFO: iter: 286500/300480  CE: 2.0275  
[06/01 12:44:41] Re-training INFO: iter: 286625/300480  CE: 1.9924  
[06/01 12:45:36] Re-training INFO: --> epoch: 229/240  avg CE: 2.0959  lr: 0.0025871532950824394
[06/01 12:46:21] Re-training INFO: iter: 286750/300480  CE: 2.2137  
[06/01 12:47:45] Re-training INFO: iter: 286875/300480  CE: 2.1554  
[06/01 12:49:09] Re-training INFO: iter: 287000/300480  CE: 2.0721  
[06/01 12:50:33] Re-training INFO: iter: 287125/300480  CE: 2.0134  
[06/01 12:51:57] Re-training INFO: iter: 287250/300480  CE: 2.3296  
[06/01 12:53:22] Re-training INFO: iter: 287375/300480  CE: 2.2195  
[06/01 12:54:46] Re-training INFO: iter: 287500/300480  CE: 2.1967  
[06/01 12:56:10] Re-training INFO: iter: 287625/300480  CE: 2.1935  
[06/01 12:57:34] Re-training INFO: iter: 287750/300480  CE: 1.9282  
[06/01 12:58:58] Re-training INFO: iter: 287875/300480  CE: 2.0822  
[06/01 12:59:53] Re-training INFO: --> epoch: 230/240  avg CE: 2.0849  lr: 0.0021387846565474045
[06/01 13:00:38] Re-training INFO: iter: 288000/300480  CE: 2.0994  
[06/01 13:02:02] Re-training INFO: iter: 288125/300480  CE: 1.9755  
[06/01 13:03:27] Re-training INFO: iter: 288250/300480  CE: 1.9941  
[06/01 13:04:50] Re-training INFO: iter: 288375/300480  CE: 1.9334  
[06/01 13:06:14] Re-training INFO: iter: 288500/300480  CE: 2.0892  
[06/01 13:07:38] Re-training INFO: iter: 288625/300480  CE: 2.1023  
[06/01 13:09:03] Re-training INFO: iter: 288750/300480  CE: 1.8950  
[06/01 13:10:27] Re-training INFO: iter: 288875/300480  CE: 2.1151  
[06/01 13:11:51] Re-training INFO: iter: 289000/300480  CE: 1.8972  
[06/01 13:13:15] Re-training INFO: iter: 289125/300480  CE: 2.0646  
[06/01 13:14:12] Re-training INFO: --> epoch: 231/240  avg CE: 2.0801  lr: 0.0017328857612684267
[06/01 13:14:54] Re-training INFO: iter: 289250/300480  CE: 2.1973  
[06/01 13:16:18] Re-training INFO: iter: 289375/300480  CE: 2.2506  
[06/01 13:17:41] Re-training INFO: iter: 289500/300480  CE: 2.1421  
[06/01 13:19:05] Re-training INFO: iter: 289625/300480  CE: 2.3229  
[06/01 13:20:28] Re-training INFO: iter: 289750/300480  CE: 2.1634  
[06/01 13:21:52] Re-training INFO: iter: 289875/300480  CE: 2.1955  
[06/01 13:23:16] Re-training INFO: iter: 290000/300480  CE: 2.2737  
[06/01 13:24:40] Re-training INFO: iter: 290125/300480  CE: 1.9862  
[06/01 13:26:04] Re-training INFO: iter: 290250/300480  CE: 2.1747  
[06/01 13:27:30] Re-training INFO: iter: 290375/300480  CE: 2.1584  
[06/01 13:28:28] Re-training INFO: --> epoch: 232/240  avg CE: 2.0860  lr: 0.0013695261579316775
[06/01 13:29:09] Re-training INFO: iter: 290500/300480  CE: 1.9557  
[06/01 13:30:33] Re-training INFO: iter: 290625/300480  CE: 2.0511  
[06/01 13:31:58] Re-training INFO: iter: 290750/300480  CE: 1.9901  
[06/01 13:33:20] Re-training INFO: iter: 290875/300480  CE: 2.0251  
[06/01 13:34:45] Re-training INFO: iter: 291000/300480  CE: 1.9233  
[06/01 13:36:09] Re-training INFO: iter: 291125/300480  CE: 2.1369  
[06/01 13:37:33] Re-training INFO: iter: 291250/300480  CE: 2.1215  
[06/01 13:38:58] Re-training INFO: iter: 291375/300480  CE: 1.8578  
[06/01 13:40:21] Re-training INFO: iter: 291500/300480  CE: 2.0793  
[06/01 13:41:45] Re-training INFO: iter: 291625/300480  CE: 1.8596  
[06/01 13:42:45] Re-training INFO: --> epoch: 233/240  avg CE: 2.0798  lr: 0.0010487681063345855
[06/01 13:43:26] Re-training INFO: iter: 291750/300480  CE: 2.0480  
[06/01 13:44:50] Re-training INFO: iter: 291875/300480  CE: 2.0553  
[06/01 13:46:15] Re-training INFO: iter: 292000/300480  CE: 1.8503  
[06/01 13:47:39] Re-training INFO: iter: 292125/300480  CE: 2.0575  
[06/01 13:49:03] Re-training INFO: iter: 292250/300480  CE: 1.9934  
[06/01 13:50:28] Re-training INFO: iter: 292375/300480  CE: 2.2220  
[06/01 13:51:52] Re-training INFO: iter: 292500/300480  CE: 2.2030  
[06/01 13:53:16] Re-training INFO: iter: 292625/300480  CE: 2.1012  
[06/01 13:54:41] Re-training INFO: iter: 292750/300480  CE: 2.1861  
[06/01 13:56:06] Re-training INFO: iter: 292875/300480  CE: 2.0244  
[06/01 13:57:06] Re-training INFO: --> epoch: 234/240  avg CE: 2.0810  lr: 0.000770666566718009
[06/01 13:57:45] Re-training INFO: iter: 293000/300480  CE: 1.9448  
[06/01 13:59:10] Re-training INFO: iter: 293125/300480  CE: 2.1120  
[06/01 14:00:34] Re-training INFO: iter: 293250/300480  CE: 2.0614  
[06/01 14:01:57] Re-training INFO: iter: 293375/300480  CE: 2.1646  
[06/01 14:03:23] Re-training INFO: iter: 293500/300480  CE: 1.9192  
[06/01 14:04:45] Re-training INFO: iter: 293625/300480  CE: 2.0670  
[06/01 14:06:08] Re-training INFO: iter: 293750/300480  CE: 1.9415  
[06/01 14:07:31] Re-training INFO: iter: 293875/300480  CE: 2.0863  
[06/01 14:08:55] Re-training INFO: iter: 294000/300480  CE: 1.9418  
[06/01 14:10:19] Re-training INFO: iter: 294125/300480  CE: 2.2001  
[06/01 14:11:21] Re-training INFO: --> epoch: 235/240  avg CE: 2.0817  lr: 0.0005352691903491302
[06/01 14:11:58] Re-training INFO: iter: 294250/300480  CE: 1.7249  
[06/01 14:13:23] Re-training INFO: iter: 294375/300480  CE: 2.0136  
[06/01 14:14:47] Re-training INFO: iter: 294500/300480  CE: 2.4567  
[06/01 14:16:12] Re-training INFO: iter: 294625/300480  CE: 2.2197  
[06/01 14:17:36] Re-training INFO: iter: 294750/300480  CE: 2.0870  
[06/01 14:18:59] Re-training INFO: iter: 294875/300480  CE: 2.2813  
[06/01 14:20:24] Re-training INFO: iter: 295000/300480  CE: 2.0772  
[06/01 14:21:47] Re-training INFO: iter: 295125/300480  CE: 2.0385  
[06/01 14:23:11] Re-training INFO: iter: 295250/300480  CE: 2.3823  
[06/01 14:24:34] Re-training INFO: iter: 295375/300480  CE: 2.2345  
[06/01 14:25:38] Re-training INFO: --> epoch: 236/240  avg CE: 2.0793  lr: 0.0003426163113565417
[06/01 14:26:13] Re-training INFO: iter: 295500/300480  CE: 1.8181  
[06/01 14:27:38] Re-training INFO: iter: 295625/300480  CE: 1.8049  
[06/01 14:29:02] Re-training INFO: iter: 295750/300480  CE: 2.0681  
[06/01 14:30:26] Re-training INFO: iter: 295875/300480  CE: 2.1237  
[06/01 14:31:50] Re-training INFO: iter: 296000/300480  CE: 2.2397  
[06/01 14:33:13] Re-training INFO: iter: 296125/300480  CE: 2.3122  
[06/01 14:34:37] Re-training INFO: iter: 296250/300480  CE: 2.1971  
[06/01 14:36:01] Re-training INFO: iter: 296375/300480  CE: 2.1929  
[06/01 14:37:25] Re-training INFO: iter: 296500/300480  CE: 2.0193  
[06/01 14:38:50] Re-training INFO: iter: 296625/300480  CE: 1.9927  
[06/01 14:39:54] Re-training INFO: --> epoch: 237/240  avg CE: 2.0767  lr: 0.00019274093981927476
[06/01 14:40:27] Re-training INFO: iter: 296750/300480  CE: 2.2606  
[06/01 14:41:50] Re-training INFO: iter: 296875/300480  CE: 2.0053  
[06/01 14:43:16] Re-training INFO: iter: 297000/300480  CE: 1.8980  
[06/01 14:44:39] Re-training INFO: iter: 297125/300480  CE: 2.1198  
[06/01 14:46:04] Re-training INFO: iter: 297250/300480  CE: 2.1981  
[06/01 14:47:28] Re-training INFO: iter: 297375/300480  CE: 2.0711  
[06/01 14:48:53] Re-training INFO: iter: 297500/300480  CE: 2.1700  
[06/01 14:50:18] Re-training INFO: iter: 297625/300480  CE: 2.4124  
[06/01 14:51:41] Re-training INFO: iter: 297750/300480  CE: 2.0360  
[06/01 14:53:06] Re-training INFO: iter: 297875/300480  CE: 1.9249  
[06/01 14:54:12] Re-training INFO: --> epoch: 238/240  avg CE: 2.0776  lr: 8.566875611068503e-05
[06/01 14:54:44] Re-training INFO: iter: 298000/300480  CE: 1.9637  
[06/01 14:56:09] Re-training INFO: iter: 298125/300480  CE: 2.2822  
[06/01 14:57:33] Re-training INFO: iter: 298250/300480  CE: 1.9522  
[06/01 14:58:56] Re-training INFO: iter: 298375/300480  CE: 2.0519  
[06/01 15:00:21] Re-training INFO: iter: 298500/300480  CE: 1.9025  
[06/01 15:01:45] Re-training INFO: iter: 298625/300480  CE: 1.8104  
[06/01 15:03:09] Re-training INFO: iter: 298750/300480  CE: 2.0394  
[06/01 15:04:33] Re-training INFO: iter: 298875/300480  CE: 2.1011  
[06/01 15:05:57] Re-training INFO: iter: 299000/300480  CE: 1.9179  
[06/01 15:07:22] Re-training INFO: iter: 299125/300480  CE: 2.1616  
[06/01 15:08:29] Re-training INFO: --> epoch: 239/240  avg CE: 2.0744  lr: 2.1418106498249934e-05
[06/01 15:09:01] Re-training INFO: iter: 299250/300480  CE: 1.8062  
[06/01 15:10:26] Re-training INFO: iter: 299375/300480  CE: 2.0739  
[06/01 15:11:51] Re-training INFO: iter: 299500/300480  CE: 2.0767  
[06/01 15:13:16] Re-training INFO: iter: 299625/300480  CE: 2.0436  
[06/01 15:14:42] Re-training INFO: iter: 299750/300480  CE: 1.9851  
[06/01 15:16:06] Re-training INFO: iter: 299875/300480  CE: 1.9078  
[06/01 15:17:32] Re-training INFO: iter: 300000/300480  CE: 2.1834  
[06/01 15:18:56] Re-training INFO: iter: 300125/300480  CE: 2.0488  
[06/01 15:20:20] Re-training INFO: iter: 300250/300480  CE: 1.8921  
[06/01 15:21:45] Re-training INFO: iter: 300375/300480  CE: 2.1018  
[06/01 15:22:55] Re-training INFO: --> epoch: 240/240  avg CE: 2.0772  lr: 0.0
[06/01 15:23:27] Re-training INFO: # of Test Samples: 50000.0
[06/01 15:23:27] Re-training INFO: Top-1/-5 acc: 74.15 / 91.99
[06/01 15:23:27] Re-training INFO: Top-1/-5 acc: 25.85 /  8.01
[06/01 15:23:27] Re-training INFO: 

[06/01 15:24:00] Re-training INFO: # of Test Samples: 50000.0
[06/01 15:24:00] Re-training INFO: Top-1/-5 acc: 74.15 / 91.99
[06/01 15:24:00] Re-training INFO: Top-1/-5 acc: 25.85 /  8.01
[06/01 15:24:00] Re-training INFO: --> END Retrain-mobile1-k2r-div4-TBS-seed-0
[06/01 15:24:02] Re-training INFO: ELAPSED TIME: 206296.9(s) = 57(h) 18(m)
