[06/15 00:06:07] Re-training INFO: tag                 : mobile1-k4r
[06/15 00:06:07] Re-training INFO: arch                : [0, 2, 6, 0, 4, 0, 2, 2, 3, 4, 4, 6, 2, 0, 4, 2, 5, 3, 2, 0, 5]
[06/15 00:06:07] Re-training INFO: seed                : 0
[06/15 00:06:07] Re-training INFO: data_path           : ../../../dataset/ILSVRC2012
[06/15 00:06:07] Re-training INFO: save_path           : ./Evaluation
[06/15 00:06:07] Re-training INFO: search_space        : proxyless
[06/15 00:06:07] Re-training INFO: valid_size          : 0
[06/15 00:06:07] Re-training INFO: num_gpus            : 8
[06/15 00:06:07] Re-training INFO: workers             : 4
[06/15 00:06:07] Re-training INFO: interval_ep_eval    : 20
[06/15 00:06:07] Re-training INFO: train_batch_size    : 1024
[06/15 00:06:07] Re-training INFO: test_batch_size     : 256
[06/15 00:06:07] Re-training INFO: max_epoch           : 240
[06/15 00:06:07] Re-training INFO: learning_rate       : 0.5
[06/15 00:06:07] Re-training INFO: momentum            : 0.9
[06/15 00:06:07] Re-training INFO: weight_decay        : 4e-05
[06/15 00:06:07] Re-training INFO: nesterov            : True
[06/15 00:06:07] Re-training INFO: lr_schedule_type    : cosine
[06/15 00:06:07] Re-training INFO: warmup              : False
[06/15 00:06:07] Re-training INFO: drop_out            : 0.2
[06/15 00:06:07] Re-training INFO: label_smooth        : 0.1
[06/15 00:06:07] Re-training INFO: rank                : 0
[06/15 00:06:07] Re-training INFO: gpu                 : 0
[06/15 00:06:07] Re-training INFO: save_name           : Retrain-mobile1-k4r-seed-0
[06/15 00:06:07] Re-training INFO: log_path            : ./Evaluation/logs/Retrain-mobile1-k4r-seed-0.txt
[06/15 00:06:07] Re-training INFO: ckpt_path           : ./Evaluation/checkpoint/Retrain-mobile1-k4r-seed-0.pt
[06/15 00:06:07] Re-training INFO: dist_url            : tcp://127.0.0.1:23456
[06/15 00:06:07] Re-training INFO: world_size          : 8
[06/15 00:06:07] Re-training INFO: distributed         : True
[06/15 00:06:07] Re-training INFO: ['3x3_MBConv3', '3x3_MBConv6', '5x5_MBConv3', '5x5_MBConv6', '7x7_MBConv3', '7x7_MBConv6', 'Identity']
[06/15 00:06:14] Re-training INFO: # of Params : 3.938
[06/15 00:06:15] Re-training INFO: DistributedDataParallel(
  (module): CNN(
    (first_conv): Sequential(
      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU6(inplace=True)
    )
    (first_block): InvertedResidual(
      (depth_conv): Sequential(
        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
        (1): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (2): ReLU6(inplace=True)
      )
      (point_linear): Sequential(
        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): SyncBatchNorm(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (blocks): ModuleList(
      (0): InvertedResidual(
        (inverted_bottleneck): Sequential(
          (0): Conv2d(16, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (depth_conv): Sequential(
          (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=48, bias=False)
          (1): SyncBatchNorm(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (point_linear): Sequential(
          (0): Conv2d(48, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): InvertedResidual(
        (inverted_bottleneck): Sequential(
          (0): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (depth_conv): Sequential(
          (0): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=96, bias=False)
          (1): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (point_linear): Sequential(
          (0): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (2): Identity()
      (3): InvertedResidual(
        (inverted_bottleneck): Sequential(
          (0): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (depth_conv): Sequential(
          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
          (1): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (point_linear): Sequential(
          (0): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (4): InvertedResidual(
        (inverted_bottleneck): Sequential(
          (0): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (depth_conv): Sequential(
          (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=96, bias=False)
          (1): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (point_linear): Sequential(
          (0): Conv2d(96, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (5): InvertedResidual(
        (inverted_bottleneck): Sequential(
          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (depth_conv): Sequential(
          (0): Conv2d(120, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=120, bias=False)
          (1): SyncBatchNorm(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (point_linear): Sequential(
          (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (6): InvertedResidual(
        (inverted_bottleneck): Sequential(
          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (depth_conv): Sequential(
          (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)
          (1): SyncBatchNorm(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (point_linear): Sequential(
          (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (7): InvertedResidual(
        (inverted_bottleneck): Sequential(
          (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (depth_conv): Sequential(
          (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)
          (1): SyncBatchNorm(120, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (point_linear): Sequential(
          (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (8): InvertedResidual(
        (inverted_bottleneck): Sequential(
          (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (depth_conv): Sequential(
          (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=240, bias=False)
          (1): SyncBatchNorm(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (point_linear): Sequential(
          (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (9): InvertedResidual(
        (inverted_bottleneck): Sequential(
          (0): Conv2d(80, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (depth_conv): Sequential(
          (0): Conv2d(240, 240, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=240, bias=False)
          (1): SyncBatchNorm(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (point_linear): Sequential(
          (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (10): InvertedResidual(
        (inverted_bottleneck): Sequential(
          (0): Conv2d(80, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (depth_conv): Sequential(
          (0): Conv2d(240, 240, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=240, bias=False)
          (1): SyncBatchNorm(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (point_linear): Sequential(
          (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (11): Identity()
      (12): InvertedResidual(
        (inverted_bottleneck): Sequential(
          (0): Conv2d(80, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (depth_conv): Sequential(
          (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)
          (1): SyncBatchNorm(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (point_linear): Sequential(
          (0): Conv2d(240, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (13): InvertedResidual(
        (inverted_bottleneck): Sequential(
          (0): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (depth_conv): Sequential(
          (0): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
          (1): SyncBatchNorm(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (point_linear): Sequential(
          (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (14): InvertedResidual(
        (inverted_bottleneck): Sequential(
          (0): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (depth_conv): Sequential(
          (0): Conv2d(288, 288, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=288, bias=False)
          (1): SyncBatchNorm(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (point_linear): Sequential(
          (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (15): InvertedResidual(
        (inverted_bottleneck): Sequential(
          (0): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (depth_conv): Sequential(
          (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)
          (1): SyncBatchNorm(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (point_linear): Sequential(
          (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (16): InvertedResidual(
        (inverted_bottleneck): Sequential(
          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (depth_conv): Sequential(
          (0): Conv2d(576, 576, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=576, bias=False)
          (1): SyncBatchNorm(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (point_linear): Sequential(
          (0): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (17): InvertedResidual(
        (inverted_bottleneck): Sequential(
          (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (depth_conv): Sequential(
          (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)
          (1): SyncBatchNorm(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (point_linear): Sequential(
          (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (18): InvertedResidual(
        (inverted_bottleneck): Sequential(
          (0): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (depth_conv): Sequential(
          (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)
          (1): SyncBatchNorm(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (point_linear): Sequential(
          (0): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (19): InvertedResidual(
        (inverted_bottleneck): Sequential(
          (0): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (depth_conv): Sequential(
          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
          (1): SyncBatchNorm(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (point_linear): Sequential(
          (0): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (20): InvertedResidual(
        (inverted_bottleneck): Sequential(
          (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (depth_conv): Sequential(
          (0): Conv2d(1152, 1152, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1152, bias=False)
          (1): SyncBatchNorm(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (2): ReLU6(inplace=True)
        )
        (point_linear): Sequential(
          (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): SyncBatchNorm(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
    )
    (feature_mix_layer): Sequential(
      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): SyncBatchNorm(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU6(inplace=True)
    )
    (avgpool): AvgPool2d(kernel_size=7, stride=7, padding=0)
    (classifier): Sequential(
      (0): Dropout(p=0.2, inplace=False)
      (1): Linear(in_features=1280, out_features=1000, bias=True)
    )
  )
)
[06/15 00:06:20] Re-training INFO: Trainset Size: 1281167
[06/15 00:06:20] Re-training INFO: Validset Size:   50000
[06/15 00:06:20] Re-training INFO: Compose(
    RandomResizedCrop(size=(224, 224), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=bilinear)
    RandomHorizontalFlip(p=0.5)
    ColorJitter(brightness=[0.6, 1.4], contrast=[0.6, 1.4], saturation=[0.6, 1.4], hue=[-0.1, 0.1])
    ToTensor()
    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
)
[06/15 00:06:20] Re-training INFO: SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.5
    lr: 0.5
    momentum: 0.9
    nesterov: True
    weight_decay: 4e-05

Parameter Group 1
    dampening: 0
    initial_lr: 0.5
    lr: 0.5
    momentum: 0.9
    nesterov: True
    weight_decay: 0.0
)
[06/15 00:06:20] Re-training INFO: <torch.optim.lr_scheduler.CosineAnnealingLR object at 0x7f0068141520>
[06/15 00:06:20] Re-training INFO: --> START Retrain-mobile1-k4r-seed-0
[06/15 00:08:11] Re-training INFO: iter:   125/300480  CE: 6.5470  
[06/15 00:09:35] Re-training INFO: iter:   250/300480  CE: 6.0914  
[06/15 00:10:59] Re-training INFO: iter:   375/300480  CE: 5.7250  
[06/15 00:12:23] Re-training INFO: iter:   500/300480  CE: 5.7137  
[06/15 00:13:46] Re-training INFO: iter:   625/300480  CE: 5.3993  
[06/15 00:15:11] Re-training INFO: iter:   750/300480  CE: 4.7753  
[06/15 00:16:35] Re-training INFO: iter:   875/300480  CE: 5.2402  
[06/15 00:17:58] Re-training INFO: iter:  1000/300480  CE: 4.8396  
[06/15 00:19:21] Re-training INFO: iter:  1125/300480  CE: 4.4067  
[06/15 00:20:45] Re-training INFO: iter:  1250/300480  CE: 4.6822  
[06/15 00:20:46] Re-training INFO: --> epoch:   1/240  avg CE: 5.5067  lr: 0.49997858189350175
[06/15 00:22:24] Re-training INFO: iter:  1375/300480  CE: 4.5367  
[06/15 00:23:49] Re-training INFO: iter:  1500/300480  CE: 4.5531  
[06/15 00:25:14] Re-training INFO: iter:  1625/300480  CE: 4.5892  
[06/15 00:26:38] Re-training INFO: iter:  1750/300480  CE: 4.5083  
[06/15 00:28:01] Re-training INFO: iter:  1875/300480  CE: 3.9654  
[06/15 00:29:25] Re-training INFO: iter:  2000/300480  CE: 4.2876  
[06/15 00:30:49] Re-training INFO: iter:  2125/300480  CE: 4.1117  
[06/15 00:32:12] Re-training INFO: iter:  2250/300480  CE: 4.3185  
[06/15 00:33:37] Re-training INFO: iter:  2375/300480  CE: 3.9668  
[06/15 00:35:00] Re-training INFO: iter:  2500/300480  CE: 4.0877  
[06/15 00:35:01] Re-training INFO: --> epoch:   2/240  avg CE: 4.2750  lr: 0.4999143312438893
[06/15 00:36:39] Re-training INFO: iter:  2625/300480  CE: 4.0000  
[06/15 00:38:03] Re-training INFO: iter:  2750/300480  CE: 3.6160  
[06/15 00:39:25] Re-training INFO: iter:  2875/300480  CE: 3.8287  
[06/15 00:40:49] Re-training INFO: iter:  3000/300480  CE: 4.0194  
[06/15 00:42:14] Re-training INFO: iter:  3125/300480  CE: 4.0195  
[06/15 00:43:37] Re-training INFO: iter:  3250/300480  CE: 3.7553  
[06/15 00:45:01] Re-training INFO: iter:  3375/300480  CE: 3.8662  
[06/15 00:46:25] Re-training INFO: iter:  3500/300480  CE: 3.8410  
[06/15 00:47:48] Re-training INFO: iter:  3625/300480  CE: 3.7621  
[06/15 00:49:12] Re-training INFO: iter:  3750/300480  CE: 3.9260  
[06/15 00:49:14] Re-training INFO: --> epoch:   3/240  avg CE: 3.8415  lr: 0.49980725906018075
[06/15 00:50:51] Re-training INFO: iter:  3875/300480  CE: 3.7731  
[06/15 00:52:14] Re-training INFO: iter:  4000/300480  CE: 3.6735  
[06/15 00:53:39] Re-training INFO: iter:  4125/300480  CE: 3.7651  
[06/15 00:55:03] Re-training INFO: iter:  4250/300480  CE: 3.4478  
[06/15 00:56:27] Re-training INFO: iter:  4375/300480  CE: 3.6566  
[06/15 00:57:51] Re-training INFO: iter:  4500/300480  CE: 3.6372  
[06/15 00:59:14] Re-training INFO: iter:  4625/300480  CE: 3.2656  
[06/15 01:00:37] Re-training INFO: iter:  4750/300480  CE: 3.8093  
[06/15 01:02:01] Re-training INFO: iter:  4875/300480  CE: 3.6329  
[06/15 01:03:25] Re-training INFO: iter:  5000/300480  CE: 3.4346  
[06/15 01:03:28] Re-training INFO: --> epoch:   4/240  avg CE: 3.6190  lr: 0.49965738368864343
[06/15 01:05:03] Re-training INFO: iter:  5125/300480  CE: 3.3846  
[06/15 01:06:26] Re-training INFO: iter:  5250/300480  CE: 3.3684  
[06/15 01:07:51] Re-training INFO: iter:  5375/300480  CE: 3.4765  
[06/15 01:09:14] Re-training INFO: iter:  5500/300480  CE: 3.3317  
[06/15 01:10:38] Re-training INFO: iter:  5625/300480  CE: 3.4399  
[06/15 01:12:03] Re-training INFO: iter:  5750/300480  CE: 2.9585  
[06/15 01:13:26] Re-training INFO: iter:  5875/300480  CE: 3.4407  
[06/15 01:14:51] Re-training INFO: iter:  6000/300480  CE: 3.2417  
[06/15 01:16:12] Re-training INFO: iter:  6125/300480  CE: 3.1628  
[06/15 01:17:37] Re-training INFO: iter:  6250/300480  CE: 3.4019  
[06/15 01:17:42] Re-training INFO: --> epoch:   5/240  avg CE: 3.4744  lr: 0.49946473080965087
[06/15 01:19:16] Re-training INFO: iter:  6375/300480  CE: 3.5233  
[06/15 01:20:38] Re-training INFO: iter:  6500/300480  CE: 3.1437  
[06/15 01:22:02] Re-training INFO: iter:  6625/300480  CE: 3.3318  
[06/15 01:23:26] Re-training INFO: iter:  6750/300480  CE: 3.5117  
[06/15 01:24:49] Re-training INFO: iter:  6875/300480  CE: 3.3990  
[06/15 01:26:13] Re-training INFO: iter:  7000/300480  CE: 3.4585  
[06/15 01:27:37] Re-training INFO: iter:  7125/300480  CE: 3.4456  
[06/15 01:29:01] Re-training INFO: iter:  7250/300480  CE: 3.2981  
[06/15 01:30:25] Re-training INFO: iter:  7375/300480  CE: 3.4711  
[06/15 01:31:48] Re-training INFO: iter:  7500/300480  CE: 3.3558  
[06/15 01:31:54] Re-training INFO: --> epoch:   6/240  avg CE: 3.3847  lr: 0.499229333433282
[06/15 01:33:26] Re-training INFO: iter:  7625/300480  CE: 3.0362  
[06/15 01:34:49] Re-training INFO: iter:  7750/300480  CE: 3.4120  
[06/15 01:36:12] Re-training INFO: iter:  7875/300480  CE: 3.4215  
[06/15 01:37:36] Re-training INFO: iter:  8000/300480  CE: 3.2731  
[06/15 01:39:01] Re-training INFO: iter:  8125/300480  CE: 3.3394  
[06/15 01:40:25] Re-training INFO: iter:  8250/300480  CE: 3.1272  
[06/15 01:41:49] Re-training INFO: iter:  8375/300480  CE: 3.3951  
[06/15 01:43:13] Re-training INFO: iter:  8500/300480  CE: 3.3081  
[06/15 01:44:36] Re-training INFO: iter:  8625/300480  CE: 3.4036  
[06/15 01:45:59] Re-training INFO: iter:  8750/300480  CE: 3.3223  
[06/15 01:46:07] Re-training INFO: --> epoch:   7/240  avg CE: 3.3162  lr: 0.4989512318936654
[06/15 01:47:38] Re-training INFO: iter:  8875/300480  CE: 3.1069  
[06/15 01:49:00] Re-training INFO: iter:  9000/300480  CE: 3.2525  
[06/15 01:50:25] Re-training INFO: iter:  9125/300480  CE: 3.2997  
[06/15 01:51:49] Re-training INFO: iter:  9250/300480  CE: 3.2184  
[06/15 01:53:12] Re-training INFO: iter:  9375/300480  CE: 3.0969  
[06/15 01:54:34] Re-training INFO: iter:  9500/300480  CE: 3.2059  
[06/15 01:55:58] Re-training INFO: iter:  9625/300480  CE: 3.1472  
[06/15 01:57:22] Re-training INFO: iter:  9750/300480  CE: 3.0523  
[06/15 01:58:45] Re-training INFO: iter:  9875/300480  CE: 3.3953  
[06/15 02:00:09] Re-training INFO: iter: 10000/300480  CE: 3.1699  
[06/15 02:00:18] Re-training INFO: --> epoch:   8/240  avg CE: 3.2555  lr: 0.4986304738420683
[06/15 02:01:48] Re-training INFO: iter: 10125/300480  CE: 3.0216  
[06/15 02:03:11] Re-training INFO: iter: 10250/300480  CE: 3.1603  
[06/15 02:04:36] Re-training INFO: iter: 10375/300480  CE: 2.9915  
[06/15 02:05:59] Re-training INFO: iter: 10500/300480  CE: 3.0822  
[06/15 02:07:22] Re-training INFO: iter: 10625/300480  CE: 3.3190  
[06/15 02:08:47] Re-training INFO: iter: 10750/300480  CE: 2.9705  
[06/15 02:10:09] Re-training INFO: iter: 10875/300480  CE: 3.0284  
[06/15 02:11:33] Re-training INFO: iter: 11000/300480  CE: 3.4920  
[06/15 02:12:56] Re-training INFO: iter: 11125/300480  CE: 3.1842  
[06/15 02:14:19] Re-training INFO: iter: 11250/300480  CE: 3.1564  
[06/15 02:14:30] Re-training INFO: --> epoch:   9/240  avg CE: 3.2270  lr: 0.4982671142387316
[06/15 02:15:58] Re-training INFO: iter: 11375/300480  CE: 2.9560  
[06/15 02:17:22] Re-training INFO: iter: 11500/300480  CE: 3.1435  
[06/15 02:18:45] Re-training INFO: iter: 11625/300480  CE: 3.0667  
[06/15 02:20:09] Re-training INFO: iter: 11750/300480  CE: 3.1520  
[06/15 02:21:31] Re-training INFO: iter: 11875/300480  CE: 3.0946  
[06/15 02:22:55] Re-training INFO: iter: 12000/300480  CE: 3.1146  
[06/15 02:24:18] Re-training INFO: iter: 12125/300480  CE: 3.1902  
[06/15 02:25:41] Re-training INFO: iter: 12250/300480  CE: 3.0402  
[06/15 02:27:04] Re-training INFO: iter: 12375/300480  CE: 3.0812  
[06/15 02:28:27] Re-training INFO: iter: 12500/300480  CE: 3.2315  
[06/15 02:28:39] Re-training INFO: --> epoch:  10/240  avg CE: 3.1891  lr: 0.4978612153434526
[06/15 02:30:05] Re-training INFO: iter: 12625/300480  CE: 2.9442  
[06/15 02:31:28] Re-training INFO: iter: 12750/300480  CE: 3.3614  
[06/15 02:32:51] Re-training INFO: iter: 12875/300480  CE: 3.1172  
[06/15 02:34:15] Re-training INFO: iter: 13000/300480  CE: 3.0901  
[06/15 02:35:38] Re-training INFO: iter: 13125/300480  CE: 3.1920  
[06/15 02:37:02] Re-training INFO: iter: 13250/300480  CE: 3.2008  
[06/15 02:38:26] Re-training INFO: iter: 13375/300480  CE: 3.1343  
[06/15 02:39:48] Re-training INFO: iter: 13500/300480  CE: 3.2341  
[06/15 02:41:11] Re-training INFO: iter: 13625/300480  CE: 3.1203  
[06/15 02:42:35] Re-training INFO: iter: 13750/300480  CE: 3.2615  
[06/15 02:42:48] Re-training INFO: --> epoch:  11/240  avg CE: 3.1772  lr: 0.4974128467049176
[06/15 02:44:13] Re-training INFO: iter: 13875/300480  CE: 3.2040  
[06/15 02:45:36] Re-training INFO: iter: 14000/300480  CE: 3.4349  
[06/15 02:47:01] Re-training INFO: iter: 14125/300480  CE: 3.1577  
[06/15 02:48:25] Re-training INFO: iter: 14250/300480  CE: 3.1334  
[06/15 02:49:48] Re-training INFO: iter: 14375/300480  CE: 3.2235  
[06/15 02:51:10] Re-training INFO: iter: 14500/300480  CE: 2.9478  
[06/15 02:52:34] Re-training INFO: iter: 14625/300480  CE: 3.0297  
[06/15 02:53:58] Re-training INFO: iter: 14750/300480  CE: 3.3838  
[06/15 02:55:22] Re-training INFO: iter: 14875/300480  CE: 3.0320  
[06/15 02:56:46] Re-training INFO: iter: 15000/300480  CE: 3.1792  
[06/15 02:56:59] Re-training INFO: --> epoch:  12/240  avg CE: 3.1451  lr: 0.49692208514878444
[06/15 02:58:24] Re-training INFO: iter: 15125/300480  CE: 3.1630  
[06/15 02:59:47] Re-training INFO: iter: 15250/300480  CE: 3.1331  
[06/15 03:01:10] Re-training INFO: iter: 15375/300480  CE: 2.8150  
[06/15 03:02:34] Re-training INFO: iter: 15500/300480  CE: 3.2074  
[06/15 03:03:58] Re-training INFO: iter: 15625/300480  CE: 3.3086  
[06/15 03:05:21] Re-training INFO: iter: 15750/300480  CE: 2.8912  
[06/15 03:06:43] Re-training INFO: iter: 15875/300480  CE: 3.2985  
[06/15 03:08:08] Re-training INFO: iter: 16000/300480  CE: 3.0974  
[06/15 03:09:32] Re-training INFO: iter: 16125/300480  CE: 3.0632  
[06/15 03:10:56] Re-training INFO: iter: 16250/300480  CE: 3.2005  
[06/15 03:11:12] Re-training INFO: --> epoch:  13/240  avg CE: 3.1350  lr: 0.49638901476451947
[06/15 03:12:33] Re-training INFO: iter: 16375/300480  CE: 3.2476  
[06/15 03:13:57] Re-training INFO: iter: 16500/300480  CE: 3.1552  
[06/15 03:15:21] Re-training INFO: iter: 16625/300480  CE: 3.1452  
[06/15 03:16:45] Re-training INFO: iter: 16750/300480  CE: 2.9019  
[06/15 03:18:08] Re-training INFO: iter: 16875/300480  CE: 3.0637  
[06/15 03:19:31] Re-training INFO: iter: 17000/300480  CE: 2.8975  
[06/15 03:20:55] Re-training INFO: iter: 17125/300480  CE: 3.2790  
[06/15 03:22:18] Re-training INFO: iter: 17250/300480  CE: 3.0507  
[06/15 03:23:43] Re-training INFO: iter: 17375/300480  CE: 2.9391  
[06/15 03:25:07] Re-training INFO: iter: 17500/300480  CE: 3.0418  
[06/15 03:25:23] Re-training INFO: --> epoch:  14/240  avg CE: 3.0987  lr: 0.4958137268909887
[06/15 03:26:46] Re-training INFO: iter: 17625/300480  CE: 2.7316  
[06/15 03:28:09] Re-training INFO: iter: 17750/300480  CE: 3.3194  
[06/15 03:29:32] Re-training INFO: iter: 17875/300480  CE: 3.2555  
[06/15 03:30:56] Re-training INFO: iter: 18000/300480  CE: 2.9682  
[06/15 03:32:19] Re-training INFO: iter: 18125/300480  CE: 3.1573  
[06/15 03:33:43] Re-training INFO: iter: 18250/300480  CE: 2.9243  
[06/15 03:35:06] Re-training INFO: iter: 18375/300480  CE: 2.9983  
[06/15 03:36:29] Re-training INFO: iter: 18500/300480  CE: 3.3348  
[06/15 03:37:52] Re-training INFO: iter: 18625/300480  CE: 2.9980  
[06/15 03:39:15] Re-training INFO: iter: 18750/300480  CE: 3.1840  
[06/15 03:39:33] Re-training INFO: --> epoch:  15/240  avg CE: 3.0981  lr: 0.4951963201008076
[06/15 03:40:55] Re-training INFO: iter: 18875/300480  CE: 3.0094  
[06/15 03:42:17] Re-training INFO: iter: 19000/300480  CE: 3.1522  
[06/15 03:43:41] Re-training INFO: iter: 19125/300480  CE: 3.1760  
[06/15 03:45:04] Re-training INFO: iter: 19250/300480  CE: 2.9411  
[06/15 03:46:28] Re-training INFO: iter: 19375/300480  CE: 3.1909  
[06/15 03:47:52] Re-training INFO: iter: 19500/300480  CE: 3.0277  
[06/15 03:49:15] Re-training INFO: iter: 19625/300480  CE: 2.8332  
[06/15 03:50:39] Re-training INFO: iter: 19750/300480  CE: 3.4033  
[06/15 03:52:02] Re-training INFO: iter: 19875/300480  CE: 2.9936  
[06/15 03:53:27] Re-training INFO: iter: 20000/300480  CE: 2.6913  
[06/15 03:53:46] Re-training INFO: --> epoch:  16/240  avg CE: 3.0872  lr: 0.4945369001834514
[06/15 03:55:05] Re-training INFO: iter: 20125/300480  CE: 3.1460  
[06/15 03:56:28] Re-training INFO: iter: 20250/300480  CE: 3.1836  
[06/15 03:57:53] Re-training INFO: iter: 20375/300480  CE: 2.8727  
[06/15 03:59:16] Re-training INFO: iter: 20500/300480  CE: 3.1043  
[06/15 04:00:38] Re-training INFO: iter: 20625/300480  CE: 3.2391  
[06/15 04:02:01] Re-training INFO: iter: 20750/300480  CE: 3.2039  
[06/15 04:03:25] Re-training INFO: iter: 20875/300480  CE: 3.0927  
[06/15 04:04:48] Re-training INFO: iter: 21000/300480  CE: 2.9748  
[06/15 04:06:12] Re-training INFO: iter: 21125/300480  CE: 3.1094  
[06/15 04:07:35] Re-training INFO: iter: 21250/300480  CE: 3.1994  
[06/15 04:07:56] Re-training INFO: --> epoch:  17/240  avg CE: 3.0733  lr: 0.49383558012712814
[06/15 04:09:13] Re-training INFO: iter: 21375/300480  CE: 2.7387  
[06/15 04:10:36] Re-training INFO: iter: 21500/300480  CE: 2.8738  
[06/15 04:12:03] Re-training INFO: iter: 21625/300480  CE: 3.0355  
[06/15 04:13:27] Re-training INFO: iter: 21750/300480  CE: 3.0374  
[06/15 04:14:50] Re-training INFO: iter: 21875/300480  CE: 2.9391  
[06/15 04:16:14] Re-training INFO: iter: 22000/300480  CE: 3.1856  
[06/15 04:17:39] Re-training INFO: iter: 22125/300480  CE: 2.9781  
[06/15 04:19:02] Re-training INFO: iter: 22250/300480  CE: 3.1301  
[06/15 04:20:27] Re-training INFO: iter: 22375/300480  CE: 2.9961  
[06/15 04:21:51] Re-training INFO: iter: 22500/300480  CE: 3.0951  
[06/15 04:22:12] Re-training INFO: --> epoch:  18/240  avg CE: 3.0702  lr: 0.49309248009941914
[06/15 04:23:29] Re-training INFO: iter: 22625/300480  CE: 2.8801  
[06/15 04:24:52] Re-training INFO: iter: 22750/300480  CE: 3.2839  
[06/15 04:26:15] Re-training INFO: iter: 22875/300480  CE: 3.0814  
[06/15 04:27:39] Re-training INFO: iter: 23000/300480  CE: 3.2201  
[06/15 04:29:02] Re-training INFO: iter: 23125/300480  CE: 3.3147  
[06/15 04:30:26] Re-training INFO: iter: 23250/300480  CE: 3.2208  
[06/15 04:31:50] Re-training INFO: iter: 23375/300480  CE: 3.1664  
[06/15 04:33:13] Re-training INFO: iter: 23500/300480  CE: 3.3651  
[06/15 04:34:37] Re-training INFO: iter: 23625/300480  CE: 3.0644  
[06/15 04:36:01] Re-training INFO: iter: 23750/300480  CE: 3.2323  
[06/15 04:36:24] Re-training INFO: --> epoch:  19/240  avg CE: 3.0549  lr: 0.4923077274266886
[06/15 04:37:39] Re-training INFO: iter: 23875/300480  CE: 3.1105  
[06/15 04:39:02] Re-training INFO: iter: 24000/300480  CE: 2.8458  
[06/15 04:40:26] Re-training INFO: iter: 24125/300480  CE: 2.9117  
[06/15 04:41:49] Re-training INFO: iter: 24250/300480  CE: 2.8102  
[06/15 04:43:14] Re-training INFO: iter: 24375/300480  CE: 2.9646  
[06/15 04:44:38] Re-training INFO: iter: 24500/300480  CE: 3.1774  
[06/15 04:46:02] Re-training INFO: iter: 24625/300480  CE: 3.0228  
[06/15 04:47:24] Re-training INFO: iter: 24750/300480  CE: 3.2706  
[06/15 04:48:49] Re-training INFO: iter: 24875/300480  CE: 2.9148  
[06/15 04:50:13] Re-training INFO: iter: 25000/300480  CE: 3.0312  
[06/15 04:50:37] Re-training INFO: --> epoch:  20/240  avg CE: 3.0434  lr: 0.49148145657226705
[06/15 04:51:09] Re-training INFO: # of Test Samples: 50000.0
[06/15 04:51:09] Re-training INFO: Top-1/-5 acc: 52.48 / 78.11
[06/15 04:51:09] Re-training INFO: Top-1/-5 acc: 47.52 / 21.89
[06/15 04:51:09] Re-training INFO: 

[06/15 04:52:24] Re-training INFO: iter: 25125/300480  CE: 3.2106  
[06/15 04:53:47] Re-training INFO: iter: 25250/300480  CE: 3.1035  
[06/15 04:55:10] Re-training INFO: iter: 25375/300480  CE: 2.7953  
[06/15 04:56:34] Re-training INFO: iter: 25500/300480  CE: 2.9562  
[06/15 04:57:58] Re-training INFO: iter: 25625/300480  CE: 2.9197  
[06/15 04:59:20] Re-training INFO: iter: 25750/300480  CE: 2.7551  
[06/15 05:00:44] Re-training INFO: iter: 25875/300480  CE: 3.1664  
[06/15 05:02:07] Re-training INFO: iter: 26000/300480  CE: 3.2561  
[06/15 05:03:32] Re-training INFO: iter: 26125/300480  CE: 2.8479  
[06/15 05:04:56] Re-training INFO: iter: 26250/300480  CE: 2.9878  
[06/15 05:05:21] Re-training INFO: --> epoch:  21/240  avg CE: 3.0410  lr: 0.4906138091134118
[06/15 05:06:33] Re-training INFO: iter: 26375/300480  CE: 2.9144  
[06/15 05:07:57] Re-training INFO: iter: 26500/300480  CE: 3.3373  
[06/15 05:09:20] Re-training INFO: iter: 26625/300480  CE: 2.8115  
[06/15 05:10:45] Re-training INFO: iter: 26750/300480  CE: 3.0475  
[06/15 05:12:08] Re-training INFO: iter: 26875/300480  CE: 3.2454  
[06/15 05:13:30] Re-training INFO: iter: 27000/300480  CE: 3.3377  
[06/15 05:14:55] Re-training INFO: iter: 27125/300480  CE: 3.1813  
[06/15 05:16:18] Re-training INFO: iter: 27250/300480  CE: 2.9451  
[06/15 05:17:41] Re-training INFO: iter: 27375/300480  CE: 3.0207  
[06/15 05:19:05] Re-training INFO: iter: 27500/300480  CE: 2.8275  
[06/15 05:19:33] Re-training INFO: --> epoch:  22/240  avg CE: 3.0310  lr: 0.48970493371704826
[06/15 05:20:44] Re-training INFO: iter: 27625/300480  CE: 2.6727  
[06/15 05:22:08] Re-training INFO: iter: 27750/300480  CE: 3.1761  
[06/15 05:23:31] Re-training INFO: iter: 27875/300480  CE: 3.1410  
[06/15 05:24:57] Re-training INFO: iter: 28000/300480  CE: 3.1414  
[06/15 05:26:22] Re-training INFO: iter: 28125/300480  CE: 2.8773  
[06/15 05:27:46] Re-training INFO: iter: 28250/300480  CE: 3.0381  
[06/15 05:29:10] Re-training INFO: iter: 28375/300480  CE: 3.0864  
[06/15 05:30:33] Re-training INFO: iter: 28500/300480  CE: 2.9611  
[06/15 05:31:58] Re-training INFO: iter: 28625/300480  CE: 3.1352  
[06/15 05:33:21] Re-training INFO: iter: 28750/300480  CE: 3.1228  
[06/15 05:33:51] Re-training INFO: --> epoch:  23/240  avg CE: 3.0310  lr: 0.4887549861142967
[06/15 05:35:01] Re-training INFO: iter: 28875/300480  CE: 3.0102  
[06/15 05:36:25] Re-training INFO: iter: 29000/300480  CE: 3.0002  
[06/15 05:37:49] Re-training INFO: iter: 29125/300480  CE: 2.9524  
[06/15 05:39:14] Re-training INFO: iter: 29250/300480  CE: 2.8069  
[06/15 05:40:38] Re-training INFO: iter: 29375/300480  CE: 3.0031  
[06/15 05:42:01] Re-training INFO: iter: 29500/300480  CE: 2.9197  
[06/15 05:43:24] Re-training INFO: iter: 29625/300480  CE: 3.1206  
[06/15 05:44:48] Re-training INFO: iter: 29750/300480  CE: 3.1179  
[06/15 05:46:12] Re-training INFO: iter: 29875/300480  CE: 2.7609  
[06/15 05:47:36] Re-training INFO: iter: 30000/300480  CE: 2.7482  
[06/15 05:48:07] Re-training INFO: --> epoch:  24/240  avg CE: 3.0117  lr: 0.4877641290737884
[06/15 05:49:15] Re-training INFO: iter: 30125/300480  CE: 2.8972  
[06/15 05:50:38] Re-training INFO: iter: 30250/300480  CE: 3.1026  
[06/15 05:52:02] Re-training INFO: iter: 30375/300480  CE: 2.8295  
[06/15 05:53:25] Re-training INFO: iter: 30500/300480  CE: 3.0398  
[06/15 05:54:49] Re-training INFO: iter: 30625/300480  CE: 2.8993  
[06/15 05:56:12] Re-training INFO: iter: 30750/300480  CE: 3.0595  
[06/15 05:57:35] Re-training INFO: iter: 30875/300480  CE: 2.8843  
[06/15 05:58:59] Re-training INFO: iter: 31000/300480  CE: 3.4301  
[06/15 06:00:22] Re-training INFO: iter: 31125/300480  CE: 2.9129  
[06/15 06:01:46] Re-training INFO: iter: 31250/300480  CE: 3.0378  
[06/15 06:02:18] Re-training INFO: --> epoch:  25/240  avg CE: 3.0092  lr: 0.48673253237377645
[06/15 06:03:24] Re-training INFO: iter: 31375/300480  CE: 2.9714  
[06/15 06:04:50] Re-training INFO: iter: 31500/300480  CE: 2.9882  
[06/15 06:06:12] Re-training INFO: iter: 31625/300480  CE: 2.8001  
[06/15 06:07:35] Re-training INFO: iter: 31750/300480  CE: 2.8824  
[06/15 06:08:59] Re-training INFO: iter: 31875/300480  CE: 2.9654  
[06/15 06:10:23] Re-training INFO: iter: 32000/300480  CE: 3.1190  
[06/15 06:11:46] Re-training INFO: iter: 32125/300480  CE: 3.2544  
[06/15 06:13:09] Re-training INFO: iter: 32250/300480  CE: 2.9354  
[06/15 06:14:33] Re-training INFO: iter: 32375/300480  CE: 2.8981  
[06/15 06:15:57] Re-training INFO: iter: 32500/300480  CE: 2.7769  
[06/15 06:16:29] Re-training INFO: --> epoch:  26/240  avg CE: 3.0022  lr: 0.48566037277304464
[06/15 06:17:35] Re-training INFO: iter: 32625/300480  CE: 3.0696  
[06/15 06:18:58] Re-training INFO: iter: 32750/300480  CE: 2.7117  
[06/15 06:20:22] Re-training INFO: iter: 32875/300480  CE: 3.0296  
[06/15 06:21:45] Re-training INFO: iter: 33000/300480  CE: 2.8006  
[06/15 06:23:09] Re-training INFO: iter: 33125/300480  CE: 2.8713  
[06/15 06:24:33] Re-training INFO: iter: 33250/300480  CE: 3.0868  
[06/15 06:25:57] Re-training INFO: iter: 33375/300480  CE: 3.0407  
[06/15 06:27:21] Re-training INFO: iter: 33500/300480  CE: 2.9562  
[06/15 06:28:45] Re-training INFO: iter: 33625/300480  CE: 2.9129  
[06/15 06:30:10] Re-training INFO: iter: 33750/300480  CE: 2.8834  
[06/15 06:30:43] Re-training INFO: --> epoch:  27/240  avg CE: 2.9947  lr: 0.48454783398062107
[06/15 06:31:47] Re-training INFO: iter: 33875/300480  CE: 3.0251  
[06/15 06:33:11] Re-training INFO: iter: 34000/300480  CE: 3.3218  
[06/15 06:34:35] Re-training INFO: iter: 34125/300480  CE: 3.1751  
[06/15 06:35:59] Re-training INFO: iter: 34250/300480  CE: 3.0564  
[06/15 06:37:22] Re-training INFO: iter: 34375/300480  CE: 2.7615  
[06/15 06:38:47] Re-training INFO: iter: 34500/300480  CE: 2.9416  
[06/15 06:40:10] Re-training INFO: iter: 34625/300480  CE: 2.9626  
[06/15 06:41:34] Re-training INFO: iter: 34750/300480  CE: 3.2824  
[06/15 06:42:58] Re-training INFO: iter: 34875/300480  CE: 3.0353  
[06/15 06:44:22] Re-training INFO: iter: 35000/300480  CE: 2.8341  
[06/15 06:44:58] Re-training INFO: --> epoch:  28/240  avg CE: 2.9939  lr: 0.4833951066243004
[06/15 06:46:01] Re-training INFO: iter: 35125/300480  CE: 3.0726  
[06/15 06:47:25] Re-training INFO: iter: 35250/300480  CE: 2.9648  
[06/15 06:48:48] Re-training INFO: iter: 35375/300480  CE: 2.9143  
[06/15 06:50:11] Re-training INFO: iter: 35500/300480  CE: 3.1007  
[06/15 06:51:36] Re-training INFO: iter: 35625/300480  CE: 3.0358  
[06/15 06:53:00] Re-training INFO: iter: 35750/300480  CE: 3.1111  
[06/15 06:54:23] Re-training INFO: iter: 35875/300480  CE: 2.8175  
[06/15 06:55:47] Re-training INFO: iter: 36000/300480  CE: 2.9308  
[06/15 06:57:11] Re-training INFO: iter: 36125/300480  CE: 2.9509  
[06/15 06:58:33] Re-training INFO: iter: 36250/300480  CE: 2.9654  
[06/15 06:59:11] Re-training INFO: --> epoch:  29/240  avg CE: 2.9874  lr: 0.48220238821798106
[06/15 07:00:12] Re-training INFO: iter: 36375/300480  CE: 2.7600  
[06/15 07:01:36] Re-training INFO: iter: 36500/300480  CE: 3.3324  
[06/15 07:02:59] Re-training INFO: iter: 36625/300480  CE: 2.8130  
[06/15 07:04:24] Re-training INFO: iter: 36750/300480  CE: 3.2786  
[06/15 07:05:47] Re-training INFO: iter: 36875/300480  CE: 3.2339  
[06/15 07:07:10] Re-training INFO: iter: 37000/300480  CE: 3.0596  
[06/15 07:08:34] Re-training INFO: iter: 37125/300480  CE: 3.0850  
[06/15 07:09:57] Re-training INFO: iter: 37250/300480  CE: 3.0887  
[06/15 07:11:21] Re-training INFO: iter: 37375/300480  CE: 3.0094  
[06/15 07:12:45] Re-training INFO: iter: 37500/300480  CE: 3.0042  
[06/15 07:13:23] Re-training INFO: --> epoch:  30/240  avg CE: 2.9849  lr: 0.4809698831278217
[06/15 07:14:24] Re-training INFO: iter: 37625/300480  CE: 2.7882  
[06/15 07:15:47] Re-training INFO: iter: 37750/300480  CE: 3.1536  
[06/15 07:17:12] Re-training INFO: iter: 37875/300480  CE: 3.1200  
[06/15 07:18:36] Re-training INFO: iter: 38000/300480  CE: 2.7862  
[06/15 07:20:00] Re-training INFO: iter: 38125/300480  CE: 2.9681  
[06/15 07:21:23] Re-training INFO: iter: 38250/300480  CE: 2.9265  
[06/15 07:22:47] Re-training INFO: iter: 38375/300480  CE: 2.9412  
[06/15 07:24:11] Re-training INFO: iter: 38500/300480  CE: 3.0048  
[06/15 07:25:35] Re-training INFO: iter: 38625/300480  CE: 3.2084  
[06/15 07:26:59] Re-training INFO: iter: 38750/300480  CE: 3.1633  
[06/15 07:27:38] Re-training INFO: --> epoch:  31/240  avg CE: 2.9746  lr: 0.4796978025372246
[06/15 07:28:37] Re-training INFO: iter: 38875/300480  CE: 2.9438  
[06/15 07:30:00] Re-training INFO: iter: 39000/300480  CE: 2.9714  
[06/15 07:31:24] Re-training INFO: iter: 39125/300480  CE: 2.9323  
[06/15 07:32:48] Re-training INFO: iter: 39250/300480  CE: 2.9619  
[06/15 07:34:11] Re-training INFO: iter: 39375/300480  CE: 2.9704  
[06/15 07:35:33] Re-training INFO: iter: 39500/300480  CE: 3.0873  
[06/15 07:36:57] Re-training INFO: iter: 39625/300480  CE: 2.8610  
[06/15 07:38:20] Re-training INFO: iter: 39750/300480  CE: 2.9572  
[06/15 07:39:45] Re-training INFO: iter: 39875/300480  CE: 2.9552  
[06/15 07:41:09] Re-training INFO: iter: 40000/300480  CE: 2.7108  
[06/15 07:41:50] Re-training INFO: --> epoch:  32/240  avg CE: 2.9830  lr: 0.4783863644106502
[06/15 07:42:47] Re-training INFO: iter: 40125/300480  CE: 3.1092  
[06/15 07:44:11] Re-training INFO: iter: 40250/300480  CE: 2.9887  
[06/15 07:45:35] Re-training INFO: iter: 40375/300480  CE: 3.3710  
[06/15 07:46:59] Re-training INFO: iter: 40500/300480  CE: 2.9219  
[06/15 07:48:22] Re-training INFO: iter: 40625/300480  CE: 3.0610  
[06/15 07:49:45] Re-training INFO: iter: 40750/300480  CE: 2.9242  
[06/15 07:51:10] Re-training INFO: iter: 40875/300480  CE: 3.0652  
[06/15 07:52:34] Re-training INFO: iter: 41000/300480  CE: 2.7976  
[06/15 07:53:57] Re-training INFO: iter: 41125/300480  CE: 2.7390  
[06/15 07:55:21] Re-training INFO: iter: 41250/300480  CE: 3.3968  
[06/15 07:56:03] Re-training INFO: --> epoch:  33/240  avg CE: 2.9736  lr: 0.47703579345627034
[06/15 07:57:00] Re-training INFO: iter: 41375/300480  CE: 2.9153  
[06/15 07:58:24] Re-training INFO: iter: 41500/300480  CE: 2.9305  
[06/15 07:59:47] Re-training INFO: iter: 41625/300480  CE: 2.9776  
[06/15 08:01:11] Re-training INFO: iter: 41750/300480  CE: 2.8027  
[06/15 08:02:35] Re-training INFO: iter: 41875/300480  CE: 3.1146  
[06/15 08:03:58] Re-training INFO: iter: 42000/300480  CE: 2.9325  
[06/15 08:05:22] Re-training INFO: iter: 42125/300480  CE: 2.8473  
[06/15 08:06:45] Re-training INFO: iter: 42250/300480  CE: 2.8142  
[06/15 08:08:08] Re-training INFO: iter: 42375/300480  CE: 3.0030  
[06/15 08:09:32] Re-training INFO: iter: 42500/300480  CE: 2.8188  
[06/15 08:10:16] Re-training INFO: --> epoch:  34/240  avg CE: 2.9639  lr: 0.4756463210874652
[06/15 08:11:10] Re-training INFO: iter: 42625/300480  CE: 2.8721  
[06/15 08:12:34] Re-training INFO: iter: 42750/300480  CE: 2.8589  
[06/15 08:13:57] Re-training INFO: iter: 42875/300480  CE: 3.1761  
[06/15 08:15:21] Re-training INFO: iter: 43000/300480  CE: 2.9125  
[06/15 08:16:44] Re-training INFO: iter: 43125/300480  CE: 2.9168  
[06/15 08:18:07] Re-training INFO: iter: 43250/300480  CE: 2.9420  
[06/15 08:19:30] Re-training INFO: iter: 43375/300480  CE: 2.8251  
[06/15 08:20:54] Re-training INFO: iter: 43500/300480  CE: 2.9315  
[06/15 08:22:18] Re-training INFO: iter: 43625/300480  CE: 3.0397  
[06/15 08:23:41] Re-training INFO: iter: 43750/300480  CE: 2.9289  
[06/15 08:24:26] Re-training INFO: --> epoch:  35/240  avg CE: 2.9527  lr: 0.47421818538317206
[06/15 08:25:19] Re-training INFO: iter: 43875/300480  CE: 3.2440  
[06/15 08:26:42] Re-training INFO: iter: 44000/300480  CE: 2.9085  
[06/15 08:28:07] Re-training INFO: iter: 44125/300480  CE: 3.0102  
[06/15 08:29:29] Re-training INFO: iter: 44250/300480  CE: 2.7101  
[06/15 08:30:54] Re-training INFO: iter: 44375/300480  CE: 3.1590  
[06/15 08:32:17] Re-training INFO: iter: 44500/300480  CE: 3.0131  
[06/15 08:33:41] Re-training INFO: iter: 44625/300480  CE: 2.9201  
[06/15 08:35:05] Re-training INFO: iter: 44750/300480  CE: 3.0160  
[06/15 08:36:27] Re-training INFO: iter: 44875/300480  CE: 2.8580  
[06/15 08:37:50] Re-training INFO: iter: 45000/300480  CE: 3.0141  
[06/15 08:38:37] Re-training INFO: --> epoch:  36/240  avg CE: 2.9542  lr: 0.47275163104709195
[06/15 08:39:29] Re-training INFO: iter: 45125/300480  CE: 3.2099  
[06/15 08:40:52] Re-training INFO: iter: 45250/300480  CE: 3.2043  
[06/15 08:42:16] Re-training INFO: iter: 45375/300480  CE: 3.1541  
[06/15 08:43:40] Re-training INFO: iter: 45500/300480  CE: 3.2526  
[06/15 08:45:05] Re-training INFO: iter: 45625/300480  CE: 3.0532  
[06/15 08:46:30] Re-training INFO: iter: 45750/300480  CE: 2.9856  
[06/15 08:47:53] Re-training INFO: iter: 45875/300480  CE: 2.9137  
[06/15 08:49:16] Re-training INFO: iter: 46000/300480  CE: 2.9015  
[06/15 08:50:40] Re-training INFO: iter: 46125/300480  CE: 2.7064  
[06/15 08:52:03] Re-training INFO: iter: 46250/300480  CE: 2.7987  
[06/15 08:52:50] Re-training INFO: --> epoch:  37/240  avg CE: 2.9536  lr: 0.47124690936576047
[06/15 08:53:41] Re-training INFO: iter: 46375/300480  CE: 3.0528  
[06/15 08:55:04] Re-training INFO: iter: 46500/300480  CE: 2.9337  
[06/15 08:56:28] Re-training INFO: iter: 46625/300480  CE: 2.8234  
[06/15 08:57:52] Re-training INFO: iter: 46750/300480  CE: 2.7872  
[06/15 08:59:15] Re-training INFO: iter: 46875/300480  CE: 3.1134  
[06/15 09:00:39] Re-training INFO: iter: 47000/300480  CE: 2.9866  
[06/15 09:02:01] Re-training INFO: iter: 47125/300480  CE: 2.8889  
[06/15 09:03:26] Re-training INFO: iter: 47250/300480  CE: 3.0055  
[06/15 09:04:49] Re-training INFO: iter: 47375/300480  CE: 2.8739  
[06/15 09:06:13] Re-training INFO: iter: 47500/300480  CE: 2.8381  
[06/15 09:07:01] Re-training INFO: --> epoch:  38/240  avg CE: 2.9458  lr: 0.4697042781654913
[06/15 09:07:50] Re-training INFO: iter: 47625/300480  CE: 2.5348  
[06/15 09:09:15] Re-training INFO: iter: 47750/300480  CE: 2.7966  
[06/15 09:10:37] Re-training INFO: iter: 47875/300480  CE: 2.9374  
[06/15 09:12:00] Re-training INFO: iter: 48000/300480  CE: 3.1395  
[06/15 09:13:24] Re-training INFO: iter: 48125/300480  CE: 3.0283  
[06/15 09:14:47] Re-training INFO: iter: 48250/300480  CE: 2.9287  
[06/15 09:16:12] Re-training INFO: iter: 48375/300480  CE: 3.0849  
[06/15 09:17:34] Re-training INFO: iter: 48500/300480  CE: 2.8724  
[06/15 09:18:58] Re-training INFO: iter: 48625/300480  CE: 3.1424  
[06/15 09:20:23] Re-training INFO: iter: 48750/300480  CE: 2.7853  
[06/15 09:21:14] Re-training INFO: --> epoch:  39/240  avg CE: 2.9496  lr: 0.4681240017681993
[06/15 09:22:01] Re-training INFO: iter: 48875/300480  CE: 2.9858  
[06/15 09:23:24] Re-training INFO: iter: 49000/300480  CE: 2.8089  
[06/15 09:24:49] Re-training INFO: iter: 49125/300480  CE: 2.9768  
[06/15 09:26:11] Re-training INFO: iter: 49250/300480  CE: 2.9144  
[06/15 09:27:35] Re-training INFO: iter: 49375/300480  CE: 2.9650  
[06/15 09:28:57] Re-training INFO: iter: 49500/300480  CE: 2.7561  
[06/15 09:30:23] Re-training INFO: iter: 49625/300480  CE: 2.7153  
[06/15 09:31:46] Re-training INFO: iter: 49750/300480  CE: 2.7437  
[06/15 09:33:09] Re-training INFO: iter: 49875/300480  CE: 2.8389  
[06/15 09:34:32] Re-training INFO: iter: 50000/300480  CE: 2.8170  
[06/15 09:35:24] Re-training INFO: --> epoch:  40/240  avg CE: 2.9432  lr: 0.4665063509461097
[06/15 09:35:56] Re-training INFO: # of Test Samples: 50000.0
[06/15 09:35:56] Re-training INFO: Top-1/-5 acc: 54.70 / 79.66
[06/15 09:35:56] Re-training INFO: Top-1/-5 acc: 45.30 / 20.34
[06/15 09:35:56] Re-training INFO: 

[06/15 09:36:44] Re-training INFO: iter: 50125/300480  CE: 3.2658  
[06/15 09:38:07] Re-training INFO: iter: 50250/300480  CE: 2.7495  
[06/15 09:39:30] Re-training INFO: iter: 50375/300480  CE: 2.8945  
[06/15 09:40:53] Re-training INFO: iter: 50500/300480  CE: 2.7766  
[06/15 09:42:16] Re-training INFO: iter: 50625/300480  CE: 2.7256  
[06/15 09:43:39] Re-training INFO: iter: 50750/300480  CE: 2.7136  
[06/15 09:45:04] Re-training INFO: iter: 50875/300480  CE: 2.7093  
[06/15 09:46:29] Re-training INFO: iter: 51000/300480  CE: 2.8595  
[06/15 09:47:51] Re-training INFO: iter: 51125/300480  CE: 2.7085  
[06/15 09:49:14] Re-training INFO: iter: 51250/300480  CE: 3.1236  
[06/15 09:50:07] Re-training INFO: --> epoch:  41/240  avg CE: 2.9426  lr: 0.4648516028753632
[06/15 09:50:53] Re-training INFO: iter: 51375/300480  CE: 2.9633  
[06/15 09:52:17] Re-training INFO: iter: 51500/300480  CE: 3.0584  
[06/15 09:53:40] Re-training INFO: iter: 51625/300480  CE: 3.0135  
[06/15 09:55:04] Re-training INFO: iter: 51750/300480  CE: 3.0057  
[06/15 09:56:27] Re-training INFO: iter: 51875/300480  CE: 3.0763  
[06/15 09:57:50] Re-training INFO: iter: 52000/300480  CE: 2.6945  
[06/15 09:59:14] Re-training INFO: iter: 52125/300480  CE: 2.6920  
[06/15 10:00:37] Re-training INFO: iter: 52250/300480  CE: 3.1251  
[06/15 10:02:01] Re-training INFO: iter: 52375/300480  CE: 2.9146  
[06/15 10:03:24] Re-training INFO: iter: 52500/300480  CE: 2.7517  
[06/15 10:04:19] Re-training INFO: --> epoch:  42/240  avg CE: 2.9309  lr: 0.46316004108852304
[06/15 10:05:04] Re-training INFO: iter: 52625/300480  CE: 3.1513  
[06/15 10:06:27] Re-training INFO: iter: 52750/300480  CE: 3.0755  
[06/15 10:07:50] Re-training INFO: iter: 52875/300480  CE: 2.9774  
[06/15 10:09:12] Re-training INFO: iter: 53000/300480  CE: 2.7249  
[06/15 10:10:36] Re-training INFO: iter: 53125/300480  CE: 2.8107  
[06/15 10:11:59] Re-training INFO: iter: 53250/300480  CE: 2.5588  
[06/15 10:13:23] Re-training INFO: iter: 53375/300480  CE: 2.6855  
[06/15 10:14:46] Re-training INFO: iter: 53500/300480  CE: 2.9213  
[06/15 10:16:10] Re-training INFO: iter: 53625/300480  CE: 2.7569  
[06/15 10:17:34] Re-training INFO: iter: 53750/300480  CE: 2.9518  
[06/15 10:18:30] Re-training INFO: --> epoch:  43/240  avg CE: 2.9331  lr: 0.46143195542599336
[06/15 10:19:11] Re-training INFO: iter: 53875/300480  CE: 2.8964  
[06/15 10:20:36] Re-training INFO: iter: 54000/300480  CE: 2.6595  
[06/15 10:22:00] Re-training INFO: iter: 54125/300480  CE: 2.7960  
[06/15 10:23:24] Re-training INFO: iter: 54250/300480  CE: 3.1055  
[06/15 10:24:49] Re-training INFO: iter: 54375/300480  CE: 2.9460  
[06/15 10:26:11] Re-training INFO: iter: 54500/300480  CE: 3.0571  
[06/15 10:27:36] Re-training INFO: iter: 54625/300480  CE: 3.1036  
[06/15 10:29:00] Re-training INFO: iter: 54750/300480  CE: 3.0357  
[06/15 10:30:23] Re-training INFO: iter: 54875/300480  CE: 2.8778  
[06/15 10:31:47] Re-training INFO: iter: 55000/300480  CE: 2.9547  
[06/15 10:32:44] Re-training INFO: --> epoch:  44/240  avg CE: 2.9227  lr: 0.459667641986356
[06/15 10:33:26] Re-training INFO: iter: 55125/300480  CE: 3.0638  
[06/15 10:34:49] Re-training INFO: iter: 55250/300480  CE: 2.9888  
[06/15 10:36:12] Re-training INFO: iter: 55375/300480  CE: 2.9838  
[06/15 10:37:37] Re-training INFO: iter: 55500/300480  CE: 3.0322  
[06/15 10:39:00] Re-training INFO: iter: 55625/300480  CE: 2.8575  
[06/15 10:40:23] Re-training INFO: iter: 55750/300480  CE: 3.0084  
[06/15 10:41:47] Re-training INFO: iter: 55875/300480  CE: 2.7423  
[06/15 10:43:13] Re-training INFO: iter: 56000/300480  CE: 3.0633  
[06/15 10:44:35] Re-training INFO: iter: 56125/300480  CE: 3.1583  
[06/15 10:46:00] Re-training INFO: iter: 56250/300480  CE: 3.0077  
[06/15 10:46:58] Re-training INFO: --> epoch:  45/240  avg CE: 2.9302  lr: 0.45786740307563634
[06/15 10:47:37] Re-training INFO: iter: 56375/300480  CE: 3.0791  
[06/15 10:49:01] Re-training INFO: iter: 56500/300480  CE: 2.8135  
[06/15 10:50:25] Re-training INFO: iter: 56625/300480  CE: 2.9522  
[06/15 10:51:48] Re-training INFO: iter: 56750/300480  CE: 3.2317  
[06/15 10:53:12] Re-training INFO: iter: 56875/300480  CE: 3.2427  
[06/15 10:54:36] Re-training INFO: iter: 57000/300480  CE: 2.8500  
[06/15 10:55:59] Re-training INFO: iter: 57125/300480  CE: 2.8378  
[06/15 10:57:22] Re-training INFO: iter: 57250/300480  CE: 3.0080  
[06/15 10:58:46] Re-training INFO: iter: 57375/300480  CE: 3.1025  
[06/15 11:00:09] Re-training INFO: iter: 57500/300480  CE: 3.0200  
[06/15 11:01:09] Re-training INFO: --> epoch:  46/240  avg CE: 2.9233  lr: 0.45603154715550387
[06/15 11:01:48] Re-training INFO: iter: 57625/300480  CE: 2.9288  
[06/15 11:03:12] Re-training INFO: iter: 57750/300480  CE: 2.9057  
[06/15 11:04:35] Re-training INFO: iter: 57875/300480  CE: 2.9066  
[06/15 11:06:00] Re-training INFO: iter: 58000/300480  CE: 3.1271  
[06/15 11:07:23] Re-training INFO: iter: 58125/300480  CE: 3.1215  
[06/15 11:08:48] Re-training INFO: iter: 58250/300480  CE: 2.8268  
[06/15 11:10:10] Re-training INFO: iter: 58375/300480  CE: 2.9605  
[06/15 11:11:34] Re-training INFO: iter: 58500/300480  CE: 3.0338  
[06/15 11:12:58] Re-training INFO: iter: 58625/300480  CE: 2.7509  
[06/15 11:14:21] Re-training INFO: iter: 58750/300480  CE: 2.8309  
[06/15 11:15:22] Re-training INFO: --> epoch:  47/240  avg CE: 2.9225  lr: 0.45416038879041976
[06/15 11:15:59] Re-training INFO: iter: 58875/300480  CE: 2.8702  
[06/15 11:17:23] Re-training INFO: iter: 59000/300480  CE: 3.0579  
[06/15 11:18:47] Re-training INFO: iter: 59125/300480  CE: 2.9317  
[06/15 11:20:10] Re-training INFO: iter: 59250/300480  CE: 2.8018  
[06/15 11:21:33] Re-training INFO: iter: 59375/300480  CE: 2.9383  
[06/15 11:22:57] Re-training INFO: iter: 59500/300480  CE: 2.9435  
[06/15 11:24:20] Re-training INFO: iter: 59625/300480  CE: 2.7653  
[06/15 11:25:44] Re-training INFO: iter: 59750/300480  CE: 2.9503  
[06/15 11:27:07] Re-training INFO: iter: 59875/300480  CE: 2.8345  
[06/15 11:28:30] Re-training INFO: iter: 60000/300480  CE: 3.0277  
[06/15 11:29:33] Re-training INFO: --> epoch:  48/240  avg CE: 2.9120  lr: 0.45225424859373686
[06/15 11:30:09] Re-training INFO: iter: 60125/300480  CE: 2.9683  
[06/15 11:31:33] Re-training INFO: iter: 60250/300480  CE: 2.5581  
[06/15 11:32:56] Re-training INFO: iter: 60375/300480  CE: 3.0736  
[06/15 11:34:20] Re-training INFO: iter: 60500/300480  CE: 3.0002  
[06/15 11:35:44] Re-training INFO: iter: 60625/300480  CE: 2.5568  
[06/15 11:37:07] Re-training INFO: iter: 60750/300480  CE: 2.8117  
[06/15 11:38:31] Re-training INFO: iter: 60875/300480  CE: 3.2026  
[06/15 11:39:55] Re-training INFO: iter: 61000/300480  CE: 2.8212  
[06/15 11:41:18] Re-training INFO: iter: 61125/300480  CE: 2.9387  
[06/15 11:42:42] Re-training INFO: iter: 61250/300480  CE: 3.0912  
[06/15 11:43:45] Re-training INFO: --> epoch:  49/240  avg CE: 2.9103  lr: 0.45031345317276517
[06/15 11:44:20] Re-training INFO: iter: 61375/300480  CE: 2.7254  
[06/15 11:45:44] Re-training INFO: iter: 61500/300480  CE: 2.7345  
[06/15 11:47:09] Re-training INFO: iter: 61625/300480  CE: 3.1083  
[06/15 11:48:32] Re-training INFO: iter: 61750/300480  CE: 2.9283  
[06/15 11:49:56] Re-training INFO: iter: 61875/300480  CE: 2.8116  
[06/15 11:51:19] Re-training INFO: iter: 62000/300480  CE: 2.9566  
[06/15 11:52:44] Re-training INFO: iter: 62125/300480  CE: 2.9859  
[06/15 11:54:06] Re-training INFO: iter: 62250/300480  CE: 2.7373  
[06/15 11:55:30] Re-training INFO: iter: 62375/300480  CE: 2.8190  
[06/15 11:56:54] Re-training INFO: iter: 62500/300480  CE: 2.9102  
[06/15 11:57:59] Re-training INFO: --> epoch:  50/240  avg CE: 2.9055  lr: 0.4483383350728088
[06/15 11:58:33] Re-training INFO: iter: 62625/300480  CE: 2.8331  
[06/15 11:59:56] Re-training INFO: iter: 62750/300480  CE: 3.0093  
[06/15 12:01:21] Re-training INFO: iter: 62875/300480  CE: 2.8541  
[06/15 12:02:44] Re-training INFO: iter: 63000/300480  CE: 2.5769  
[06/15 12:04:08] Re-training INFO: iter: 63125/300480  CE: 2.8837  
[06/15 12:05:32] Re-training INFO: iter: 63250/300480  CE: 2.7477  
[06/15 12:06:55] Re-training INFO: iter: 63375/300480  CE: 2.9750  
[06/15 12:08:19] Re-training INFO: iter: 63500/300480  CE: 3.2556  
[06/15 12:09:43] Re-training INFO: iter: 63625/300480  CE: 2.9190  
[06/15 12:11:07] Re-training INFO: iter: 63750/300480  CE: 3.1555  
[06/15 12:12:13] Re-training INFO: --> epoch:  51/240  avg CE: 2.9054  lr: 0.4463292327201862
[06/15 12:12:45] Re-training INFO: iter: 63875/300480  CE: 3.2484  
[06/15 12:14:10] Re-training INFO: iter: 64000/300480  CE: 2.8147  
[06/15 12:15:33] Re-training INFO: iter: 64125/300480  CE: 2.9517  
[06/15 12:16:56] Re-training INFO: iter: 64250/300480  CE: 2.9350  
[06/15 12:18:21] Re-training INFO: iter: 64375/300480  CE: 2.8080  
[06/15 12:19:46] Re-training INFO: iter: 64500/300480  CE: 2.8978  
[06/15 12:21:09] Re-training INFO: iter: 64625/300480  CE: 2.9762  
[06/15 12:22:33] Re-training INFO: iter: 64750/300480  CE: 3.1065  
[06/15 12:23:58] Re-training INFO: iter: 64875/300480  CE: 2.9318  
[06/15 12:25:22] Re-training INFO: iter: 65000/300480  CE: 2.9380  
[06/15 12:26:29] Re-training INFO: --> epoch:  52/240  avg CE: 2.8959  lr: 0.4442864903642427
[06/15 12:27:00] Re-training INFO: iter: 65125/300480  CE: 2.9681  
[06/15 12:28:24] Re-training INFO: iter: 65250/300480  CE: 3.1374  
[06/15 12:29:47] Re-training INFO: iter: 65375/300480  CE: 2.6324  
[06/15 12:31:11] Re-training INFO: iter: 65500/300480  CE: 2.9507  
[06/15 12:32:36] Re-training INFO: iter: 65625/300480  CE: 3.0662  
[06/15 12:34:00] Re-training INFO: iter: 65750/300480  CE: 3.1879  
[06/15 12:35:23] Re-training INFO: iter: 65875/300480  CE: 2.9839  
[06/15 12:36:47] Re-training INFO: iter: 66000/300480  CE: 3.0527  
[06/15 12:38:12] Re-training INFO: iter: 66125/300480  CE: 2.9186  
[06/15 12:39:35] Re-training INFO: iter: 66250/300480  CE: 2.9625  
[06/15 12:40:44] Re-training INFO: --> epoch:  53/240  avg CE: 2.9012  lr: 0.4422104580183649
[06/15 12:41:13] Re-training INFO: iter: 66375/300480  CE: 2.8903  
[06/15 12:42:37] Re-training INFO: iter: 66500/300480  CE: 2.8792  
[06/15 12:44:02] Re-training INFO: iter: 66625/300480  CE: 2.8200  
[06/15 12:45:26] Re-training INFO: iter: 66750/300480  CE: 2.7240  
[06/15 12:46:49] Re-training INFO: iter: 66875/300480  CE: 2.9905  
[06/15 12:48:12] Re-training INFO: iter: 67000/300480  CE: 2.7895  
[06/15 12:49:36] Re-training INFO: iter: 67125/300480  CE: 3.0027  
[06/15 12:51:01] Re-training INFO: iter: 67250/300480  CE: 2.6113  
[06/15 12:52:25] Re-training INFO: iter: 67375/300480  CE: 2.6359  
[06/15 12:53:48] Re-training INFO: iter: 67500/300480  CE: 2.8600  
[06/15 12:54:59] Re-training INFO: --> epoch:  54/240  avg CE: 2.8948  lr: 0.44010149140000776
[06/15 12:55:27] Re-training INFO: iter: 67625/300480  CE: 2.7810  
[06/15 12:56:51] Re-training INFO: iter: 67750/300480  CE: 2.8517  
[06/15 12:58:14] Re-training INFO: iter: 67875/300480  CE: 2.7473  
[06/15 12:59:37] Re-training INFO: iter: 68000/300480  CE: 2.7942  
[06/15 13:01:01] Re-training INFO: iter: 68125/300480  CE: 2.8553  
[06/15 13:02:24] Re-training INFO: iter: 68250/300480  CE: 2.6168  
[06/15 13:03:48] Re-training INFO: iter: 68375/300480  CE: 2.7314  
[06/15 13:05:13] Re-training INFO: iter: 68500/300480  CE: 3.1801  
[06/15 13:06:36] Re-training INFO: iter: 68625/300480  CE: 2.9061  
[06/15 13:08:00] Re-training INFO: iter: 68750/300480  CE: 3.0589  
[06/15 13:09:12] Re-training INFO: --> epoch:  55/240  avg CE: 2.8957  lr: 0.43795995186974435
[06/15 13:09:38] Re-training INFO: iter: 68875/300480  CE: 3.0979  
[06/15 13:11:03] Re-training INFO: iter: 69000/300480  CE: 2.7636  
[06/15 13:12:28] Re-training INFO: iter: 69125/300480  CE: 2.8663  
[06/15 13:13:52] Re-training INFO: iter: 69250/300480  CE: 2.7442  
[06/15 13:15:15] Re-training INFO: iter: 69375/300480  CE: 2.7198  
[06/15 13:16:38] Re-training INFO: iter: 69500/300480  CE: 2.8943  
[06/15 13:18:03] Re-training INFO: iter: 69625/300480  CE: 3.1492  
[06/15 13:19:27] Re-training INFO: iter: 69750/300480  CE: 3.1429  
[06/15 13:20:50] Re-training INFO: iter: 69875/300480  CE: 2.8519  
[06/15 13:22:14] Re-training INFO: iter: 70000/300480  CE: 3.1978  
[06/15 13:23:28] Re-training INFO: --> epoch:  56/240  avg CE: 2.8837  lr: 0.43578620636934856
[06/15 13:23:54] Re-training INFO: iter: 70125/300480  CE: 2.9469  
[06/15 13:25:18] Re-training INFO: iter: 70250/300480  CE: 2.9306  
[06/15 13:26:41] Re-training INFO: iter: 70375/300480  CE: 3.1311  
[06/15 13:28:06] Re-training INFO: iter: 70500/300480  CE: 3.1034  
[06/15 13:29:31] Re-training INFO: iter: 70625/300480  CE: 2.7305  
[06/15 13:30:55] Re-training INFO: iter: 70750/300480  CE: 3.0312  
[06/15 13:32:18] Re-training INFO: iter: 70875/300480  CE: 2.5240  
[06/15 13:33:42] Re-training INFO: iter: 71000/300480  CE: 2.7098  
[06/15 13:35:06] Re-training INFO: iter: 71125/300480  CE: 2.8371  
[06/15 13:36:30] Re-training INFO: iter: 71250/300480  CE: 2.9810  
[06/15 13:37:44] Re-training INFO: --> epoch:  57/240  avg CE: 2.8892  lr: 0.4335806273589214
[06/15 13:38:08] Re-training INFO: iter: 71375/300480  CE: 3.0308  
[06/15 13:39:31] Re-training INFO: iter: 71500/300480  CE: 2.7742  
[06/15 13:40:56] Re-training INFO: iter: 71625/300480  CE: 2.7995  
[06/15 13:42:20] Re-training INFO: iter: 71750/300480  CE: 2.9167  
[06/15 13:43:45] Re-training INFO: iter: 71875/300480  CE: 3.0949  
[06/15 13:45:09] Re-training INFO: iter: 72000/300480  CE: 2.9965  
[06/15 13:46:34] Re-training INFO: iter: 72125/300480  CE: 2.7123  
[06/15 13:47:56] Re-training INFO: iter: 72250/300480  CE: 3.0432  
[06/15 13:49:19] Re-training INFO: iter: 72375/300480  CE: 3.0990  
[06/15 13:50:43] Re-training INFO: iter: 72500/300480  CE: 2.8814  
[06/15 13:51:59] Re-training INFO: --> epoch:  58/240  avg CE: 2.8797  lr: 0.4313435927530719
[06/15 13:52:21] Re-training INFO: iter: 72625/300480  CE: 2.8280  
[06/15 13:53:44] Re-training INFO: iter: 72750/300480  CE: 3.0440  
[06/15 13:55:09] Re-training INFO: iter: 72875/300480  CE: 2.7114  
[06/15 13:56:33] Re-training INFO: iter: 73000/300480  CE: 2.9082  
[06/15 13:57:57] Re-training INFO: iter: 73125/300480  CE: 2.8676  
[06/15 13:59:21] Re-training INFO: iter: 73250/300480  CE: 2.9333  
[06/15 14:00:44] Re-training INFO: iter: 73375/300480  CE: 2.8048  
[06/15 14:02:09] Re-training INFO: iter: 73500/300480  CE: 2.8872  
[06/15 14:03:33] Re-training INFO: iter: 73625/300480  CE: 2.9042  
[06/15 14:04:57] Re-training INFO: iter: 73750/300480  CE: 2.9526  
[06/15 14:06:14] Re-training INFO: --> epoch:  59/240  avg CE: 2.8765  lr: 0.42907548585616356
[06/15 14:06:35] Re-training INFO: iter: 73875/300480  CE: 2.8908  
[06/15 14:07:59] Re-training INFO: iter: 74000/300480  CE: 2.6855  
[06/15 14:09:23] Re-training INFO: iter: 74125/300480  CE: 2.9150  
[06/15 14:10:47] Re-training INFO: iter: 74250/300480  CE: 2.8497  
[06/15 14:12:09] Re-training INFO: iter: 74375/300480  CE: 2.7002  
[06/15 14:13:34] Re-training INFO: iter: 74500/300480  CE: 2.7647  
[06/15 14:14:58] Re-training INFO: iter: 74625/300480  CE: 2.8929  
[06/15 14:16:21] Re-training INFO: iter: 74750/300480  CE: 3.0103  
[06/15 14:17:45] Re-training INFO: iter: 74875/300480  CE: 2.7993  
[06/15 14:19:08] Re-training INFO: iter: 75000/300480  CE: 3.2216  
[06/15 14:20:26] Re-training INFO: --> epoch:  60/240  avg CE: 2.8805  lr: 0.42677669529663687
[06/15 14:20:58] Re-training INFO: # of Test Samples: 50000.0
[06/15 14:20:58] Re-training INFO: Top-1/-5 acc: 58.35 / 82.48
[06/15 14:20:58] Re-training INFO: Top-1/-5 acc: 41.65 / 17.52
[06/15 14:20:58] Re-training INFO: 

[06/15 14:21:18] Re-training INFO: iter: 75125/300480  CE: 2.6287  
[06/15 14:22:40] Re-training INFO: iter: 75250/300480  CE: 2.7463  
[06/15 14:24:04] Re-training INFO: iter: 75375/300480  CE: 3.1626  
[06/15 14:25:28] Re-training INFO: iter: 75500/300480  CE: 2.7938  
[06/15 14:26:52] Re-training INFO: iter: 75625/300480  CE: 2.7623  
[06/15 14:28:15] Re-training INFO: iter: 75750/300480  CE: 2.6455  
[06/15 14:29:38] Re-training INFO: iter: 75875/300480  CE: 2.8253  
[06/15 14:31:02] Re-training INFO: iter: 76000/300480  CE: 2.7880  
[06/15 14:32:25] Re-training INFO: iter: 76125/300480  CE: 3.1043  
[06/15 14:33:49] Re-training INFO: iter: 76250/300480  CE: 2.4424  
[06/15 14:35:08] Re-training INFO: --> epoch:  61/240  avg CE: 2.8761  lr: 0.42444761496042005
[06/15 14:35:27] Re-training INFO: iter: 76375/300480  CE: 2.7677  
[06/15 14:36:51] Re-training INFO: iter: 76500/300480  CE: 2.8951  
[06/15 14:38:14] Re-training INFO: iter: 76625/300480  CE: 2.9798  
[06/15 14:39:38] Re-training INFO: iter: 76750/300480  CE: 2.5475  
[06/15 14:41:02] Re-training INFO: iter: 76875/300480  CE: 2.8937  
[06/15 14:42:25] Re-training INFO: iter: 77000/300480  CE: 2.8146  
[06/15 14:43:50] Re-training INFO: iter: 77125/300480  CE: 2.8445  
[06/15 14:45:13] Re-training INFO: iter: 77250/300480  CE: 2.5993  
[06/15 14:46:37] Re-training INFO: iter: 77375/300480  CE: 3.0685  
[06/15 14:47:59] Re-training INFO: iter: 77500/300480  CE: 2.8579  
[06/15 14:49:22] Re-training INFO: --> epoch:  62/240  avg CE: 2.8740  lr: 0.4220886439234385
[06/15 14:49:40] Re-training INFO: iter: 77625/300480  CE: 2.9269  
[06/15 14:51:03] Re-training INFO: iter: 77750/300480  CE: 2.8567  
[06/15 14:52:26] Re-training INFO: iter: 77875/300480  CE: 2.8442  
[06/15 14:53:50] Re-training INFO: iter: 78000/300480  CE: 2.7008  
[06/15 14:55:15] Re-training INFO: iter: 78125/300480  CE: 2.7260  
[06/15 14:56:38] Re-training INFO: iter: 78250/300480  CE: 2.7455  
[06/15 14:58:01] Re-training INFO: iter: 78375/300480  CE: 2.7022  
[06/15 14:59:25] Re-training INFO: iter: 78500/300480  CE: 2.6396  
[06/15 15:00:49] Re-training INFO: iter: 78625/300480  CE: 2.8997  
[06/15 15:02:11] Re-training INFO: iter: 78750/300480  CE: 3.1310  
[06/15 15:03:34] Re-training INFO: iter: 78875/300480  CE: 3.1152  
[06/15 15:03:34] Re-training INFO: --> epoch:  63/240  avg CE: 2.8713  lr: 0.4197001863832355
[06/15 15:05:13] Re-training INFO: iter: 79000/300480  CE: 2.8015  
[06/15 15:06:37] Re-training INFO: iter: 79125/300480  CE: 2.7305  
[06/15 15:08:00] Re-training INFO: iter: 79250/300480  CE: 2.9386  
[06/15 15:09:24] Re-training INFO: iter: 79375/300480  CE: 2.8119  
[06/15 15:10:48] Re-training INFO: iter: 79500/300480  CE: 2.9284  
[06/15 15:12:12] Re-training INFO: iter: 79625/300480  CE: 2.8895  
[06/15 15:13:36] Re-training INFO: iter: 79750/300480  CE: 3.0035  
[06/15 15:15:00] Re-training INFO: iter: 79875/300480  CE: 3.1508  
[06/15 15:16:22] Re-training INFO: iter: 80000/300480  CE: 2.9098  
[06/15 15:17:45] Re-training INFO: iter: 80125/300480  CE: 2.9346  
[06/15 15:17:45] Re-training INFO: --> epoch:  64/240  avg CE: 2.8606  lr: 0.41728265158971456
[06/15 15:19:23] Re-training INFO: iter: 80250/300480  CE: 2.6277  
[06/15 15:20:48] Re-training INFO: iter: 80375/300480  CE: 2.8503  
[06/15 15:22:12] Re-training INFO: iter: 80500/300480  CE: 2.6889  
[06/15 15:23:35] Re-training INFO: iter: 80625/300480  CE: 2.9041  
[06/15 15:24:59] Re-training INFO: iter: 80750/300480  CE: 2.5932  
[06/15 15:26:22] Re-training INFO: iter: 80875/300480  CE: 2.9393  
[06/15 15:27:47] Re-training INFO: iter: 81000/300480  CE: 3.0457  
[06/15 15:29:09] Re-training INFO: iter: 81125/300480  CE: 2.9846  
[06/15 15:30:33] Re-training INFO: iter: 81250/300480  CE: 2.4620  
[06/15 15:31:56] Re-training INFO: iter: 81375/300480  CE: 2.8898  
[06/15 15:31:58] Re-training INFO: --> epoch:  65/240  avg CE: 2.8626  lr: 0.4148364537750172
[06/15 15:33:36] Re-training INFO: iter: 81500/300480  CE: 2.9786  
[06/15 15:35:00] Re-training INFO: iter: 81625/300480  CE: 2.5841  
[06/15 15:36:23] Re-training INFO: iter: 81750/300480  CE: 2.9729  
[06/15 15:37:47] Re-training INFO: iter: 81875/300480  CE: 2.9609  
[06/15 15:39:11] Re-training INFO: iter: 82000/300480  CE: 3.0366  
[06/15 15:40:36] Re-training INFO: iter: 82125/300480  CE: 3.1118  
[06/15 15:41:59] Re-training INFO: iter: 82250/300480  CE: 2.8593  
[06/15 15:43:22] Re-training INFO: iter: 82375/300480  CE: 2.6783  
[06/15 15:44:45] Re-training INFO: iter: 82500/300480  CE: 2.8197  
[06/15 15:46:09] Re-training INFO: iter: 82625/300480  CE: 2.9958  
[06/15 15:46:12] Re-training INFO: --> epoch:  66/240  avg CE: 2.8582  lr: 0.4123620120825459
[06/15 15:47:47] Re-training INFO: iter: 82750/300480  CE: 2.6806  
[06/15 15:49:10] Re-training INFO: iter: 82875/300480  CE: 2.8824  
[06/15 15:50:35] Re-training INFO: iter: 83000/300480  CE: 2.5150  
[06/15 15:51:58] Re-training INFO: iter: 83125/300480  CE: 2.5744  
[06/15 15:53:22] Re-training INFO: iter: 83250/300480  CE: 3.0211  
[06/15 15:54:45] Re-training INFO: iter: 83375/300480  CE: 3.1731  
[06/15 15:56:10] Re-training INFO: iter: 83500/300480  CE: 2.8350  
[06/15 15:57:34] Re-training INFO: iter: 83625/300480  CE: 2.8619  
[06/15 15:58:57] Re-training INFO: iter: 83750/300480  CE: 3.1239  
[06/15 16:00:21] Re-training INFO: iter: 83875/300480  CE: 2.9004  
[06/15 16:00:25] Re-training INFO: --> epoch:  67/240  avg CE: 2.8595  lr: 0.4098597504951462
[06/15 16:01:59] Re-training INFO: iter: 84000/300480  CE: 2.8379  
[06/15 16:03:23] Re-training INFO: iter: 84125/300480  CE: 2.9697  
[06/15 16:04:47] Re-training INFO: iter: 84250/300480  CE: 2.9529  
[06/15 16:06:11] Re-training INFO: iter: 84375/300480  CE: 2.9919  
[06/15 16:07:35] Re-training INFO: iter: 84500/300480  CE: 2.7241  
[06/15 16:08:58] Re-training INFO: iter: 84625/300480  CE: 2.8099  
[06/15 16:10:22] Re-training INFO: iter: 84750/300480  CE: 2.8306  
[06/15 16:11:45] Re-training INFO: iter: 84875/300480  CE: 2.7380  
[06/15 16:13:09] Re-training INFO: iter: 85000/300480  CE: 3.2434  
[06/15 16:14:33] Re-training INFO: iter: 85125/300480  CE: 2.8180  
[06/15 16:14:38] Re-training INFO: --> epoch:  68/240  avg CE: 2.8614  lr: 0.4073300977624594
[06/15 16:16:12] Re-training INFO: iter: 85250/300480  CE: 2.7195  
[06/15 16:17:34] Re-training INFO: iter: 85375/300480  CE: 2.9071  
[06/15 16:18:59] Re-training INFO: iter: 85500/300480  CE: 2.9591  
[06/15 16:20:24] Re-training INFO: iter: 85625/300480  CE: 2.7551  
[06/15 16:21:47] Re-training INFO: iter: 85750/300480  CE: 2.8899  
[06/15 16:23:11] Re-training INFO: iter: 85875/300480  CE: 2.8673  
[06/15 16:24:36] Re-training INFO: iter: 86000/300480  CE: 2.9216  
[06/15 16:25:59] Re-training INFO: iter: 86125/300480  CE: 2.5572  
[06/15 16:27:22] Re-training INFO: iter: 86250/300480  CE: 3.0871  
[06/15 16:28:46] Re-training INFO: iter: 86375/300480  CE: 2.7627  
[06/15 16:28:53] Re-training INFO: --> epoch:  69/240  avg CE: 2.8446  lr: 0.4047734873274585
[06/15 16:30:25] Re-training INFO: iter: 86500/300480  CE: 2.7513  
[06/15 16:31:47] Re-training INFO: iter: 86625/300480  CE: 2.7415  
[06/15 16:33:13] Re-training INFO: iter: 86750/300480  CE: 2.9135  
[06/15 16:34:36] Re-training INFO: iter: 86875/300480  CE: 2.9131  
[06/15 16:36:00] Re-training INFO: iter: 87000/300480  CE: 2.7340  
[06/15 16:37:23] Re-training INFO: iter: 87125/300480  CE: 2.7800  
[06/15 16:38:46] Re-training INFO: iter: 87250/300480  CE: 2.8038  
[06/15 16:40:10] Re-training INFO: iter: 87375/300480  CE: 2.8165  
[06/15 16:41:35] Re-training INFO: iter: 87500/300480  CE: 2.4958  
[06/15 16:42:59] Re-training INFO: iter: 87625/300480  CE: 2.8135  
[06/15 16:43:07] Re-training INFO: --> epoch:  70/240  avg CE: 2.8526  lr: 0.40219035725218016
[06/15 16:44:36] Re-training INFO: iter: 87750/300480  CE: 2.6041  
[06/15 16:46:01] Re-training INFO: iter: 87875/300480  CE: 2.9598  
[06/15 16:47:23] Re-training INFO: iter: 88000/300480  CE: 3.2257  
[06/15 16:48:47] Re-training INFO: iter: 88125/300480  CE: 2.6990  
[06/15 16:50:12] Re-training INFO: iter: 88250/300480  CE: 2.7354  
[06/15 16:51:36] Re-training INFO: iter: 88375/300480  CE: 2.8241  
[06/15 16:53:00] Re-training INFO: iter: 88500/300480  CE: 2.6505  
[06/15 16:54:25] Re-training INFO: iter: 88625/300480  CE: 2.8759  
[06/15 16:55:50] Re-training INFO: iter: 88750/300480  CE: 2.4993  
[06/15 16:57:13] Re-training INFO: iter: 88875/300480  CE: 2.9746  
[06/15 16:57:22] Re-training INFO: --> epoch:  71/240  avg CE: 2.8395  lr: 0.39958115014266476
[06/15 16:58:50] Re-training INFO: iter: 89000/300480  CE: 2.8941  
[06/15 17:00:13] Re-training INFO: iter: 89125/300480  CE: 2.8656  
[06/15 17:01:37] Re-training INFO: iter: 89250/300480  CE: 3.0265  
[06/15 17:03:00] Re-training INFO: iter: 89375/300480  CE: 2.5014  
[06/15 17:04:24] Re-training INFO: iter: 89500/300480  CE: 3.0980  
[06/15 17:05:48] Re-training INFO: iter: 89625/300480  CE: 2.7863  
[06/15 17:07:11] Re-training INFO: iter: 89750/300480  CE: 2.9278  
[06/15 17:08:33] Re-training INFO: iter: 89875/300480  CE: 2.8267  
[06/15 17:09:57] Re-training INFO: iter: 90000/300480  CE: 2.8826  
[06/15 17:11:21] Re-training INFO: iter: 90125/300480  CE: 2.9914  
[06/15 17:11:31] Re-training INFO: --> epoch:  72/240  avg CE: 2.8353  lr: 0.39694631307311834
[06/15 17:12:58] Re-training INFO: iter: 90250/300480  CE: 2.8470  
[06/15 17:14:23] Re-training INFO: iter: 90375/300480  CE: 2.9342  
[06/15 17:15:46] Re-training INFO: iter: 90500/300480  CE: 3.0579  
[06/15 17:17:11] Re-training INFO: iter: 90625/300480  CE: 3.0386  
[06/15 17:18:34] Re-training INFO: iter: 90750/300480  CE: 2.7836  
[06/15 17:19:58] Re-training INFO: iter: 90875/300480  CE: 2.8091  
[06/15 17:21:21] Re-training INFO: iter: 91000/300480  CE: 2.8973  
[06/15 17:22:44] Re-training INFO: iter: 91125/300480  CE: 2.9441  
[06/15 17:24:09] Re-training INFO: iter: 91250/300480  CE: 2.6017  
[06/15 17:25:33] Re-training INFO: iter: 91375/300480  CE: 2.7763  
[06/15 17:25:45] Re-training INFO: --> epoch:  73/240  avg CE: 2.8407  lr: 0.39428629750930844
[06/15 17:27:11] Re-training INFO: iter: 91500/300480  CE: 2.5644  
[06/15 17:28:35] Re-training INFO: iter: 91625/300480  CE: 2.8455  
[06/15 17:29:58] Re-training INFO: iter: 91750/300480  CE: 2.7333  
[06/15 17:31:20] Re-training INFO: iter: 91875/300480  CE: 2.8416  
[06/15 17:32:44] Re-training INFO: iter: 92000/300480  CE: 2.7435  
[06/15 17:34:08] Re-training INFO: iter: 92125/300480  CE: 2.7721  
[06/15 17:35:30] Re-training INFO: iter: 92250/300480  CE: 2.9637  
[06/15 17:36:54] Re-training INFO: iter: 92375/300480  CE: 2.8247  
[06/15 17:38:18] Re-training INFO: iter: 92500/300480  CE: 2.8887  
[06/15 17:39:41] Re-training INFO: iter: 92625/300480  CE: 2.6422  
[06/15 17:39:54] Re-training INFO: --> epoch:  74/240  avg CE: 2.8310  lr: 0.3916015592312082
[06/15 17:41:19] Re-training INFO: iter: 92750/300480  CE: 2.7414  
[06/15 17:42:42] Re-training INFO: iter: 92875/300480  CE: 2.8604  
[06/15 17:44:07] Re-training INFO: iter: 93000/300480  CE: 2.9605  
[06/15 17:45:31] Re-training INFO: iter: 93125/300480  CE: 2.6897  
[06/15 17:46:55] Re-training INFO: iter: 93250/300480  CE: 2.7957  
[06/15 17:48:18] Re-training INFO: iter: 93375/300480  CE: 3.0159  
[06/15 17:49:43] Re-training INFO: iter: 93500/300480  CE: 2.7620  
[06/15 17:51:06] Re-training INFO: iter: 93625/300480  CE: 2.8551  
[06/15 17:52:29] Re-training INFO: iter: 93750/300480  CE: 2.9241  
[06/15 17:53:53] Re-training INFO: iter: 93875/300480  CE: 2.7891  
[06/15 17:54:08] Re-training INFO: --> epoch:  75/240  avg CE: 2.8299  lr: 0.38889255825490054
[06/15 17:55:30] Re-training INFO: iter: 94000/300480  CE: 2.8562  
[06/15 17:56:54] Re-training INFO: iter: 94125/300480  CE: 2.8282  
[06/15 17:58:18] Re-training INFO: iter: 94250/300480  CE: 2.6420  
[06/15 17:59:42] Re-training INFO: iter: 94375/300480  CE: 2.5020  
[06/15 18:01:05] Re-training INFO: iter: 94500/300480  CE: 2.7570  
[06/15 18:02:28] Re-training INFO: iter: 94625/300480  CE: 2.8239  
[06/15 18:03:51] Re-training INFO: iter: 94750/300480  CE: 2.7539  
[06/15 18:05:15] Re-training INFO: iter: 94875/300480  CE: 3.0881  
[06/15 18:06:39] Re-training INFO: iter: 95000/300480  CE: 2.7722  
[06/15 18:08:03] Re-training INFO: iter: 95125/300480  CE: 2.6868  
[06/15 18:08:19] Re-training INFO: --> epoch:  76/240  avg CE: 2.8198  lr: 0.3861597587537568
[06/15 18:09:41] Re-training INFO: iter: 95250/300480  CE: 2.7779  
[06/15 18:11:04] Re-training INFO: iter: 95375/300480  CE: 3.0114  
[06/15 18:12:29] Re-training INFO: iter: 95500/300480  CE: 3.0196  
[06/15 18:13:52] Re-training INFO: iter: 95625/300480  CE: 2.8428  
[06/15 18:15:16] Re-training INFO: iter: 95750/300480  CE: 2.7396  
[06/15 18:16:40] Re-training INFO: iter: 95875/300480  CE: 2.9433  
[06/15 18:18:03] Re-training INFO: iter: 96000/300480  CE: 2.9043  
[06/15 18:19:28] Re-training INFO: iter: 96125/300480  CE: 3.0061  
[06/15 18:20:51] Re-training INFO: iter: 96250/300480  CE: 3.0737  
[06/15 18:22:14] Re-training INFO: iter: 96375/300480  CE: 2.9459  
[06/15 18:22:32] Re-training INFO: --> epoch:  77/240  avg CE: 2.8281  lr: 0.3834036289789029
[06/15 18:23:53] Re-training INFO: iter: 96500/300480  CE: 2.6283  
[06/15 18:25:18] Re-training INFO: iter: 96625/300480  CE: 2.6958  
[06/15 18:26:41] Re-training INFO: iter: 96750/300480  CE: 2.8591  
[06/15 18:28:04] Re-training INFO: iter: 96875/300480  CE: 3.0696  
[06/15 18:29:28] Re-training INFO: iter: 97000/300480  CE: 2.5469  
[06/15 18:30:54] Re-training INFO: iter: 97125/300480  CE: 2.8286  
[06/15 18:32:16] Re-training INFO: iter: 97250/300480  CE: 2.6848  
[06/15 18:33:41] Re-training INFO: iter: 97375/300480  CE: 2.9810  
[06/15 18:35:04] Re-training INFO: iter: 97500/300480  CE: 3.2004  
[06/15 18:36:29] Re-training INFO: iter: 97625/300480  CE: 2.8001  
[06/15 18:36:47] Re-training INFO: --> epoch:  78/240  avg CE: 2.8171  lr: 0.3806246411789872
[06/15 18:38:07] Re-training INFO: iter: 97750/300480  CE: 2.8581  
[06/15 18:39:31] Re-training INFO: iter: 97875/300480  CE: 2.7042  
[06/15 18:40:54] Re-training INFO: iter: 98000/300480  CE: 2.7383  
[06/15 18:42:17] Re-training INFO: iter: 98125/300480  CE: 2.9634  
[06/15 18:43:42] Re-training INFO: iter: 98250/300480  CE: 2.9337  
[06/15 18:45:05] Re-training INFO: iter: 98375/300480  CE: 2.9552  
[06/15 18:46:30] Re-training INFO: iter: 98500/300480  CE: 2.7707  
[06/15 18:47:53] Re-training INFO: iter: 98625/300480  CE: 2.8261  
[06/15 18:49:18] Re-training INFO: iter: 98750/300480  CE: 2.5267  
[06/15 18:50:42] Re-training INFO: iter: 98875/300480  CE: 2.6691  
[06/15 18:51:01] Re-training INFO: --> epoch:  79/240  avg CE: 2.8169  lr: 0.3778232715192631
[06/15 18:52:20] Re-training INFO: iter: 99000/300480  CE: 2.7813  
[06/15 18:53:44] Re-training INFO: iter: 99125/300480  CE: 2.8522  
[06/15 18:55:08] Re-training INFO: iter: 99250/300480  CE: 2.8640  
[06/15 18:56:31] Re-training INFO: iter: 99375/300480  CE: 2.8172  
[06/15 18:57:54] Re-training INFO: iter: 99500/300480  CE: 2.7108  
[06/15 18:59:18] Re-training INFO: iter: 99625/300480  CE: 2.7132  
[06/15 19:00:41] Re-training INFO: iter: 99750/300480  CE: 2.4785  
[06/15 19:02:05] Re-training INFO: iter: 99875/300480  CE: 2.7976  
[06/15 19:03:28] Re-training INFO: iter: 100000/300480  CE: 3.0311  
[06/15 19:04:51] Re-training INFO: iter: 100125/300480  CE: 2.9583  
[06/15 19:05:12] Re-training INFO: --> epoch:  80/240  avg CE: 2.8093  lr: 0.375
[06/15 19:05:44] Re-training INFO: # of Test Samples: 50000.0
[06/15 19:05:44] Re-training INFO: Top-1/-5 acc: 60.14 / 83.70
[06/15 19:05:44] Re-training INFO: Top-1/-5 acc: 39.86 / 16.30
[06/15 19:05:44] Re-training INFO: 

[06/15 19:07:02] Re-training INFO: iter: 100250/300480  CE: 2.7034  
[06/15 19:08:25] Re-training INFO: iter: 100375/300480  CE: 2.5847  
[06/15 19:09:49] Re-training INFO: iter: 100500/300480  CE: 2.7133  
[06/15 19:11:14] Re-training INFO: iter: 100625/300480  CE: 2.4847  
[06/15 19:12:36] Re-training INFO: iter: 100750/300480  CE: 2.5811  
[06/15 19:14:01] Re-training INFO: iter: 100875/300480  CE: 2.7433  
[06/15 19:15:25] Re-training INFO: iter: 101000/300480  CE: 2.9625  
[06/15 19:16:48] Re-training INFO: iter: 101125/300480  CE: 3.0700  
[06/15 19:18:12] Re-training INFO: iter: 101250/300480  CE: 2.9639  
[06/15 19:19:35] Re-training INFO: iter: 101375/300480  CE: 2.7216  
[06/15 19:19:57] Re-training INFO: --> epoch:  81/240  avg CE: 2.7983  lr: 0.37215531037423877
[06/15 19:21:13] Re-training INFO: iter: 101500/300480  CE: 2.8159  
[06/15 19:22:37] Re-training INFO: iter: 101625/300480  CE: 2.7187  
[06/15 19:24:00] Re-training INFO: iter: 101750/300480  CE: 2.9427  
[06/15 19:25:24] Re-training INFO: iter: 101875/300480  CE: 2.9527  
[06/15 19:26:47] Re-training INFO: iter: 102000/300480  CE: 2.7692  
[06/15 19:28:11] Re-training INFO: iter: 102125/300480  CE: 2.9612  
[06/15 19:29:35] Re-training INFO: iter: 102250/300480  CE: 2.7929  
[06/15 19:31:00] Re-training INFO: iter: 102375/300480  CE: 2.5350  
[06/15 19:32:24] Re-training INFO: iter: 102500/300480  CE: 2.7980  
[06/15 19:33:47] Re-training INFO: iter: 102625/300480  CE: 2.8380  
[06/15 19:34:11] Re-training INFO: --> epoch:  82/240  avg CE: 2.8081  lr: 0.3692896900649021
[06/15 19:35:25] Re-training INFO: iter: 102750/300480  CE: 3.0461  
[06/15 19:36:49] Re-training INFO: iter: 102875/300480  CE: 2.7047  
[06/15 19:38:12] Re-training INFO: iter: 103000/300480  CE: 2.9946  
[06/15 19:39:35] Re-training INFO: iter: 103125/300480  CE: 2.6249  
[06/15 19:41:00] Re-training INFO: iter: 103250/300480  CE: 2.8282  
[06/15 19:42:23] Re-training INFO: iter: 103375/300480  CE: 2.7470  
[06/15 19:43:47] Re-training INFO: iter: 103500/300480  CE: 2.9948  
[06/15 19:45:09] Re-training INFO: iter: 103625/300480  CE: 2.7374  
[06/15 19:46:33] Re-training INFO: iter: 103750/300480  CE: 2.9673  
[06/15 19:47:56] Re-training INFO: iter: 103875/300480  CE: 3.1060  
[06/15 19:48:22] Re-training INFO: --> epoch:  83/240  avg CE: 2.7994  lr: 0.36640363008127785
[06/15 19:49:36] Re-training INFO: iter: 104000/300480  CE: 2.6888  
[06/15 19:51:00] Re-training INFO: iter: 104125/300480  CE: 2.6269  
[06/15 19:52:25] Re-training INFO: iter: 104250/300480  CE: 2.7956  
[06/15 19:53:49] Re-training INFO: iter: 104375/300480  CE: 3.0216  
[06/15 19:55:12] Re-training INFO: iter: 104500/300480  CE: 3.0566  
[06/15 19:56:37] Re-training INFO: iter: 104625/300480  CE: 2.7630  
[06/15 19:58:00] Re-training INFO: iter: 104750/300480  CE: 2.7198  
[06/15 19:59:24] Re-training INFO: iter: 104875/300480  CE: 2.8990  
[06/15 20:00:47] Re-training INFO: iter: 105000/300480  CE: 2.9065  
[06/15 20:02:11] Re-training INFO: iter: 105125/300480  CE: 2.7625  
[06/15 20:02:38] Re-training INFO: --> epoch:  84/240  avg CE: 2.8049  lr: 0.3634976249348867
[06/15 20:03:50] Re-training INFO: iter: 105250/300480  CE: 2.9471  
[06/15 20:05:14] Re-training INFO: iter: 105375/300480  CE: 3.0640  
[06/15 20:06:37] Re-training INFO: iter: 105500/300480  CE: 2.7983  
[06/15 20:08:01] Re-training INFO: iter: 105625/300480  CE: 2.5928  
[06/15 20:09:24] Re-training INFO: iter: 105750/300480  CE: 2.7732  
[06/15 20:10:48] Re-training INFO: iter: 105875/300480  CE: 2.5456  
[06/15 20:12:12] Re-training INFO: iter: 106000/300480  CE: 2.7082  
[06/15 20:13:36] Re-training INFO: iter: 106125/300480  CE: 2.6124  
[06/15 20:14:59] Re-training INFO: iter: 106250/300480  CE: 2.6300  
[06/15 20:16:23] Re-training INFO: iter: 106375/300480  CE: 2.7393  
[06/15 20:16:51] Re-training INFO: --> epoch:  85/240  avg CE: 2.7978  lr: 0.3605721725547503
[06/15 20:18:02] Re-training INFO: iter: 106500/300480  CE: 2.8656  
[06/15 20:19:25] Re-training INFO: iter: 106625/300480  CE: 2.7592  
[06/15 20:20:51] Re-training INFO: iter: 106750/300480  CE: 3.0433  
[06/15 20:22:14] Re-training INFO: iter: 106875/300480  CE: 2.9187  
[06/15 20:23:37] Re-training INFO: iter: 107000/300480  CE: 2.6493  
[06/15 20:25:00] Re-training INFO: iter: 107125/300480  CE: 2.6723  
[06/15 20:26:25] Re-training INFO: iter: 107250/300480  CE: 3.0426  
[06/15 20:27:48] Re-training INFO: iter: 107375/300480  CE: 2.9230  
[06/15 20:29:12] Re-training INFO: iter: 107500/300480  CE: 3.1294  
[06/15 20:30:35] Re-training INFO: iter: 107625/300480  CE: 2.5476  
[06/15 20:31:05] Re-training INFO: --> epoch:  86/240  avg CE: 2.7941  lr: 0.3576277742020738
[06/15 20:32:16] Re-training INFO: iter: 107750/300480  CE: 2.7827  
[06/15 20:33:40] Re-training INFO: iter: 107875/300480  CE: 2.7189  
[06/15 20:35:03] Re-training INFO: iter: 108000/300480  CE: 2.6626  
[06/15 20:36:27] Re-training INFO: iter: 108125/300480  CE: 2.6315  
[06/15 20:37:52] Re-training INFO: iter: 108250/300480  CE: 2.6721  
[06/15 20:39:15] Re-training INFO: iter: 108375/300480  CE: 2.8903  
[06/15 20:40:39] Re-training INFO: iter: 108500/300480  CE: 2.7448  
[06/15 20:42:02] Re-training INFO: iter: 108625/300480  CE: 2.8633  
[06/15 20:43:27] Re-training INFO: iter: 108750/300480  CE: 2.9411  
[06/15 20:44:50] Re-training INFO: iter: 108875/300480  CE: 2.6558  
[06/15 20:45:20] Re-training INFO: --> epoch:  87/240  avg CE: 2.8040  lr: 0.35466493438435703
[06/15 20:46:27] Re-training INFO: iter: 109000/300480  CE: 3.1528  
[06/15 20:47:52] Re-training INFO: iter: 109125/300480  CE: 2.5871  
[06/15 20:49:14] Re-training INFO: iter: 109250/300480  CE: 2.8999  
[06/15 20:50:39] Re-training INFO: iter: 109375/300480  CE: 2.8300  
[06/15 20:52:01] Re-training INFO: iter: 109500/300480  CE: 2.4797  
[06/15 20:53:25] Re-training INFO: iter: 109625/300480  CE: 2.6116  
[06/15 20:54:50] Re-training INFO: iter: 109750/300480  CE: 3.0188  
[06/15 20:56:15] Re-training INFO: iter: 109875/300480  CE: 2.9684  
[06/15 20:57:38] Re-training INFO: iter: 110000/300480  CE: 2.6503  
[06/15 20:59:03] Re-training INFO: iter: 110125/300480  CE: 2.7783  
[06/15 20:59:36] Re-training INFO: --> epoch:  88/240  avg CE: 2.7878  lr: 0.35168416076895004
[06/15 21:00:43] Re-training INFO: iter: 110250/300480  CE: 2.8135  
[06/15 21:02:07] Re-training INFO: iter: 110375/300480  CE: 2.8128  
[06/15 21:03:31] Re-training INFO: iter: 110500/300480  CE: 2.8503  
[06/15 21:04:54] Re-training INFO: iter: 110625/300480  CE: 2.6310  
[06/15 21:06:19] Re-training INFO: iter: 110750/300480  CE: 2.4929  
[06/15 21:07:41] Re-training INFO: iter: 110875/300480  CE: 3.0143  
[06/15 21:09:05] Re-training INFO: iter: 111000/300480  CE: 2.5374  
[06/15 21:10:31] Re-training INFO: iter: 111125/300480  CE: 2.7852  
[06/15 21:11:54] Re-training INFO: iter: 111250/300480  CE: 2.4762  
[06/15 21:13:17] Re-training INFO: iter: 111375/300480  CE: 2.7034  
[06/15 21:13:51] Re-training INFO: --> epoch:  89/240  avg CE: 2.7825  lr: 0.34868596409606684
[06/15 21:14:56] Re-training INFO: iter: 111500/300480  CE: 2.8019  
[06/15 21:16:20] Re-training INFO: iter: 111625/300480  CE: 2.5015  
[06/15 21:17:43] Re-training INFO: iter: 111750/300480  CE: 2.7542  
[06/15 21:19:07] Re-training INFO: iter: 111875/300480  CE: 2.6542  
[06/15 21:20:31] Re-training INFO: iter: 112000/300480  CE: 3.0751  
[06/15 21:21:55] Re-training INFO: iter: 112125/300480  CE: 2.8467  
[06/15 21:23:19] Re-training INFO: iter: 112250/300480  CE: 2.6549  
[06/15 21:24:43] Re-training INFO: iter: 112375/300480  CE: 2.6926  
[06/15 21:26:06] Re-training INFO: iter: 112500/300480  CE: 2.9887  
[06/15 21:27:30] Re-training INFO: iter: 112625/300480  CE: 2.9431  
[06/15 21:28:05] Re-training INFO: --> epoch:  90/240  avg CE: 2.7900  lr: 0.34567085809127246
[06/15 21:29:09] Re-training INFO: iter: 112750/300480  CE: 2.9286  
[06/15 21:30:33] Re-training INFO: iter: 112875/300480  CE: 3.0125  
[06/15 21:31:56] Re-training INFO: iter: 113000/300480  CE: 3.0974  
[06/15 21:33:20] Re-training INFO: iter: 113125/300480  CE: 2.6653  
[06/15 21:34:42] Re-training INFO: iter: 113250/300480  CE: 3.0568  
[06/15 21:36:07] Re-training INFO: iter: 113375/300480  CE: 2.4967  
[06/15 21:37:32] Re-training INFO: iter: 113500/300480  CE: 2.4336  
[06/15 21:38:55] Re-training INFO: iter: 113625/300480  CE: 2.8160  
[06/15 21:40:19] Re-training INFO: iter: 113750/300480  CE: 3.0837  
[06/15 21:41:42] Re-training INFO: iter: 113875/300480  CE: 2.7337  
[06/15 21:42:18] Re-training INFO: --> epoch:  91/240  avg CE: 2.7856  lr: 0.3426393593774591
[06/15 21:43:20] Re-training INFO: iter: 114000/300480  CE: 2.9080  
[06/15 21:44:45] Re-training INFO: iter: 114125/300480  CE: 2.8333  
[06/15 21:46:09] Re-training INFO: iter: 114250/300480  CE: 2.7353  
[06/15 21:47:33] Re-training INFO: iter: 114375/300480  CE: 2.7806  
[06/15 21:48:57] Re-training INFO: iter: 114500/300480  CE: 2.9642  
[06/15 21:50:22] Re-training INFO: iter: 114625/300480  CE: 3.0322  
[06/15 21:51:45] Re-training INFO: iter: 114750/300480  CE: 2.7297  
[06/15 21:53:09] Re-training INFO: iter: 114875/300480  CE: 2.8131  
[06/15 21:54:35] Re-training INFO: iter: 115000/300480  CE: 2.4685  
[06/15 21:55:59] Re-training INFO: iter: 115125/300480  CE: 2.8169  
[06/15 21:56:36] Re-training INFO: --> epoch:  92/240  avg CE: 2.7770  lr: 0.339591987386325
[06/15 21:57:36] Re-training INFO: iter: 115250/300480  CE: 2.7078  
[06/15 21:59:00] Re-training INFO: iter: 115375/300480  CE: 2.5973  
[06/15 22:00:23] Re-training INFO: iter: 115500/300480  CE: 2.7107  
[06/15 22:01:46] Re-training INFO: iter: 115625/300480  CE: 2.5323  
[06/15 22:03:10] Re-training INFO: iter: 115750/300480  CE: 2.8154  
[06/15 22:04:33] Re-training INFO: iter: 115875/300480  CE: 2.8057  
[06/15 22:05:58] Re-training INFO: iter: 116000/300480  CE: 2.9223  
[06/15 22:07:23] Re-training INFO: iter: 116125/300480  CE: 2.8655  
[06/15 22:08:45] Re-training INFO: iter: 116250/300480  CE: 2.5795  
[06/15 22:10:08] Re-training INFO: iter: 116375/300480  CE: 2.6378  
[06/15 22:10:47] Re-training INFO: --> epoch:  93/240  avg CE: 2.7751  lr: 0.33652926426937324
[06/15 22:11:48] Re-training INFO: iter: 116500/300480  CE: 2.7868  
[06/15 22:13:11] Re-training INFO: iter: 116625/300480  CE: 2.7346  
[06/15 22:14:34] Re-training INFO: iter: 116750/300480  CE: 2.5716  
[06/15 22:15:58] Re-training INFO: iter: 116875/300480  CE: 2.7822  
[06/15 22:17:22] Re-training INFO: iter: 117000/300480  CE: 2.7269  
[06/15 22:18:46] Re-training INFO: iter: 117125/300480  CE: 2.6117  
[06/15 22:20:10] Re-training INFO: iter: 117250/300480  CE: 3.0013  
[06/15 22:21:33] Re-training INFO: iter: 117375/300480  CE: 2.8502  
[06/15 22:22:57] Re-training INFO: iter: 117500/300480  CE: 3.0510  
[06/15 22:24:20] Re-training INFO: iter: 117625/300480  CE: 2.7851  
[06/15 22:25:00] Re-training INFO: --> epoch:  94/240  avg CE: 2.7678  lr: 0.33345171480844277
[06/15 22:25:59] Re-training INFO: iter: 117750/300480  CE: 2.5418  
[06/15 22:27:22] Re-training INFO: iter: 117875/300480  CE: 2.8154  
[06/15 22:28:46] Re-training INFO: iter: 118000/300480  CE: 3.0207  
[06/15 22:30:09] Re-training INFO: iter: 118125/300480  CE: 2.5805  
[06/15 22:31:33] Re-training INFO: iter: 118250/300480  CE: 2.7812  
[06/15 22:32:57] Re-training INFO: iter: 118375/300480  CE: 2.7744  
[06/15 22:34:20] Re-training INFO: iter: 118500/300480  CE: 2.8512  
[06/15 22:35:44] Re-training INFO: iter: 118625/300480  CE: 2.7192  
[06/15 22:37:07] Re-training INFO: iter: 118750/300480  CE: 2.6296  
[06/15 22:38:31] Re-training INFO: iter: 118875/300480  CE: 2.8088  
[06/15 22:39:13] Re-training INFO: --> epoch:  95/240  avg CE: 2.7643  lr: 0.3303598663257904
[06/15 22:40:09] Re-training INFO: iter: 119000/300480  CE: 2.6267  
[06/15 22:41:34] Re-training INFO: iter: 119125/300480  CE: 2.8574  
[06/15 22:42:58] Re-training INFO: iter: 119250/300480  CE: 2.8936  
[06/15 22:44:21] Re-training INFO: iter: 119375/300480  CE: 2.7788  
[06/15 22:45:44] Re-training INFO: iter: 119500/300480  CE: 2.7460  
[06/15 22:47:09] Re-training INFO: iter: 119625/300480  CE: 2.6788  
[06/15 22:48:32] Re-training INFO: iter: 119750/300480  CE: 2.9125  
[06/15 22:49:55] Re-training INFO: iter: 119875/300480  CE: 2.6066  
[06/15 22:51:19] Re-training INFO: iter: 120000/300480  CE: 2.6368  
[06/15 22:52:43] Re-training INFO: iter: 120125/300480  CE: 2.7742  
[06/15 22:53:26] Re-training INFO: --> epoch:  96/240  avg CE: 2.7656  lr: 0.32725424859373686
[06/15 22:54:21] Re-training INFO: iter: 120250/300480  CE: 3.0883  
[06/15 22:55:43] Re-training INFO: iter: 120375/300480  CE: 2.6398  
[06/15 22:57:07] Re-training INFO: iter: 120500/300480  CE: 2.8761  
[06/15 22:58:31] Re-training INFO: iter: 120625/300480  CE: 2.8039  
[06/15 22:59:55] Re-training INFO: iter: 120750/300480  CE: 2.4495  
[06/15 23:01:18] Re-training INFO: iter: 120875/300480  CE: 2.8982  
[06/15 23:02:42] Re-training INFO: iter: 121000/300480  CE: 2.3712  
[06/15 23:04:05] Re-training INFO: iter: 121125/300480  CE: 2.9044  
[06/15 23:05:30] Re-training INFO: iter: 121250/300480  CE: 2.5336  
[06/15 23:06:53] Re-training INFO: iter: 121375/300480  CE: 2.9343  
[06/15 23:07:37] Re-training INFO: --> epoch:  97/240  avg CE: 2.7616  lr: 0.3241353937438927
[06/15 23:08:30] Re-training INFO: iter: 121500/300480  CE: 2.5329  
[06/15 23:09:54] Re-training INFO: iter: 121625/300480  CE: 2.6056  
[06/15 23:11:18] Re-training INFO: iter: 121750/300480  CE: 2.5310  
[06/15 23:12:42] Re-training INFO: iter: 121875/300480  CE: 2.6748  
[06/15 23:14:06] Re-training INFO: iter: 122000/300480  CE: 2.8563  
[06/15 23:15:30] Re-training INFO: iter: 122125/300480  CE: 2.7505  
[06/15 23:16:53] Re-training INFO: iter: 122250/300480  CE: 2.9767  
[06/15 23:18:18] Re-training INFO: iter: 122375/300480  CE: 3.0027  
[06/15 23:19:43] Re-training INFO: iter: 122500/300480  CE: 2.7088  
[06/15 23:21:06] Re-training INFO: iter: 122625/300480  CE: 2.6954  
[06/15 23:21:51] Re-training INFO: --> epoch:  98/240  avg CE: 2.7560  lr: 0.3210038361759807
[06/15 23:22:44] Re-training INFO: iter: 122750/300480  CE: 2.8096  
[06/15 23:24:07] Re-training INFO: iter: 122875/300480  CE: 2.8135  
[06/15 23:25:31] Re-training INFO: iter: 123000/300480  CE: 2.4709  
[06/15 23:26:53] Re-training INFO: iter: 123125/300480  CE: 3.0960  
[06/15 23:28:17] Re-training INFO: iter: 123250/300480  CE: 2.7932  
[06/15 23:29:41] Re-training INFO: iter: 123375/300480  CE: 2.8531  
[06/15 23:31:04] Re-training INFO: iter: 123500/300480  CE: 2.9667  
[06/15 23:32:27] Re-training INFO: iter: 123625/300480  CE: 2.7218  
[06/15 23:33:50] Re-training INFO: iter: 123750/300480  CE: 2.6929  
[06/15 23:35:15] Re-training INFO: iter: 123875/300480  CE: 2.8486  
[06/15 23:36:01] Re-training INFO: --> epoch:  99/240  avg CE: 2.7540  lr: 0.31786011246626855
[06/15 23:36:51] Re-training INFO: iter: 124000/300480  CE: 2.7857  
[06/15 23:38:16] Re-training INFO: iter: 124125/300480  CE: 2.6457  
[06/15 23:39:40] Re-training INFO: iter: 124250/300480  CE: 2.6801  
[06/15 23:41:03] Re-training INFO: iter: 124375/300480  CE: 2.6920  
[06/15 23:42:26] Re-training INFO: iter: 124500/300480  CE: 2.7797  
[06/15 23:43:50] Re-training INFO: iter: 124625/300480  CE: 2.8107  
[06/15 23:45:13] Re-training INFO: iter: 124750/300480  CE: 2.7951  
[06/15 23:46:36] Re-training INFO: iter: 124875/300480  CE: 2.8079  
[06/15 23:48:00] Re-training INFO: iter: 125000/300480  CE: 2.7170  
[06/15 23:49:23] Re-training INFO: iter: 125125/300480  CE: 2.8863  
[06/15 23:50:11] Re-training INFO: --> epoch: 100/240  avg CE: 2.7523  lr: 0.3147047612756302
[06/15 23:50:43] Re-training INFO: # of Test Samples: 50000.0
[06/15 23:50:43] Re-training INFO: Top-1/-5 acc: 60.97 / 84.22
[06/15 23:50:43] Re-training INFO: Top-1/-5 acc: 39.03 / 15.78
[06/15 23:50:43] Re-training INFO: 

[06/15 23:51:33] Re-training INFO: iter: 125250/300480  CE: 3.1035  
[06/15 23:52:56] Re-training INFO: iter: 125375/300480  CE: 2.9019  
[06/15 23:54:20] Re-training INFO: iter: 125500/300480  CE: 2.8384  
[06/15 23:55:45] Re-training INFO: iter: 125625/300480  CE: 2.8025  
[06/15 23:57:10] Re-training INFO: iter: 125750/300480  CE: 2.5949  
[06/15 23:58:33] Re-training INFO: iter: 125875/300480  CE: 2.7358  
[06/15 23:59:57] Re-training INFO: iter: 126000/300480  CE: 2.7694  
[06/16 00:01:20] Re-training INFO: iter: 126125/300480  CE: 2.4906  
[06/16 00:02:45] Re-training INFO: iter: 126250/300480  CE: 2.7133  
[06/16 00:04:09] Re-training INFO: iter: 126375/300480  CE: 2.8311  
[06/16 00:04:59] Re-training INFO: --> epoch: 101/240  avg CE: 2.7434  lr: 0.3115383232572483
[06/16 00:05:48] Re-training INFO: iter: 126500/300480  CE: 2.8024  
[06/16 00:07:13] Re-training INFO: iter: 126625/300480  CE: 2.9854  
[06/16 00:08:36] Re-training INFO: iter: 126750/300480  CE: 2.9280  
[06/16 00:09:59] Re-training INFO: iter: 126875/300480  CE: 2.7645  
[06/16 00:11:23] Re-training INFO: iter: 127000/300480  CE: 2.6272  
[06/16 00:12:47] Re-training INFO: iter: 127125/300480  CE: 2.8467  
[06/16 00:14:10] Re-training INFO: iter: 127250/300480  CE: 2.9394  
[06/16 00:15:34] Re-training INFO: iter: 127375/300480  CE: 2.5156  
[06/16 00:16:57] Re-training INFO: iter: 127500/300480  CE: 2.8814  
[06/16 00:18:21] Re-training INFO: iter: 127625/300480  CE: 2.5368  
[06/16 00:19:12] Re-training INFO: --> epoch: 102/240  avg CE: 2.7408  lr: 0.3083613409639764
[06/16 00:19:59] Re-training INFO: iter: 127750/300480  CE: 2.8063  
[06/16 00:21:23] Re-training INFO: iter: 127875/300480  CE: 2.7591  
[06/16 00:22:46] Re-training INFO: iter: 128000/300480  CE: 2.7004  
[06/16 00:24:09] Re-training INFO: iter: 128125/300480  CE: 2.7170  
[06/16 00:25:33] Re-training INFO: iter: 128250/300480  CE: 2.7239  
[06/16 00:26:57] Re-training INFO: iter: 128375/300480  CE: 2.7918  
[06/16 00:28:21] Re-training INFO: iter: 128500/300480  CE: 2.9599  
[06/16 00:29:44] Re-training INFO: iter: 128625/300480  CE: 2.6720  
[06/16 00:31:07] Re-training INFO: iter: 128750/300480  CE: 2.7586  
[06/16 00:32:31] Re-training INFO: iter: 128875/300480  CE: 2.8761  
[06/16 00:33:23] Re-training INFO: --> epoch: 103/240  avg CE: 2.7339  lr: 0.30517435875537524
[06/16 00:34:09] Re-training INFO: iter: 129000/300480  CE: 2.8737  
[06/16 00:35:33] Re-training INFO: iter: 129125/300480  CE: 2.8227  
[06/16 00:36:56] Re-training INFO: iter: 129250/300480  CE: 2.6730  
[06/16 00:38:19] Re-training INFO: iter: 129375/300480  CE: 2.8024  
[06/16 00:39:42] Re-training INFO: iter: 129500/300480  CE: 2.8888  
[06/16 00:41:06] Re-training INFO: iter: 129625/300480  CE: 2.7856  
[06/16 00:42:30] Re-training INFO: iter: 129750/300480  CE: 2.8208  
[06/16 00:43:54] Re-training INFO: iter: 129875/300480  CE: 2.6465  
[06/16 00:45:17] Re-training INFO: iter: 130000/300480  CE: 2.8329  
[06/16 00:46:42] Re-training INFO: iter: 130125/300480  CE: 2.7548  
[06/16 00:47:36] Re-training INFO: --> epoch: 104/240  avg CE: 2.7340  lr: 0.30197792270443985
[06/16 00:48:22] Re-training INFO: iter: 130250/300480  CE: 2.5916  
[06/16 00:49:44] Re-training INFO: iter: 130375/300480  CE: 2.6414  
[06/16 00:51:08] Re-training INFO: iter: 130500/300480  CE: 2.8536  
[06/16 00:52:31] Re-training INFO: iter: 130625/300480  CE: 2.8614  
[06/16 00:53:55] Re-training INFO: iter: 130750/300480  CE: 2.6242  
[06/16 00:55:17] Re-training INFO: iter: 130875/300480  CE: 2.5799  
[06/16 00:56:41] Re-training INFO: iter: 131000/300480  CE: 2.6038  
[06/16 00:58:04] Re-training INFO: iter: 131125/300480  CE: 2.7524  
[06/16 00:59:27] Re-training INFO: iter: 131250/300480  CE: 2.8859  
[06/16 01:00:51] Re-training INFO: iter: 131375/300480  CE: 2.6397  
[06/16 01:01:46] Re-training INFO: --> epoch: 105/240  avg CE: 2.7327  lr: 0.2987725805040321
[06/16 01:02:30] Re-training INFO: iter: 131500/300480  CE: 2.9611  
[06/16 01:03:54] Re-training INFO: iter: 131625/300480  CE: 2.5958  
[06/16 01:05:20] Re-training INFO: iter: 131750/300480  CE: 2.7363  
[06/16 01:06:42] Re-training INFO: iter: 131875/300480  CE: 2.5263  
[06/16 01:08:06] Re-training INFO: iter: 132000/300480  CE: 2.7038  
[06/16 01:09:29] Re-training INFO: iter: 132125/300480  CE: 2.5303  
[06/16 01:10:53] Re-training INFO: iter: 132250/300480  CE: 2.5166  
[06/16 01:12:18] Re-training INFO: iter: 132375/300480  CE: 2.5903  
[06/16 01:13:42] Re-training INFO: iter: 132500/300480  CE: 2.7205  
[06/16 01:15:06] Re-training INFO: iter: 132625/300480  CE: 2.5648  
[06/16 01:16:02] Re-training INFO: --> epoch: 106/240  avg CE: 2.7289  lr: 0.29555888137303693
[06/16 01:16:44] Re-training INFO: iter: 132750/300480  CE: 2.6982  
[06/16 01:18:07] Re-training INFO: iter: 132875/300480  CE: 2.5996  
[06/16 01:19:30] Re-training INFO: iter: 133000/300480  CE: 2.7272  
[06/16 01:20:54] Re-training INFO: iter: 133125/300480  CE: 2.6521  
[06/16 01:22:17] Re-training INFO: iter: 133250/300480  CE: 2.6095  
[06/16 01:23:40] Re-training INFO: iter: 133375/300480  CE: 2.8670  
[06/16 01:25:03] Re-training INFO: iter: 133500/300480  CE: 2.7910  
[06/16 01:26:27] Re-training INFO: iter: 133625/300480  CE: 2.5889  
[06/16 01:27:51] Re-training INFO: iter: 133750/300480  CE: 2.7687  
[06/16 01:29:14] Re-training INFO: iter: 133875/300480  CE: 2.6754  
[06/16 01:30:12] Re-training INFO: --> epoch: 107/240  avg CE: 2.7198  lr: 0.2923373759622561
[06/16 01:30:51] Re-training INFO: iter: 134000/300480  CE: 2.6881  
[06/16 01:32:17] Re-training INFO: iter: 134125/300480  CE: 2.9725  
[06/16 01:33:39] Re-training INFO: iter: 134250/300480  CE: 2.8161  
[06/16 01:35:03] Re-training INFO: iter: 134375/300480  CE: 2.5842  
[06/16 01:36:27] Re-training INFO: iter: 134500/300480  CE: 2.5427  
[06/16 01:37:49] Re-training INFO: iter: 134625/300480  CE: 2.7294  
[06/16 01:39:13] Re-training INFO: iter: 134750/300480  CE: 2.7362  
[06/16 01:40:38] Re-training INFO: iter: 134875/300480  CE: 2.5596  
[06/16 01:42:01] Re-training INFO: iter: 135000/300480  CE: 3.0752  
[06/16 01:43:24] Re-training INFO: iter: 135125/300480  CE: 2.7532  
[06/16 01:44:23] Re-training INFO: --> epoch: 108/240  avg CE: 2.7239  lr: 0.28910861626005774
[06/16 01:45:02] Re-training INFO: iter: 135250/300480  CE: 2.5588  
[06/16 01:46:26] Re-training INFO: iter: 135375/300480  CE: 2.7834  
[06/16 01:47:50] Re-training INFO: iter: 135500/300480  CE: 2.7557  
[06/16 01:49:14] Re-training INFO: iter: 135625/300480  CE: 3.0204  
[06/16 01:50:38] Re-training INFO: iter: 135750/300480  CE: 2.6560  
[06/16 01:52:03] Re-training INFO: iter: 135875/300480  CE: 2.6227  
[06/16 01:53:28] Re-training INFO: iter: 136000/300480  CE: 2.5055  
[06/16 01:54:51] Re-training INFO: iter: 136125/300480  CE: 2.7175  
[06/16 01:56:16] Re-training INFO: iter: 136250/300480  CE: 2.8280  
[06/16 01:57:39] Re-training INFO: iter: 136375/300480  CE: 2.7694  
[06/16 01:58:40] Re-training INFO: --> epoch: 109/240  avg CE: 2.7192  lr: 0.2858731554977949
[06/16 01:59:17] Re-training INFO: iter: 136500/300480  CE: 2.5911  
[06/16 02:00:42] Re-training INFO: iter: 136625/300480  CE: 2.6053  
[06/16 02:02:04] Re-training INFO: iter: 136750/300480  CE: 2.7831  
[06/16 02:03:28] Re-training INFO: iter: 136875/300480  CE: 2.5464  
[06/16 02:04:52] Re-training INFO: iter: 137000/300480  CE: 2.7280  
[06/16 02:06:16] Re-training INFO: iter: 137125/300480  CE: 2.6281  
[06/16 02:07:39] Re-training INFO: iter: 137250/300480  CE: 2.9273  
[06/16 02:09:03] Re-training INFO: iter: 137375/300480  CE: 2.4192  
[06/16 02:10:27] Re-training INFO: iter: 137500/300480  CE: 2.7292  
[06/16 02:11:51] Re-training INFO: iter: 137625/300480  CE: 3.0051  
[06/16 02:12:52] Re-training INFO: --> epoch: 110/240  avg CE: 2.7130  lr: 0.2826315480550129
[06/16 02:13:28] Re-training INFO: iter: 137750/300480  CE: 2.9756  
[06/16 02:14:52] Re-training INFO: iter: 137875/300480  CE: 2.6260  
[06/16 02:16:16] Re-training INFO: iter: 138000/300480  CE: 3.1091  
[06/16 02:17:38] Re-training INFO: iter: 138125/300480  CE: 2.9149  
[06/16 02:19:02] Re-training INFO: iter: 138250/300480  CE: 2.6446  
[06/16 02:20:25] Re-training INFO: iter: 138375/300480  CE: 2.6597  
[06/16 02:21:49] Re-training INFO: iter: 138500/300480  CE: 2.7030  
[06/16 02:23:11] Re-training INFO: iter: 138625/300480  CE: 2.7218  
[06/16 02:24:36] Re-training INFO: iter: 138750/300480  CE: 2.4759  
[06/16 02:25:59] Re-training INFO: iter: 138875/300480  CE: 2.6331  
[06/16 02:27:02] Re-training INFO: --> epoch: 111/240  avg CE: 2.7140  lr: 0.27938434936445944
[06/16 02:27:37] Re-training INFO: iter: 139000/300480  CE: 2.4427  
[06/16 02:29:02] Re-training INFO: iter: 139125/300480  CE: 2.8292  
[06/16 02:30:24] Re-training INFO: iter: 139250/300480  CE: 2.5564  
[06/16 02:31:49] Re-training INFO: iter: 139375/300480  CE: 2.9347  
[06/16 02:33:12] Re-training INFO: iter: 139500/300480  CE: 2.8569  
[06/16 02:34:36] Re-training INFO: iter: 139625/300480  CE: 2.7974  
[06/16 02:36:00] Re-training INFO: iter: 139750/300480  CE: 2.8289  
[06/16 02:37:24] Re-training INFO: iter: 139875/300480  CE: 2.7718  
[06/16 02:38:47] Re-training INFO: iter: 140000/300480  CE: 2.8222  
[06/16 02:40:11] Re-training INFO: iter: 140125/300480  CE: 2.8826  
[06/16 02:41:15] Re-training INFO: --> epoch: 112/240  avg CE: 2.7038  lr: 0.2761321158169134
[06/16 02:41:49] Re-training INFO: iter: 140250/300480  CE: 2.7137  
[06/16 02:43:13] Re-training INFO: iter: 140375/300480  CE: 2.6841  
[06/16 02:44:36] Re-training INFO: iter: 140500/300480  CE: 2.7706  
[06/16 02:46:00] Re-training INFO: iter: 140625/300480  CE: 2.7874  
[06/16 02:47:25] Re-training INFO: iter: 140750/300480  CE: 2.7001  
[06/16 02:48:48] Re-training INFO: iter: 140875/300480  CE: 2.8086  
[06/16 02:50:12] Re-training INFO: iter: 141000/300480  CE: 3.0586  
[06/16 02:51:36] Re-training INFO: iter: 141125/300480  CE: 2.5162  
[06/16 02:52:59] Re-training INFO: iter: 141250/300480  CE: 2.7150  
[06/16 02:54:23] Re-training INFO: iter: 141375/300480  CE: 2.5392  
[06/16 02:55:28] Re-training INFO: --> epoch: 113/240  avg CE: 2.7057  lr: 0.27287540466585064
[06/16 02:56:01] Re-training INFO: iter: 141500/300480  CE: 2.6755  
[06/16 02:57:26] Re-training INFO: iter: 141625/300480  CE: 2.6734  
[06/16 02:58:48] Re-training INFO: iter: 141750/300480  CE: 2.7758  
[06/16 03:00:13] Re-training INFO: iter: 141875/300480  CE: 2.8027  
[06/16 03:01:36] Re-training INFO: iter: 142000/300480  CE: 2.6939  
[06/16 03:02:59] Re-training INFO: iter: 142125/300480  CE: 2.7321  
[06/16 03:04:22] Re-training INFO: iter: 142250/300480  CE: 2.6692  
[06/16 03:05:46] Re-training INFO: iter: 142375/300480  CE: 2.6596  
[06/16 03:07:10] Re-training INFO: iter: 142500/300480  CE: 2.8784  
[06/16 03:08:34] Re-training INFO: iter: 142625/300480  CE: 2.5772  
[06/16 03:09:41] Re-training INFO: --> epoch: 114/240  avg CE: 2.6938  lr: 0.26961477393196126
[06/16 03:10:12] Re-training INFO: iter: 142750/300480  CE: 2.6377  
[06/16 03:11:36] Re-training INFO: iter: 142875/300480  CE: 2.8615  
[06/16 03:13:00] Re-training INFO: iter: 143000/300480  CE: 2.5389  
[06/16 03:14:24] Re-training INFO: iter: 143125/300480  CE: 2.8201  
[06/16 03:15:48] Re-training INFO: iter: 143250/300480  CE: 2.8423  
[06/16 03:17:10] Re-training INFO: iter: 143375/300480  CE: 2.5648  
[06/16 03:18:34] Re-training INFO: iter: 143500/300480  CE: 2.6160  
[06/16 03:19:56] Re-training INFO: iter: 143625/300480  CE: 2.3718  
[06/16 03:21:21] Re-training INFO: iter: 143750/300480  CE: 2.6187  
[06/16 03:22:44] Re-training INFO: iter: 143875/300480  CE: 2.6208  
[06/16 03:23:52] Re-training INFO: --> epoch: 115/240  avg CE: 2.6907  lr: 0.2663507823075358
[06/16 03:24:22] Re-training INFO: iter: 144000/300480  CE: 2.6090  
[06/16 03:25:46] Re-training INFO: iter: 144125/300480  CE: 2.5280  
[06/16 03:27:11] Re-training INFO: iter: 144250/300480  CE: 2.5056  
[06/16 03:28:33] Re-training INFO: iter: 144375/300480  CE: 2.5859  
[06/16 03:29:57] Re-training INFO: iter: 144500/300480  CE: 2.7624  
[06/16 03:31:20] Re-training INFO: iter: 144625/300480  CE: 2.6971  
[06/16 03:32:44] Re-training INFO: iter: 144750/300480  CE: 3.1331  
[06/16 03:34:07] Re-training INFO: iter: 144875/300480  CE: 2.7413  
[06/16 03:35:30] Re-training INFO: iter: 145000/300480  CE: 2.6263  
[06/16 03:36:55] Re-training INFO: iter: 145125/300480  CE: 2.4981  
[06/16 03:38:04] Re-training INFO: --> epoch: 116/240  avg CE: 2.6881  lr: 0.263083989060736
[06/16 03:38:33] Re-training INFO: iter: 145250/300480  CE: 2.8960  
[06/16 03:39:57] Re-training INFO: iter: 145375/300480  CE: 2.4815  
[06/16 03:41:22] Re-training INFO: iter: 145500/300480  CE: 2.5673  
[06/16 03:42:46] Re-training INFO: iter: 145625/300480  CE: 2.7402  
[06/16 03:44:09] Re-training INFO: iter: 145750/300480  CE: 2.9166  
[06/16 03:45:32] Re-training INFO: iter: 145875/300480  CE: 2.3189  
[06/16 03:46:55] Re-training INFO: iter: 146000/300480  CE: 2.8167  
[06/16 03:48:19] Re-training INFO: iter: 146125/300480  CE: 2.7807  
[06/16 03:49:43] Re-training INFO: iter: 146250/300480  CE: 2.3677  
[06/16 03:51:06] Re-training INFO: iter: 146375/300480  CE: 2.5948  
[06/16 03:52:18] Re-training INFO: --> epoch: 117/240  avg CE: 2.6862  lr: 0.25981495393976717
[06/16 03:52:45] Re-training INFO: iter: 146500/300480  CE: 2.6959  
[06/16 03:54:09] Re-training INFO: iter: 146625/300480  CE: 2.6154  
[06/16 03:55:32] Re-training INFO: iter: 146750/300480  CE: 2.8968  
[06/16 03:56:56] Re-training INFO: iter: 146875/300480  CE: 2.6773  
[06/16 03:58:20] Re-training INFO: iter: 147000/300480  CE: 2.6844  
[06/16 03:59:44] Re-training INFO: iter: 147125/300480  CE: 2.6993  
[06/16 04:01:08] Re-training INFO: iter: 147250/300480  CE: 2.7236  
[06/16 04:02:32] Re-training INFO: iter: 147375/300480  CE: 2.5200  
[06/16 04:03:57] Re-training INFO: iter: 147500/300480  CE: 2.6300  
[06/16 04:05:21] Re-training INFO: iter: 147625/300480  CE: 2.4161  
[06/16 04:06:33] Re-training INFO: --> epoch: 118/240  avg CE: 2.6869  lr: 0.2565442370769683
[06/16 04:06:59] Re-training INFO: iter: 147750/300480  CE: 2.6394  
[06/16 04:08:23] Re-training INFO: iter: 147875/300480  CE: 2.7585  
[06/16 04:09:46] Re-training INFO: iter: 148000/300480  CE: 2.7014  
[06/16 04:11:09] Re-training INFO: iter: 148125/300480  CE: 2.8985  
[06/16 04:12:32] Re-training INFO: iter: 148250/300480  CE: 2.4870  
[06/16 04:13:55] Re-training INFO: iter: 148375/300480  CE: 2.6769  
[06/16 04:15:20] Re-training INFO: iter: 148500/300480  CE: 2.7557  
[06/16 04:16:42] Re-training INFO: iter: 148625/300480  CE: 2.7100  
