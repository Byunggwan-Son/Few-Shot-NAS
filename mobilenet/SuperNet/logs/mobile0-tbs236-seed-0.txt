[05/04 09:06:26] SuperNet Training INFO: tag                 : mobile0-tbs236
[05/04 09:06:26] SuperNet Training INFO: seed                : 0
[05/04 09:06:26] SuperNet Training INFO: thresholds          : [36]
[05/04 09:06:26] SuperNet Training INFO: data_path           : ../../../dataset/ILSVRC2012
[05/04 09:06:26] SuperNet Training INFO: save_path           : ./SuperNet
[05/04 09:06:26] SuperNet Training INFO: search_space        : proxyless
[05/04 09:06:26] SuperNet Training INFO: valid_size          : 50000
[05/04 09:06:26] SuperNet Training INFO: num_gpus            : 8
[05/04 09:06:26] SuperNet Training INFO: workers             : 4
[05/04 09:06:26] SuperNet Training INFO: interval_ep_eval    : 8
[05/04 09:06:26] SuperNet Training INFO: train_batch_size    : 1024
[05/04 09:06:26] SuperNet Training INFO: test_batch_size     : 256
[05/04 09:06:26] SuperNet Training INFO: max_epoch           : 120
[05/04 09:06:26] SuperNet Training INFO: learning_rate       : 0.12
[05/04 09:06:26] SuperNet Training INFO: momentum            : 0.9
[05/04 09:06:26] SuperNet Training INFO: weight_decay        : 4e-05
[05/04 09:06:26] SuperNet Training INFO: nesterov            : True
[05/04 09:06:26] SuperNet Training INFO: lr_schedule_type    : cosine
[05/04 09:06:26] SuperNet Training INFO: label_smooth        : 0.1
[05/04 09:06:26] SuperNet Training INFO: rank                : 0
[05/04 09:06:26] SuperNet Training INFO: gpu                 : 0
[05/04 09:06:26] SuperNet Training INFO: save_name           : mobile0-tbs236-seed-0
[05/04 09:06:26] SuperNet Training INFO: log_path            : ./SuperNet/logs/mobile0-tbs236-seed-0.txt
[05/04 09:06:26] SuperNet Training INFO: ckpt_path           : ./SuperNet/checkpoint/mobile0-tbs236-seed-0.pt
[05/04 09:06:26] SuperNet Training INFO: dist_url            : tcp://127.0.0.1:23456
[05/04 09:06:26] SuperNet Training INFO: world_size          : 8
[05/04 09:06:26] SuperNet Training INFO: distributed         : True
[05/04 09:06:26] SuperNet Training INFO: ['3x3_MBConv3', '3x3_MBConv6', '5x5_MBConv3', '5x5_MBConv6', '7x7_MBConv3', '7x7_MBConv6', 'Identity']
[05/04 09:07:07] SuperNet Training INFO: DistributedDataParallel(
  (module): SuperNet(
    (first_conv): Sequential(
      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      (2): ReLU6(inplace=True)
    )
    (first_block): InvertedResidual(
      (depth_conv): Sequential(
        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): ReLU6(inplace=True)
      )
      (point_linear): Sequential(
        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (blocks): ModuleList(
      (0): ModuleList(
        (0): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(16, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=48, bias=False)
            (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(48, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (1): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (2): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(16, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=48, bias=False)
            (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(48, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (3): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=96, bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (4): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(16, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=48, bias=False)
            (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(48, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (5): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=96, bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
      )
      (1): ModuleList(
        (0): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (1): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (2): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=96, bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (3): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=192, bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (4): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96, bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (5): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192, bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (6): Identity()
      )
      (2): ModuleList(
        (0): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (1): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (2): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=96, bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (3): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=192, bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (4): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96, bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (5): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192, bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (6): Identity()
      )
      (3): ModuleList(
        (0): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (1): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (2): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=96, bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (3): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=192, bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (4): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96, bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (5): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192, bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (6): Identity()
      )
      (4): ModuleList(
        (0): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(96, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (1): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(192, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (2): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=96, bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(96, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (3): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=192, bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(192, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (4): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=96, bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(96, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (5): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=192, bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(192, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
      )
      (5): ModuleList(
        (0): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(120, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=120, bias=False)
            (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (1): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=240, bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (2): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)
            (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (3): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (4): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(120, 120, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=120, bias=False)
            (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (5): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(240, 240, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=240, bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (6): Identity()
      )
      (6): ModuleList(
        (0): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(120, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=120, bias=False)
            (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (1): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=240, bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (2): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)
            (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (3): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (4): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(120, 120, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=120, bias=False)
            (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (5): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(240, 240, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=240, bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (6): Identity()
      )
      (7): ModuleList(
        (0): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(120, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=120, bias=False)
            (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (1): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=240, bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (2): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)
            (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (3): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (4): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(120, 120, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=120, bias=False)
            (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (5): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(240, 240, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=240, bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (6): Identity()
      )
      (8): ModuleList(
        (0): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(120, 120, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=120, bias=False)
            (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(120, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (1): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (2): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=120, bias=False)
            (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(120, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (3): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=240, bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (4): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(120, 120, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=120, bias=False)
            (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(120, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (5): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(240, 240, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=240, bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
      )
      (9): ModuleList(
        (0): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(80, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=240, bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (1): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)
            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (2): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(80, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (3): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)
            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (4): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(80, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(240, 240, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=240, bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (5): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(480, 480, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=480, bias=False)
            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (6): Identity()
      )
      (10): ModuleList(
        (0): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(80, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=240, bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (1): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)
            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (2): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(80, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (3): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)
            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (4): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(80, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(240, 240, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=240, bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (5): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(480, 480, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=480, bias=False)
            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (6): Identity()
      )
      (11): ModuleList(
        (0): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(80, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=240, bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (1): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)
            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (2): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(80, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (3): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)
            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (4): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(80, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(240, 240, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=240, bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (5): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(480, 480, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=480, bias=False)
            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (6): Identity()
      )
      (12): ModuleList(
        (0): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(80, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=240, bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(240, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (1): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)
            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (2): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(80, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(240, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (3): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)
            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (4): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(80, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(240, 240, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=240, bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(240, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (5): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(480, 480, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=480, bias=False)
            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
      )
      (13): ModuleList(
        (0): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (1): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (2): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)
            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (3): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (4): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(288, 288, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=288, bias=False)
            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (5): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(576, 576, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=576, bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (6): Identity()
      )
      (14): ModuleList(
        (0): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (1): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (2): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)
            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (3): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (4): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(288, 288, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=288, bias=False)
            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (5): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(576, 576, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=576, bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (6): Identity()
      )
      (15): ModuleList(
        (0): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (1): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (2): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)
            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (3): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (4): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(288, 288, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=288, bias=False)
            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (5): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(576, 576, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=576, bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (6): Identity()
      )
      (16): ModuleList(
        (0): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(288, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (1): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (2): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=288, bias=False)
            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(288, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (3): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=576, bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (4): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(288, 288, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=288, bias=False)
            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(288, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (5): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(576, 576, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=576, bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
      )
      (17): ModuleList(
        (0): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (1): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)
            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (2): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (3): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)
            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (4): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(576, 576, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=576, bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (5): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(1152, 1152, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1152, bias=False)
            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (6): Identity()
      )
      (18): ModuleList(
        (0): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (1): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)
            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (2): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (3): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)
            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (4): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(576, 576, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=576, bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (5): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(1152, 1152, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1152, bias=False)
            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (6): Identity()
      )
      (19): ModuleList(
        (0): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (1): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)
            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (2): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (3): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)
            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (4): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(576, 576, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=576, bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (5): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(1152, 1152, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1152, bias=False)
            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (6): Identity()
      )
      (20): ModuleList(
        (0): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(576, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (1): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)
            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (2): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(576, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (3): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)
            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (4): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(576, 576, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=576, bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(576, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (5): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(1152, 1152, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1152, bias=False)
            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
      )
    )
    (feature_mix_layer): Sequential(
      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      (2): ReLU6(inplace=True)
    )
    (avgpool): AvgPool2d(kernel_size=7, stride=7, padding=0)
    (classifier): Sequential(
      (0): Linear(in_features=1280, out_features=1000, bias=True)
    )
  )
)
[05/04 09:07:34] SuperNet Training INFO: Trainset Size: 1231167
[05/04 09:07:34] SuperNet Training INFO: Validset Size:   50000
[05/04 09:07:34] SuperNet Training INFO: Compose(
    RandomResizedCrop(size=(224, 224), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=bilinear)
    RandomHorizontalFlip(p=0.5)
    ToTensor()
    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
)
[05/04 09:08:57] SuperNet Training INFO: tag                 : mobile0-tbs236
[05/04 09:08:57] SuperNet Training INFO: seed                : 0
[05/04 09:08:57] SuperNet Training INFO: thresholds          : [36]
[05/04 09:08:57] SuperNet Training INFO: data_path           : ../../../dataset/ILSVRC2012
[05/04 09:08:57] SuperNet Training INFO: save_path           : ./SuperNet
[05/04 09:08:57] SuperNet Training INFO: search_space        : proxyless
[05/04 09:08:57] SuperNet Training INFO: valid_size          : 50000
[05/04 09:08:57] SuperNet Training INFO: num_gpus            : 8
[05/04 09:08:57] SuperNet Training INFO: workers             : 4
[05/04 09:08:57] SuperNet Training INFO: interval_ep_eval    : 8
[05/04 09:08:57] SuperNet Training INFO: train_batch_size    : 1024
[05/04 09:08:57] SuperNet Training INFO: test_batch_size     : 256
[05/04 09:08:57] SuperNet Training INFO: max_epoch           : 120
[05/04 09:08:57] SuperNet Training INFO: learning_rate       : 0.12
[05/04 09:08:57] SuperNet Training INFO: momentum            : 0.9
[05/04 09:08:57] SuperNet Training INFO: weight_decay        : 4e-05
[05/04 09:08:57] SuperNet Training INFO: nesterov            : True
[05/04 09:08:57] SuperNet Training INFO: lr_schedule_type    : cosine
[05/04 09:08:57] SuperNet Training INFO: warmup              : False
[05/04 09:08:57] SuperNet Training INFO: label_smooth        : 0.1
[05/04 09:08:57] SuperNet Training INFO: rank                : 0
[05/04 09:08:57] SuperNet Training INFO: gpu                 : 0
[05/04 09:08:57] SuperNet Training INFO: save_name           : mobile0-tbs236-seed-0
[05/04 09:08:57] SuperNet Training INFO: log_path            : ./SuperNet/logs/mobile0-tbs236-seed-0.txt
[05/04 09:08:57] SuperNet Training INFO: ckpt_path           : ./SuperNet/checkpoint/mobile0-tbs236-seed-0.pt
[05/04 09:08:57] SuperNet Training INFO: dist_url            : tcp://127.0.0.1:23456
[05/04 09:08:57] SuperNet Training INFO: world_size          : 8
[05/04 09:08:57] SuperNet Training INFO: distributed         : True
[05/04 09:08:57] SuperNet Training INFO: ['3x3_MBConv3', '3x3_MBConv6', '5x5_MBConv3', '5x5_MBConv6', '7x7_MBConv3', '7x7_MBConv6', 'Identity']
[05/04 09:09:41] SuperNet Training INFO: DistributedDataParallel(
  (module): SuperNet(
    (first_conv): Sequential(
      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      (2): ReLU6(inplace=True)
    )
    (first_block): InvertedResidual(
      (depth_conv): Sequential(
        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)
        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
        (2): ReLU6(inplace=True)
      )
      (point_linear): Sequential(
        (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      )
    )
    (blocks): ModuleList(
      (0): ModuleList(
        (0): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(16, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=48, bias=False)
            (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(48, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (1): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (2): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(16, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=48, bias=False)
            (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(48, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (3): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=96, bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (4): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(16, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(48, 48, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=48, bias=False)
            (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(48, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (5): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=96, bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
      )
      (1): ModuleList(
        (0): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (1): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (2): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=96, bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (3): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=192, bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (4): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96, bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (5): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192, bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (6): Identity()
      )
      (2): ModuleList(
        (0): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (1): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (2): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=96, bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (3): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=192, bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (4): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96, bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (5): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192, bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (6): Identity()
      )
      (3): ModuleList(
        (0): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (1): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (2): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=96, bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (3): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=192, bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (4): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=96, bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(96, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (5): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192, bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (6): Identity()
      )
      (4): ModuleList(
        (0): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(96, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (1): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(192, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (2): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(96, 96, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=96, bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(96, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (3): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=192, bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(192, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (4): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(32, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(96, 96, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=96, bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(96, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (5): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(192, 192, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=192, bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(192, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
      )
      (5): ModuleList(
        (0): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(120, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=120, bias=False)
            (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (1): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=240, bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (2): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)
            (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (3): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (4): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(120, 120, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=120, bias=False)
            (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (5): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(240, 240, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=240, bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (6): Identity()
      )
      (6): ModuleList(
        (0): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(120, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=120, bias=False)
            (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (1): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=240, bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (2): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)
            (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (3): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (4): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(120, 120, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=120, bias=False)
            (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (5): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(240, 240, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=240, bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (6): Identity()
      )
      (7): ModuleList(
        (0): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(120, 120, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=120, bias=False)
            (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (1): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=240, bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (2): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)
            (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (3): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (4): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(120, 120, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=120, bias=False)
            (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (5): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(240, 240, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=240, bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (6): Identity()
      )
      (8): ModuleList(
        (0): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(120, 120, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=120, bias=False)
            (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(120, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (1): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (2): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=120, bias=False)
            (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(120, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (3): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=240, bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (4): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(120, 120, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=120, bias=False)
            (1): BatchNorm2d(120, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(120, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (5): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(240, 240, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=240, bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
      )
      (9): ModuleList(
        (0): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(80, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=240, bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (1): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)
            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (2): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(80, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (3): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)
            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (4): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(80, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(240, 240, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=240, bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (5): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(480, 480, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=480, bias=False)
            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (6): Identity()
      )
      (10): ModuleList(
        (0): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(80, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=240, bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (1): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)
            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (2): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(80, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (3): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)
            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (4): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(80, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(240, 240, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=240, bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (5): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(480, 480, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=480, bias=False)
            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (6): Identity()
      )
      (11): ModuleList(
        (0): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(80, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=240, bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (1): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)
            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (2): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(80, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (3): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)
            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (4): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(80, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(240, 240, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=240, bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (5): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(480, 480, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=480, bias=False)
            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (6): Identity()
      )
      (12): ModuleList(
        (0): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(80, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=240, bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(240, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (1): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)
            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (2): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(80, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(240, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (3): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)
            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (4): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(80, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(240, 240, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=240, bias=False)
            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(240, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (5): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(480, 480, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=480, bias=False)
            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
      )
      (13): ModuleList(
        (0): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (1): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (2): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)
            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (3): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (4): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(288, 288, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=288, bias=False)
            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (5): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(576, 576, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=576, bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (6): Identity()
      )
      (14): ModuleList(
        (0): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (1): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (2): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)
            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (3): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (4): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(288, 288, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=288, bias=False)
            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (5): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(576, 576, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=576, bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (6): Identity()
      )
      (15): ModuleList(
        (0): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)
            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (1): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (2): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)
            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (3): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (4): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(288, 288, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=288, bias=False)
            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (5): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(576, 576, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=576, bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (6): Identity()
      )
      (16): ModuleList(
        (0): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(288, 288, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=288, bias=False)
            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(288, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (1): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (2): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(288, 288, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=288, bias=False)
            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(288, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (3): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=576, bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (4): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(288, 288, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=288, bias=False)
            (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(288, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (5): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(576, 576, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), groups=576, bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
      )
      (17): ModuleList(
        (0): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (1): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)
            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (2): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (3): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)
            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (4): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(576, 576, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=576, bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (5): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(1152, 1152, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1152, bias=False)
            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (6): Identity()
      )
      (18): ModuleList(
        (0): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (1): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)
            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (2): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (3): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)
            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (4): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(576, 576, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=576, bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (5): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(1152, 1152, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1152, bias=False)
            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (6): Identity()
      )
      (19): ModuleList(
        (0): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (1): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)
            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (2): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (3): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)
            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (4): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(576, 576, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=576, bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (5): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(1152, 1152, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1152, bias=False)
            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (6): Identity()
      )
      (20): ModuleList(
        (0): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(576, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (1): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)
            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (2): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(576, 576, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=576, bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(576, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (3): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)
            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (4): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(576, 576, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=576, bias=False)
            (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(576, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
        (5): InvertedResidual(
          (inverted_bottleneck): Sequential(
            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (depth_conv): Sequential(
            (0): Conv2d(1152, 1152, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1152, bias=False)
            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
            (2): ReLU6(inplace=True)
          )
          (point_linear): Sequential(
            (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
          )
        )
      )
    )
    (feature_mix_layer): Sequential(
      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)
      (2): ReLU6(inplace=True)
    )
    (avgpool): AvgPool2d(kernel_size=7, stride=7, padding=0)
    (classifier): Sequential(
      (0): Linear(in_features=1280, out_features=1000, bias=True)
    )
  )
)
[05/04 09:10:08] SuperNet Training INFO: Trainset Size: 1231167
[05/04 09:10:08] SuperNet Training INFO: Validset Size:   50000
[05/04 09:10:08] SuperNet Training INFO: Compose(
    RandomResizedCrop(size=(224, 224), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=bilinear)
    RandomHorizontalFlip(p=0.5)
    ToTensor()
    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
)
[05/04 09:10:08] SuperNet Training INFO: --> START mobile0-tbs236-seed-0
[05/04 09:10:08] SuperNet Training INFO: {0: 0, 1: 0}
[05/04 09:12:39] SuperNet Training INFO: iter:   120/144360  CE: 6.9282  
[05/04 09:13:41] SuperNet Training INFO: iter:   240/144360  CE: 6.8694  
[05/04 09:14:43] SuperNet Training INFO: iter:   360/144360  CE: 6.9166  
[05/04 09:15:45] SuperNet Training INFO: iter:   480/144360  CE: 6.9297  
[05/04 09:16:46] SuperNet Training INFO: iter:   600/144360  CE: 6.8946  
[05/04 09:17:49] SuperNet Training INFO: iter:   720/144360  CE: 6.9075  
[05/04 09:18:51] SuperNet Training INFO: iter:   840/144360  CE: 6.9133  
[05/04 09:19:53] SuperNet Training INFO: iter:   960/144360  CE: 6.9319  
[05/04 09:20:56] SuperNet Training INFO: iter:  1080/144360  CE: 6.8379  
[05/04 09:21:58] SuperNet Training INFO: iter:  1200/144360  CE: 6.8813  
[05/04 09:21:58] SuperNet Training INFO: --> epoch:   1/120  avg CE: 6.8902  lr: 0.11997943949853311  
[05/04 09:23:39] SuperNet Training INFO: iter:  1320/144360  CE: 6.8048  
[05/04 09:24:41] SuperNet Training INFO: iter:  1440/144360  CE: 6.7286  
[05/04 09:25:43] SuperNet Training INFO: iter:  1560/144360  CE: 6.7282  
[05/04 09:26:44] SuperNet Training INFO: iter:  1680/144360  CE: 6.7053  
[05/04 09:27:45] SuperNet Training INFO: iter:  1800/144360  CE: 6.8240  
[05/04 09:28:47] SuperNet Training INFO: iter:  1920/144360  CE: 6.8155  
[05/04 09:29:50] SuperNet Training INFO: iter:  2040/144360  CE: 6.7605  
[05/04 09:30:50] SuperNet Training INFO: iter:  2160/144360  CE: 6.7643  
[05/04 09:31:54] SuperNet Training INFO: iter:  2280/144360  CE: 6.6555  
[05/04 09:32:56] SuperNet Training INFO: iter:  2400/144360  CE: 6.6721  
[05/04 09:32:58] SuperNet Training INFO: --> epoch:   2/120  avg CE: 6.7633  lr: 0.11991777208527424  
[05/04 09:34:36] SuperNet Training INFO: iter:  2520/144360  CE: 6.6561  
[05/04 09:35:38] SuperNet Training INFO: iter:  2640/144360  CE: 6.7718  
[05/04 09:36:43] SuperNet Training INFO: iter:  2760/144360  CE: 6.6444  
[05/04 09:37:45] SuperNet Training INFO: iter:  2880/144360  CE: 6.6574  
[05/04 09:38:49] SuperNet Training INFO: iter:  3000/144360  CE: 6.7138  
[05/04 09:39:51] SuperNet Training INFO: iter:  3120/144360  CE: 6.6464  
[05/04 09:40:54] SuperNet Training INFO: iter:  3240/144360  CE: 6.6032  
[05/04 09:41:58] SuperNet Training INFO: iter:  3360/144360  CE: 6.7234  
[05/04 09:43:00] SuperNet Training INFO: iter:  3480/144360  CE: 6.5740  
[05/04 09:44:02] SuperNet Training INFO: iter:  3600/144360  CE: 6.5990  
[05/04 09:44:06] SuperNet Training INFO: --> epoch:   3/120  avg CE: 6.6203  lr: 0.11981504002398749  
[05/04 09:45:42] SuperNet Training INFO: iter:  3720/144360  CE: 6.4296  
[05/04 09:46:46] SuperNet Training INFO: iter:  3840/144360  CE: 6.6770  
[05/04 09:47:49] SuperNet Training INFO: iter:  3960/144360  CE: 6.5196  
[05/04 09:48:52] SuperNet Training INFO: iter:  4080/144360  CE: 6.3810  
[05/04 09:49:56] SuperNet Training INFO: iter:  4200/144360  CE: 6.4704  
[05/04 09:50:59] SuperNet Training INFO: iter:  4320/144360  CE: 6.4501  
[05/04 09:52:01] SuperNet Training INFO: iter:  4440/144360  CE: 6.5497  
[05/04 09:53:04] SuperNet Training INFO: iter:  4560/144360  CE: 6.5000  
[05/04 09:54:08] SuperNet Training INFO: iter:  4680/144360  CE: 6.2837  
[05/04 09:55:11] SuperNet Training INFO: iter:  4800/144360  CE: 6.6211  
[05/04 09:55:16] SuperNet Training INFO: --> epoch:   4/120  avg CE: 6.4555  lr: 0.11967131372209595  
[05/04 09:56:51] SuperNet Training INFO: iter:  4920/144360  CE: 6.4043  
[05/04 09:57:54] SuperNet Training INFO: iter:  5040/144360  CE: 6.2006  
[05/04 09:58:55] SuperNet Training INFO: iter:  5160/144360  CE: 6.2549  
[05/04 09:59:57] SuperNet Training INFO: iter:  5280/144360  CE: 6.3880  
[05/04 10:00:58] SuperNet Training INFO: iter:  5400/144360  CE: 6.1886  
[05/04 10:02:00] SuperNet Training INFO: iter:  5520/144360  CE: 6.3735  
[05/04 10:03:01] SuperNet Training INFO: iter:  5640/144360  CE: 6.1795  
[05/04 10:04:03] SuperNet Training INFO: iter:  5760/144360  CE: 6.2267  
[05/04 10:05:05] SuperNet Training INFO: iter:  5880/144360  CE: 6.2360  
[05/04 10:06:08] SuperNet Training INFO: iter:  6000/144360  CE: 6.1752  
[05/04 10:06:15] SuperNet Training INFO: --> epoch:   5/120  avg CE: 6.3096  lr: 0.11948669168242801  
[05/04 10:07:48] SuperNet Training INFO: iter:  6120/144360  CE: 6.3024  
[05/04 10:08:50] SuperNet Training INFO: iter:  6240/144360  CE: 6.3436  
[05/04 10:09:51] SuperNet Training INFO: iter:  6360/144360  CE: 6.2693  
[05/04 10:10:53] SuperNet Training INFO: iter:  6480/144360  CE: 6.2093  
[05/04 10:11:55] SuperNet Training INFO: iter:  6600/144360  CE: 6.0982  
[05/04 10:12:58] SuperNet Training INFO: iter:  6720/144360  CE: 6.0711  
[05/04 10:14:01] SuperNet Training INFO: iter:  6840/144360  CE: 6.2156  
[05/04 10:15:05] SuperNet Training INFO: iter:  6960/144360  CE: 6.0833  
[05/04 10:16:08] SuperNet Training INFO: iter:  7080/144360  CE: 6.1481  
[05/04 10:17:10] SuperNet Training INFO: iter:  7200/144360  CE: 6.1407  
[05/04 10:17:18] SuperNet Training INFO: --> epoch:   6/120  avg CE: 6.1640  lr: 0.1192613004357081  
[05/04 10:18:50] SuperNet Training INFO: iter:  7320/144360  CE: 6.1786  
[05/04 10:19:52] SuperNet Training INFO: iter:  7440/144360  CE: 6.0131  
[05/04 10:20:54] SuperNet Training INFO: iter:  7560/144360  CE: 6.0263  
[05/04 10:21:57] SuperNet Training INFO: iter:  7680/144360  CE: 6.0651  
[05/04 10:23:00] SuperNet Training INFO: iter:  7800/144360  CE: 6.0032  
[05/04 10:24:02] SuperNet Training INFO: iter:  7920/144360  CE: 6.0407  
[05/04 10:25:03] SuperNet Training INFO: iter:  8040/144360  CE: 5.9568  
[05/04 10:26:04] SuperNet Training INFO: iter:  8160/144360  CE: 5.9402  
[05/04 10:27:06] SuperNet Training INFO: iter:  8280/144360  CE: 6.0341  
[05/04 10:28:08] SuperNet Training INFO: iter:  8400/144360  CE: 6.0081  
[05/04 10:28:18] SuperNet Training INFO: --> epoch:   7/120  avg CE: 6.0224  lr: 0.11899529445383715  
[05/04 10:29:49] SuperNet Training INFO: iter:  8520/144360  CE: 6.0235  
[05/04 10:30:51] SuperNet Training INFO: iter:  8640/144360  CE: 5.7782  
[05/04 10:31:52] SuperNet Training INFO: iter:  8760/144360  CE: 5.8061  
[05/04 10:32:54] SuperNet Training INFO: iter:  8880/144360  CE: 6.0047  
[05/04 10:33:56] SuperNet Training INFO: iter:  9000/144360  CE: 5.7236  
[05/04 10:34:58] SuperNet Training INFO: iter:  9120/144360  CE: 5.7230  
[05/04 10:36:00] SuperNet Training INFO: iter:  9240/144360  CE: 5.8534  
[05/04 10:37:01] SuperNet Training INFO: iter:  9360/144360  CE: 5.8245  
[05/04 10:38:04] SuperNet Training INFO: iter:  9480/144360  CE: 6.0105  
[05/04 10:39:07] SuperNet Training INFO: iter:  9600/144360  CE: 5.9094  
[05/04 10:39:18] SuperNet Training INFO: --> epoch:   8/120  avg CE: 5.8845  lr: 0.11868885604402826  
[05/04 10:40:47] SuperNet Training INFO: iter:  9720/144360  CE: 5.8635  
[05/04 10:41:50] SuperNet Training INFO: iter:  9840/144360  CE: 5.8252  
[05/04 10:42:50] SuperNet Training INFO: iter:  9960/144360  CE: 5.7161  
[05/04 10:43:53] SuperNet Training INFO: iter: 10080/144360  CE: 5.8154  
[05/04 10:44:53] SuperNet Training INFO: iter: 10200/144360  CE: 5.9192  
[05/04 10:45:56] SuperNet Training INFO: iter: 10320/144360  CE: 5.6792  
[05/04 10:46:58] SuperNet Training INFO: iter: 10440/144360  CE: 5.7129  
[05/04 10:48:00] SuperNet Training INFO: iter: 10560/144360  CE: 5.6854  
[05/04 10:49:02] SuperNet Training INFO: iter: 10680/144360  CE: 5.7897  
[05/04 10:50:02] SuperNet Training INFO: iter: 10800/144360  CE: 5.5235  
[05/04 10:50:16] SuperNet Training INFO: --> epoch:   9/120  avg CE: 5.7522  lr: 0.11834219522386061  
[05/04 10:51:42] SuperNet Training INFO: iter: 10920/144360  CE: 5.5445  
[05/04 10:52:44] SuperNet Training INFO: iter: 11040/144360  CE: 5.4521  
[05/04 10:53:45] SuperNet Training INFO: iter: 11160/144360  CE: 5.5331  
[05/04 10:54:48] SuperNet Training INFO: iter: 11280/144360  CE: 5.6191  
[05/04 10:55:49] SuperNet Training INFO: iter: 11400/144360  CE: 5.4144  
[05/04 10:56:51] SuperNet Training INFO: iter: 11520/144360  CE: 5.8542  
[05/04 10:57:53] SuperNet Training INFO: iter: 11640/144360  CE: 5.7347  
[05/04 10:58:56] SuperNet Training INFO: iter: 11760/144360  CE: 5.6467  
[05/04 10:59:58] SuperNet Training INFO: iter: 11880/144360  CE: 5.5342  
[05/04 11:01:01] SuperNet Training INFO: iter: 12000/144360  CE: 5.4528  
[05/04 11:01:15] SuperNet Training INFO: --> epoch:  10/120  avg CE: 5.6289  lr: 0.1179555495773443  
[05/04 11:02:41] SuperNet Training INFO: iter: 12120/144360  CE: 5.6984  
[05/04 11:03:43] SuperNet Training INFO: iter: 12240/144360  CE: 5.4492  
[05/04 11:04:44] SuperNet Training INFO: iter: 12360/144360  CE: 5.2701  
[05/04 11:05:46] SuperNet Training INFO: iter: 12480/144360  CE: 5.5452  
[05/04 11:06:49] SuperNet Training INFO: iter: 12600/144360  CE: 5.3148  
[05/04 11:07:50] SuperNet Training INFO: iter: 12720/144360  CE: 5.7826  
[05/04 11:08:53] SuperNet Training INFO: iter: 12840/144360  CE: 5.5962  
[05/04 11:09:54] SuperNet Training INFO: iter: 12960/144360  CE: 5.3935  
[05/04 11:10:56] SuperNet Training INFO: iter: 13080/144360  CE: 5.4326  
[05/04 11:11:58] SuperNet Training INFO: iter: 13200/144360  CE: 5.4820  
[05/04 11:12:13] SuperNet Training INFO: --> epoch:  11/120  avg CE: 5.5039  lr: 0.11752918409209158  
[05/04 11:13:37] SuperNet Training INFO: iter: 13320/144360  CE: 5.3567  
[05/04 11:14:37] SuperNet Training INFO: iter: 13440/144360  CE: 5.2030  
[05/04 11:15:38] SuperNet Training INFO: iter: 13560/144360  CE: 5.3462  
[05/04 11:16:41] SuperNet Training INFO: iter: 13680/144360  CE: 5.5347  
[05/04 11:17:43] SuperNet Training INFO: iter: 13800/144360  CE: 5.2843  
[05/04 11:18:45] SuperNet Training INFO: iter: 13920/144360  CE: 5.4290  
[05/04 11:19:47] SuperNet Training INFO: iter: 14040/144360  CE: 5.4927  
[05/04 11:20:49] SuperNet Training INFO: iter: 14160/144360  CE: 5.3656  
[05/04 11:21:53] SuperNet Training INFO: iter: 14280/144360  CE: 5.2785  
[05/04 11:22:55] SuperNet Training INFO: iter: 14400/144360  CE: 5.4297  
[05/04 11:23:12] SuperNet Training INFO: --> epoch:  12/120  avg CE: 5.3863  lr: 0.11706339097770935  
[05/04 11:24:35] SuperNet Training INFO: iter: 14520/144360  CE: 5.2156  
[05/04 11:25:36] SuperNet Training INFO: iter: 14640/144360  CE: 4.9424  
[05/04 11:26:39] SuperNet Training INFO: iter: 14760/144360  CE: 5.1813  
[05/04 11:27:40] SuperNet Training INFO: iter: 14880/144360  CE: 5.2940  
[05/04 11:28:42] SuperNet Training INFO: iter: 15000/144360  CE: 5.5034  
[05/04 11:29:44] SuperNet Training INFO: iter: 15120/144360  CE: 5.0611  
[05/04 11:30:46] SuperNet Training INFO: iter: 15240/144360  CE: 5.3752  
[05/04 11:31:46] SuperNet Training INFO: iter: 15360/144360  CE: 5.3791  
[05/04 11:32:48] SuperNet Training INFO: iter: 15480/144360  CE: 4.8997  
[05/04 11:33:49] SuperNet Training INFO: iter: 15600/144360  CE: 5.1182  
[05/04 11:34:09] SuperNet Training INFO: --> epoch:  13/120  avg CE: 5.2574  lr: 0.11655848946553125  
[05/04 11:35:29] SuperNet Training INFO: iter: 15720/144360  CE: 5.3966  
[05/04 11:36:32] SuperNet Training INFO: iter: 15840/144360  CE: 5.1021  
[05/04 11:37:34] SuperNet Training INFO: iter: 15960/144360  CE: 5.2099  
[05/04 11:38:35] SuperNet Training INFO: iter: 16080/144360  CE: 5.1320  
[05/04 11:39:36] SuperNet Training INFO: iter: 16200/144360  CE: 5.3645  
[05/04 11:40:36] SuperNet Training INFO: iter: 16320/144360  CE: 5.0773  
[05/04 11:41:36] SuperNet Training INFO: iter: 16440/144360  CE: 5.3046  
[05/04 11:42:36] SuperNet Training INFO: iter: 16560/144360  CE: 5.1436  
[05/04 11:43:37] SuperNet Training INFO: iter: 16680/144360  CE: 5.1221  
[05/04 11:44:37] SuperNet Training INFO: iter: 16800/144360  CE: 5.0515  
[05/04 11:44:56] SuperNet Training INFO: --> epoch:  14/120  avg CE: 5.1478  lr: 0.11601482558983225  
[05/04 11:46:13] SuperNet Training INFO: iter: 16920/144360  CE: 5.2049  
[05/04 11:47:16] SuperNet Training INFO: iter: 17040/144360  CE: 5.1452  
[05/04 11:48:18] SuperNet Training INFO: iter: 17160/144360  CE: 4.8193  
[05/04 11:49:19] SuperNet Training INFO: iter: 17280/144360  CE: 4.8277  
[05/04 11:50:19] SuperNet Training INFO: iter: 17400/144360  CE: 5.1305  
[05/04 11:51:21] SuperNet Training INFO: iter: 17520/144360  CE: 4.8593  
[05/04 11:52:23] SuperNet Training INFO: iter: 17640/144360  CE: 4.9120  
[05/04 11:53:25] SuperNet Training INFO: iter: 17760/144360  CE: 4.8354  
[05/04 11:54:28] SuperNet Training INFO: iter: 17880/144360  CE: 5.0418  
[05/04 11:55:30] SuperNet Training INFO: iter: 18000/144360  CE: 4.8258  
[05/04 11:55:53] SuperNet Training INFO: --> epoch:  15/120  avg CE: 5.0424  lr: 0.11543277195067722  
[05/04 11:57:10] SuperNet Training INFO: iter: 18120/144360  CE: 4.6801  
[05/04 11:58:12] SuperNet Training INFO: iter: 18240/144360  CE: 4.8112  
[05/04 11:59:14] SuperNet Training INFO: iter: 18360/144360  CE: 4.8901  
[05/04 12:00:15] SuperNet Training INFO: iter: 18480/144360  CE: 5.0765  
[05/04 12:01:16] SuperNet Training INFO: iter: 18600/144360  CE: 5.1648  
[05/04 12:02:17] SuperNet Training INFO: iter: 18720/144360  CE: 4.7346  
[05/04 12:03:18] SuperNet Training INFO: iter: 18840/144360  CE: 4.8741  
[05/04 12:04:19] SuperNet Training INFO: iter: 18960/144360  CE: 4.8138  
[05/04 12:05:19] SuperNet Training INFO: iter: 19080/144360  CE: 4.9215  
[05/04 12:06:20] SuperNet Training INFO: iter: 19200/144360  CE: 4.8688  
[05/04 12:06:43] SuperNet Training INFO: --> epoch:  16/120  avg CE: 4.9442  lr: 0.1148127274585561  
[05/04 12:07:58] SuperNet Training INFO: iter: 19320/144360  CE: 4.8136  
[05/04 12:09:01] SuperNet Training INFO: iter: 19440/144360  CE: 4.9292  
[05/04 12:10:02] SuperNet Training INFO: iter: 19560/144360  CE: 5.0885  
[05/04 12:11:04] SuperNet Training INFO: iter: 19680/144360  CE: 4.8436  
[05/04 12:12:06] SuperNet Training INFO: iter: 19800/144360  CE: 4.6280  
[05/04 12:13:08] SuperNet Training INFO: iter: 19920/144360  CE: 4.8192  
[05/04 12:14:10] SuperNet Training INFO: iter: 20040/144360  CE: 4.9366  
[05/04 12:15:12] SuperNet Training INFO: iter: 20160/144360  CE: 4.8119  
[05/04 12:16:13] SuperNet Training INFO: iter: 20280/144360  CE: 5.0997  
[05/04 12:17:15] SuperNet Training INFO: iter: 20400/144360  CE: 4.8983  
[05/04 12:17:40] SuperNet Training INFO: --> epoch:  17/120  avg CE: 4.8488  lr: 0.11415511706099139  
[05/04 12:18:53] SuperNet Training INFO: iter: 20520/144360  CE: 4.9310  
[05/04 12:19:55] SuperNet Training INFO: iter: 20640/144360  CE: 4.6394  
[05/04 12:20:57] SuperNet Training INFO: iter: 20760/144360  CE: 4.5673  
[05/04 12:21:58] SuperNet Training INFO: iter: 20880/144360  CE: 4.9718  
[05/04 12:22:59] SuperNet Training INFO: iter: 21000/144360  CE: 4.8604  
[05/04 12:24:01] SuperNet Training INFO: iter: 21120/144360  CE: 4.8900  
[05/04 12:25:02] SuperNet Training INFO: iter: 21240/144360  CE: 5.0707  
[05/04 12:26:04] SuperNet Training INFO: iter: 21360/144360  CE: 4.5993  
[05/04 12:27:05] SuperNet Training INFO: iter: 21480/144360  CE: 4.6230  
[05/04 12:28:08] SuperNet Training INFO: iter: 21600/144360  CE: 4.9114  
[05/04 12:28:34] SuperNet Training INFO: --> epoch:  18/120  avg CE: 4.7601  lr: 0.11346039145130195  
[05/04 12:29:47] SuperNet Training INFO: iter: 21720/144360  CE: 4.5377  
[05/04 12:30:50] SuperNet Training INFO: iter: 21840/144360  CE: 4.5651  
[05/04 12:31:51] SuperNet Training INFO: iter: 21960/144360  CE: 4.8339  
[05/04 12:32:52] SuperNet Training INFO: iter: 22080/144360  CE: 4.4776  
[05/04 12:33:56] SuperNet Training INFO: iter: 22200/144360  CE: 4.7094  
[05/04 12:34:58] SuperNet Training INFO: iter: 22320/144360  CE: 4.4558  
[05/04 12:35:59] SuperNet Training INFO: iter: 22440/144360  CE: 4.7486  
[05/04 12:36:59] SuperNet Training INFO: iter: 22560/144360  CE: 4.6121  
[05/04 12:38:00] SuperNet Training INFO: iter: 22680/144360  CE: 4.5727  
[05/04 12:39:02] SuperNet Training INFO: iter: 22800/144360  CE: 4.7642  
[05/04 12:39:30] SuperNet Training INFO: --> epoch:  19/120  avg CE: 4.6761  lr: 0.11272902675971772  
[05/04 12:40:40] SuperNet Training INFO: iter: 22920/144360  CE: 4.5840  
[05/04 12:41:43] SuperNet Training INFO: iter: 23040/144360  CE: 4.5572  
[05/04 12:42:45] SuperNet Training INFO: iter: 23160/144360  CE: 4.6767  
[05/04 12:43:47] SuperNet Training INFO: iter: 23280/144360  CE: 4.6817  
[05/04 12:44:50] SuperNet Training INFO: iter: 23400/144360  CE: 4.6546  
[05/04 12:45:50] SuperNet Training INFO: iter: 23520/144360  CE: 4.7899  
[05/04 12:46:52] SuperNet Training INFO: iter: 23640/144360  CE: 4.7932  
[05/04 12:47:53] SuperNet Training INFO: iter: 23760/144360  CE: 4.4271  
[05/04 12:48:55] SuperNet Training INFO: iter: 23880/144360  CE: 4.7124  
[05/04 12:49:57] SuperNet Training INFO: iter: 24000/144360  CE: 4.7395  
[05/04 12:50:27] SuperNet Training INFO: --> epoch:  20/120  avg CE: 4.5910  lr: 0.11196152422706572  
[05/04 12:51:36] SuperNet Training INFO: iter: 24120/144360  CE: 4.5199  
[05/04 12:52:37] SuperNet Training INFO: iter: 24240/144360  CE: 4.7289  
[05/04 12:53:39] SuperNet Training INFO: iter: 24360/144360  CE: 4.5415  
[05/04 12:54:41] SuperNet Training INFO: iter: 24480/144360  CE: 4.0926  
[05/04 12:55:43] SuperNet Training INFO: iter: 24600/144360  CE: 4.6101  
[05/04 12:56:44] SuperNet Training INFO: iter: 24720/144360  CE: 4.3573  
[05/04 12:57:47] SuperNet Training INFO: iter: 24840/144360  CE: 4.7427  
[05/04 12:58:48] SuperNet Training INFO: iter: 24960/144360  CE: 4.4254  
[05/04 12:59:49] SuperNet Training INFO: iter: 25080/144360  CE: 4.3203  
[05/04 13:00:52] SuperNet Training INFO: iter: 25200/144360  CE: 4.5397  
[05/04 13:01:22] SuperNet Training INFO: --> epoch:  21/120  avg CE: 4.5339  lr: 0.11115840986124514  
[05/04 13:02:29] SuperNet Training INFO: iter: 25320/144360  CE: 4.5091  
[05/04 13:03:32] SuperNet Training INFO: iter: 25440/144360  CE: 4.4761  
[05/04 13:04:35] SuperNet Training INFO: iter: 25560/144360  CE: 4.7383  
[05/04 13:05:37] SuperNet Training INFO: iter: 25680/144360  CE: 4.4314  
[05/04 13:06:38] SuperNet Training INFO: iter: 25800/144360  CE: 4.5875  
[05/04 13:07:37] SuperNet Training INFO: iter: 25920/144360  CE: 4.5672  
[05/04 13:08:38] SuperNet Training INFO: iter: 26040/144360  CE: 4.3716  
[05/04 13:09:39] SuperNet Training INFO: iter: 26160/144360  CE: 4.4194  
[05/04 13:10:38] SuperNet Training INFO: iter: 26280/144360  CE: 4.5346  
[05/04 13:11:38] SuperNet Training INFO: iter: 26400/144360  CE: 4.3032  
[05/04 13:12:11] SuperNet Training INFO: --> epoch:  22/120  avg CE: 4.4731  lr: 0.11032023407672516  
[05/04 13:13:16] SuperNet Training INFO: iter: 26520/144360  CE: 4.3784  
[05/04 13:14:16] SuperNet Training INFO: iter: 26640/144360  CE: 4.2441  
[05/04 13:15:17] SuperNet Training INFO: iter: 26760/144360  CE: 4.4218  
[05/04 13:16:19] SuperNet Training INFO: iter: 26880/144360  CE: 4.4745  
[05/04 13:17:21] SuperNet Training INFO: iter: 27000/144360  CE: 4.1598  
[05/04 13:18:24] SuperNet Training INFO: iter: 27120/144360  CE: 4.4098  
[05/04 13:19:26] SuperNet Training INFO: iter: 27240/144360  CE: 4.3783  
[05/04 13:20:28] SuperNet Training INFO: iter: 27360/144360  CE: 4.3122  
[05/04 13:21:29] SuperNet Training INFO: iter: 27480/144360  CE: 4.3778  
[05/04 13:22:30] SuperNet Training INFO: iter: 27600/144360  CE: 4.4697  
[05/04 13:23:05] SuperNet Training INFO: --> epoch:  23/120  avg CE: 4.4043  lr: 0.10944757131732062  
[05/04 13:24:10] SuperNet Training INFO: iter: 27720/144360  CE: 4.6383  
[05/04 13:25:11] SuperNet Training INFO: iter: 27840/144360  CE: 4.3286  
[05/04 13:26:12] SuperNet Training INFO: iter: 27960/144360  CE: 4.4850  
[05/04 13:27:14] SuperNet Training INFO: iter: 28080/144360  CE: 4.3508  
[05/04 13:28:16] SuperNet Training INFO: iter: 28200/144360  CE: 4.1193  
[05/04 13:29:17] SuperNet Training INFO: iter: 28320/144360  CE: 4.2422  
[05/04 13:30:19] SuperNet Training INFO: iter: 28440/144360  CE: 4.2875  
[05/04 13:31:21] SuperNet Training INFO: iter: 28560/144360  CE: 4.2777  
[05/04 13:32:22] SuperNet Training INFO: iter: 28680/144360  CE: 4.4132  
[05/04 13:33:23] SuperNet Training INFO: iter: 28800/144360  CE: 4.3381  
[05/04 13:34:00] SuperNet Training INFO: --> epoch:  24/120  avg CE: 4.3609  lr: 0.10854101966249682  
[05/04 13:35:03] SuperNet Training INFO: iter: 28920/144360  CE: 4.4383  
[05/04 13:36:04] SuperNet Training INFO: iter: 29040/144360  CE: 4.3149  
[05/04 13:37:06] SuperNet Training INFO: iter: 29160/144360  CE: 4.6597  
[05/04 13:38:07] SuperNet Training INFO: iter: 29280/144360  CE: 4.2560  
[05/04 13:39:08] SuperNet Training INFO: iter: 29400/144360  CE: 4.3579  
[05/04 13:40:09] SuperNet Training INFO: iter: 29520/144360  CE: 4.3884  
[05/04 13:41:10] SuperNet Training INFO: iter: 29640/144360  CE: 3.9774  
[05/04 13:42:11] SuperNet Training INFO: iter: 29760/144360  CE: 4.5654  
[05/04 13:43:14] SuperNet Training INFO: iter: 29880/144360  CE: 4.1670  
[05/04 13:44:15] SuperNet Training INFO: iter: 30000/144360  CE: 4.2242  
[05/04 13:44:53] SuperNet Training INFO: --> epoch:  25/120  avg CE: 4.3144  lr: 0.10760120041747454  
[05/04 13:45:54] SuperNet Training INFO: iter: 30120/144360  CE: 4.1935  
[05/04 13:46:56] SuperNet Training INFO: iter: 30240/144360  CE: 4.0545  
[05/04 13:47:57] SuperNet Training INFO: iter: 30360/144360  CE: 4.1992  
[05/04 13:48:59] SuperNet Training INFO: iter: 30480/144360  CE: 4.4444  
[05/04 13:50:01] SuperNet Training INFO: iter: 30600/144360  CE: 4.2503  
[05/04 13:51:04] SuperNet Training INFO: iter: 30720/144360  CE: 4.2592  
[05/04 13:52:05] SuperNet Training INFO: iter: 30840/144360  CE: 4.2842  
[05/04 13:53:08] SuperNet Training INFO: iter: 30960/144360  CE: 4.2848  
[05/04 13:54:09] SuperNet Training INFO: iter: 31080/144360  CE: 4.1472  
[05/04 13:55:09] SuperNet Training INFO: iter: 31200/144360  CE: 4.2157  
[05/04 13:55:48] SuperNet Training INFO: --> epoch:  26/120  avg CE: 4.2691  lr: 0.10662875768741867  
[05/04 13:56:47] SuperNet Training INFO: iter: 31320/144360  CE: 4.0934  
[05/04 13:57:49] SuperNet Training INFO: iter: 31440/144360  CE: 4.3955  
[05/04 13:58:51] SuperNet Training INFO: iter: 31560/144360  CE: 4.2511  
[05/04 13:59:54] SuperNet Training INFO: iter: 31680/144360  CE: 4.0331  
[05/04 14:00:54] SuperNet Training INFO: iter: 31800/144360  CE: 4.1322  
[05/04 14:01:56] SuperNet Training INFO: iter: 31920/144360  CE: 4.3187  
[05/04 14:02:58] SuperNet Training INFO: iter: 32040/144360  CE: 4.2457  
[05/04 14:03:59] SuperNet Training INFO: iter: 32160/144360  CE: 3.9747  
[05/04 14:05:02] SuperNet Training INFO: iter: 32280/144360  CE: 4.2594  
[05/04 14:06:05] SuperNet Training INFO: iter: 32400/144360  CE: 4.2191  
[05/04 14:06:46] SuperNet Training INFO: --> epoch:  27/120  avg CE: 4.2297  lr: 0.10562435793600224  
[05/04 14:07:44] SuperNet Training INFO: iter: 32520/144360  CE: 4.2743  
[05/04 14:08:46] SuperNet Training INFO: iter: 32640/144360  CE: 4.3417  
[05/04 14:09:49] SuperNet Training INFO: iter: 32760/144360  CE: 4.2849  
[05/04 14:10:50] SuperNet Training INFO: iter: 32880/144360  CE: 4.1015  
[05/04 14:11:52] SuperNet Training INFO: iter: 33000/144360  CE: 4.1547  
[05/04 14:12:54] SuperNet Training INFO: iter: 33120/144360  CE: 4.3176  
[05/04 14:13:56] SuperNet Training INFO: iter: 33240/144360  CE: 4.3430  
[05/04 14:14:59] SuperNet Training INFO: iter: 33360/144360  CE: 4.2567  
[05/04 14:16:01] SuperNet Training INFO: iter: 33480/144360  CE: 4.0544  
[05/04 14:17:02] SuperNet Training INFO: iter: 33600/144360  CE: 3.8999  
[05/04 14:17:44] SuperNet Training INFO: --> epoch:  28/120  avg CE: 4.1915  lr: 0.10458868952864393  
[05/04 14:18:41] SuperNet Training INFO: iter: 33720/144360  CE: 4.0354  
[05/04 14:19:43] SuperNet Training INFO: iter: 33840/144360  CE: 4.0802  
[05/04 14:20:44] SuperNet Training INFO: iter: 33960/144360  CE: 3.9414  
[05/04 14:21:45] SuperNet Training INFO: iter: 34080/144360  CE: 4.1621  
[05/04 14:22:47] SuperNet Training INFO: iter: 34200/144360  CE: 4.2661  
[05/04 14:23:48] SuperNet Training INFO: iter: 34320/144360  CE: 4.1110  
[05/04 14:24:48] SuperNet Training INFO: iter: 34440/144360  CE: 4.0083  
[05/04 14:25:50] SuperNet Training INFO: iter: 34560/144360  CE: 4.3614  
[05/04 14:26:50] SuperNet Training INFO: iter: 34680/144360  CE: 4.2927  
[05/04 14:27:53] SuperNet Training INFO: iter: 34800/144360  CE: 4.0598  
[05/04 14:28:36] SuperNet Training INFO: --> epoch:  29/120  avg CE: 4.1580  lr: 0.10352246226073762  
[05/04 14:29:31] SuperNet Training INFO: iter: 34920/144360  CE: 4.0655  
[05/04 14:30:34] SuperNet Training INFO: iter: 35040/144360  CE: 3.9977  
[05/04 14:31:36] SuperNet Training INFO: iter: 35160/144360  CE: 4.2231  
[05/04 14:32:39] SuperNet Training INFO: iter: 35280/144360  CE: 4.0300  
[05/04 14:33:39] SuperNet Training INFO: iter: 35400/144360  CE: 4.0719  
[05/04 14:34:42] SuperNet Training INFO: iter: 35520/144360  CE: 3.9822  
[05/04 14:35:43] SuperNet Training INFO: iter: 35640/144360  CE: 4.0587  
[05/04 14:36:45] SuperNet Training INFO: iter: 35760/144360  CE: 3.8116  
[05/04 14:37:45] SuperNet Training INFO: iter: 35880/144360  CE: 4.2195  
[05/04 14:38:46] SuperNet Training INFO: iter: 36000/144360  CE: 4.1051  
[05/04 14:39:31] SuperNet Training INFO: --> epoch:  30/120  avg CE: 4.1222  lr: 0.10242640687119343  
[05/04 14:40:24] SuperNet Training INFO: iter: 36120/144360  CE: 4.1102  
[05/04 14:41:25] SuperNet Training INFO: iter: 36240/144360  CE: 4.3192  
[05/04 14:42:26] SuperNet Training INFO: iter: 36360/144360  CE: 4.1118  
[05/04 14:43:28] SuperNet Training INFO: iter: 36480/144360  CE: 4.1846  
[05/04 14:44:32] SuperNet Training INFO: iter: 36600/144360  CE: 4.1053  
[05/04 14:45:33] SuperNet Training INFO: iter: 36720/144360  CE: 3.8933  
[05/04 14:46:34] SuperNet Training INFO: iter: 36840/144360  CE: 3.8624  
[05/04 14:47:33] SuperNet Training INFO: iter: 36960/144360  CE: 4.1400  
[05/04 14:48:34] SuperNet Training INFO: iter: 37080/144360  CE: 3.9895  
[05/04 14:49:35] SuperNet Training INFO: iter: 37200/144360  CE: 3.7705  
[05/04 14:50:20] SuperNet Training INFO: --> epoch:  31/120  avg CE: 4.0867  lr: 0.10130127454162571  
[05/04 14:51:12] SuperNet Training INFO: iter: 37320/144360  CE: 4.2454  
[05/04 14:52:13] SuperNet Training INFO: iter: 37440/144360  CE: 3.9961  
[05/04 14:53:14] SuperNet Training INFO: iter: 37560/144360  CE: 3.9420  
[05/04 14:54:17] SuperNet Training INFO: iter: 37680/144360  CE: 4.3325  
[05/04 14:55:21] SuperNet Training INFO: iter: 37800/144360  CE: 4.1461  
[05/04 14:56:23] SuperNet Training INFO: iter: 37920/144360  CE: 4.0857  
[05/04 14:57:23] SuperNet Training INFO: iter: 38040/144360  CE: 4.3459  
[05/04 14:58:25] SuperNet Training INFO: iter: 38160/144360  CE: 3.9689  
[05/04 14:59:26] SuperNet Training INFO: iter: 38280/144360  CE: 3.9365  
[05/04 15:00:28] SuperNet Training INFO: iter: 38400/144360  CE: 3.7707  
[05/04 15:01:16] SuperNet Training INFO: --> epoch:  32/120  avg CE: 4.0683  lr: 0.10014783638153192  
[05/04 15:02:06] SuperNet Training INFO: iter: 38520/144360  CE: 3.8441  
[05/04 15:03:09] SuperNet Training INFO: iter: 38640/144360  CE: 4.0775  
[05/04 15:04:09] SuperNet Training INFO: iter: 38760/144360  CE: 3.9617  
[05/04 15:05:09] SuperNet Training INFO: iter: 38880/144360  CE: 4.1277  
[05/04 15:06:11] SuperNet Training INFO: iter: 39000/144360  CE: 4.1834  
[05/04 15:07:13] SuperNet Training INFO: iter: 39120/144360  CE: 3.8739  
[05/04 15:08:13] SuperNet Training INFO: iter: 39240/144360  CE: 4.0225  
[05/04 15:09:13] SuperNet Training INFO: iter: 39360/144360  CE: 4.1494  
[05/04 15:10:15] SuperNet Training INFO: iter: 39480/144360  CE: 3.9639  
[05/04 15:11:16] SuperNet Training INFO: iter: 39600/144360  CE: 4.1198  
[05/04 15:12:06] SuperNet Training INFO: --> epoch:  33/120  avg CE: 4.0359  lr: 0.09896688289981138  
[05/04 15:12:55] SuperNet Training INFO: iter: 39720/144360  CE: 4.0249  
[05/04 15:13:57] SuperNet Training INFO: iter: 39840/144360  CE: 3.8186  
[05/04 15:14:59] SuperNet Training INFO: iter: 39960/144360  CE: 4.0346  
[05/04 15:16:00] SuperNet Training INFO: iter: 40080/144360  CE: 3.7777  
[05/04 15:17:02] SuperNet Training INFO: iter: 40200/144360  CE: 4.5969  
[05/04 15:18:05] SuperNet Training INFO: iter: 40320/144360  CE: 3.8739  
[05/04 15:19:08] SuperNet Training INFO: iter: 40440/144360  CE: 3.9789  
[05/04 15:20:10] SuperNet Training INFO: iter: 40560/144360  CE: 4.2225  
[05/04 15:21:11] SuperNet Training INFO: iter: 40680/144360  CE: 3.8523  
[05/04 15:22:13] SuperNet Training INFO: iter: 40800/144360  CE: 4.2344  
[05/04 15:23:05] SuperNet Training INFO: --> epoch:  34/120  avg CE: 3.9971  lr: 0.09775922346299062  
[05/04 15:23:52] SuperNet Training INFO: iter: 40920/144360  CE: 4.2628  
[05/04 15:24:54] SuperNet Training INFO: iter: 41040/144360  CE: 3.8591  
[05/04 15:25:55] SuperNet Training INFO: iter: 41160/144360  CE: 3.9273  
[05/04 15:26:56] SuperNet Training INFO: iter: 41280/144360  CE: 3.8779  
[05/04 15:27:56] SuperNet Training INFO: iter: 41400/144360  CE: 4.3504  
[05/04 15:28:57] SuperNet Training INFO: iter: 41520/144360  CE: 3.7503  
[05/04 15:29:57] SuperNet Training INFO: iter: 41640/144360  CE: 3.8545  
[05/04 15:30:57] SuperNet Training INFO: iter: 41760/144360  CE: 3.8615  
[05/04 15:31:58] SuperNet Training INFO: iter: 41880/144360  CE: 4.2982  
[05/04 15:32:58] SuperNet Training INFO: iter: 42000/144360  CE: 4.1326  
[05/04 15:33:49] SuperNet Training INFO: --> epoch:  35/120  avg CE: 3.9642  lr: 0.09652568574052359  
[05/04 15:34:34] SuperNet Training INFO: iter: 42120/144360  CE: 4.0157  
[05/04 15:35:36] SuperNet Training INFO: iter: 42240/144360  CE: 3.9859  
[05/04 15:36:38] SuperNet Training INFO: iter: 42360/144360  CE: 4.3928  
[05/04 15:37:39] SuperNet Training INFO: iter: 42480/144360  CE: 4.0345  
[05/04 15:38:40] SuperNet Training INFO: iter: 42600/144360  CE: 3.7956  
[05/04 15:39:42] SuperNet Training INFO: iter: 42720/144360  CE: 4.0005  
[05/04 15:40:43] SuperNet Training INFO: iter: 42840/144360  CE: 3.9188  
[05/04 15:41:44] SuperNet Training INFO: iter: 42960/144360  CE: 3.9015  
[05/04 15:42:44] SuperNet Training INFO: iter: 43080/144360  CE: 3.9955  
[05/04 15:43:47] SuperNet Training INFO: iter: 43200/144360  CE: 3.9464  
[05/04 15:44:40] SuperNet Training INFO: --> epoch:  36/120  avg CE: 3.9436  lr: 0.09526711513754865  
[05/04 15:45:25] SuperNet Training INFO: iter: 43320/144360  CE: 3.7887  
[05/04 15:46:28] SuperNet Training INFO: iter: 43440/144360  CE: 3.9345  
[05/04 15:47:29] SuperNet Training INFO: iter: 43560/144360  CE: 3.9912  
[05/04 15:48:30] SuperNet Training INFO: iter: 43680/144360  CE: 3.8857  
[05/04 15:49:32] SuperNet Training INFO: iter: 43800/144360  CE: 3.6488  
[05/04 15:50:34] SuperNet Training INFO: iter: 43920/144360  CE: 4.0998  
[05/04 15:51:35] SuperNet Training INFO: iter: 44040/144360  CE: 4.1718  
[05/04 15:52:36] SuperNet Training INFO: iter: 44160/144360  CE: 3.8725  
[05/04 15:53:38] SuperNet Training INFO: iter: 44280/144360  CE: 3.7541  
[05/04 15:54:39] SuperNet Training INFO: iter: 44400/144360  CE: 4.0722  
[05/04 15:55:34] SuperNet Training INFO: --> epoch:  37/120  avg CE: 3.9051  lr: 0.0939843742154901  
[05/04 15:56:17] SuperNet Training INFO: iter: 44520/144360  CE: 3.9686  
[05/04 15:57:18] SuperNet Training INFO: iter: 44640/144360  CE: 3.6572  
[05/04 15:58:19] SuperNet Training INFO: iter: 44760/144360  CE: 4.0450  
[05/04 15:59:20] SuperNet Training INFO: iter: 44880/144360  CE: 3.9059  
[05/04 16:00:21] SuperNet Training INFO: iter: 45000/144360  CE: 4.0566  
[05/04 16:01:24] SuperNet Training INFO: iter: 45120/144360  CE: 4.0536  
[05/04 16:02:26] SuperNet Training INFO: iter: 45240/144360  CE: 3.8112  
[05/04 16:03:29] SuperNet Training INFO: iter: 45360/144360  CE: 4.1273  
[05/04 16:04:30] SuperNet Training INFO: iter: 45480/144360  CE: 3.8917  
[05/04 16:05:32] SuperNet Training INFO: iter: 45600/144360  CE: 4.0627  
[05/04 16:06:30] SuperNet Training INFO: --> epoch:  38/120  avg CE: 3.8887  lr: 0.0926783421009017  
[05/04 16:07:11] SuperNet Training INFO: iter: 45720/144360  CE: 3.7079  
[05/04 16:08:14] SuperNet Training INFO: iter: 45840/144360  CE: 3.6502  
[05/04 16:09:17] SuperNet Training INFO: iter: 45960/144360  CE: 3.8393  
[05/04 16:10:19] SuperNet Training INFO: iter: 46080/144360  CE: 3.6286  
[05/04 16:11:21] SuperNet Training INFO: iter: 46200/144360  CE: 4.2314  
[05/04 16:12:22] SuperNet Training INFO: iter: 46320/144360  CE: 3.6079  
[05/04 16:13:24] SuperNet Training INFO: iter: 46440/144360  CE: 3.5689  
[05/04 16:14:27] SuperNet Training INFO: iter: 46560/144360  CE: 4.0280  
[05/04 16:15:28] SuperNet Training INFO: iter: 46680/144360  CE: 4.1464  
[05/04 16:16:29] SuperNet Training INFO: iter: 46800/144360  CE: 3.7868  
[05/04 16:17:28] SuperNet Training INFO: --> epoch:  39/120  avg CE: 3.8658  lr: 0.09134991388295689  
[05/04 16:18:06] SuperNet Training INFO: iter: 46920/144360  CE: 3.7920  
[05/04 16:19:08] SuperNet Training INFO: iter: 47040/144360  CE: 3.9175  
[05/04 16:20:09] SuperNet Training INFO: iter: 47160/144360  CE: 4.0315  
[05/04 16:21:11] SuperNet Training INFO: iter: 47280/144360  CE: 3.8882  
[05/04 16:22:11] SuperNet Training INFO: iter: 47400/144360  CE: 3.9192  
[05/04 16:23:12] SuperNet Training INFO: iter: 47520/144360  CE: 3.8936  
[05/04 16:24:14] SuperNet Training INFO: iter: 47640/144360  CE: 3.9812  
[05/04 16:25:16] SuperNet Training INFO: iter: 47760/144360  CE: 3.5305  
[05/04 16:26:17] SuperNet Training INFO: iter: 47880/144360  CE: 3.8953  
[05/04 16:27:19] SuperNet Training INFO: iter: 48000/144360  CE: 3.8252  
[05/04 16:28:20] SuperNet Training INFO: iter: 48120/144360  CE: 4.0608  
[05/04 16:28:20] SuperNet Training INFO: --> epoch:  40/120  avg CE: 3.8444  lr: 0.0899999999999998  
[05/04 16:29:59] SuperNet Training INFO: iter: 48240/144360  CE: 3.8384  
[05/04 16:31:02] SuperNet Training INFO: iter: 48360/144360  CE: 3.8723  
[05/04 16:32:03] SuperNet Training INFO: iter: 48480/144360  CE: 3.9892  
[05/04 16:33:05] SuperNet Training INFO: iter: 48600/144360  CE: 3.6233  
[05/04 16:34:07] SuperNet Training INFO: iter: 48720/144360  CE: 4.1237  
[05/04 16:35:08] SuperNet Training INFO: iter: 48840/144360  CE: 3.9475  
[05/04 16:36:09] SuperNet Training INFO: iter: 48960/144360  CE: 3.5929  
[05/04 16:37:10] SuperNet Training INFO: iter: 49080/144360  CE: 3.8239  
[05/04 16:38:10] SuperNet Training INFO: iter: 49200/144360  CE: 3.7622  
[05/04 16:39:10] SuperNet Training INFO: iter: 49320/144360  CE: 3.5918  
[05/04 16:39:11] SuperNet Training INFO: --> epoch:  41/120  avg CE: 3.8109  lr: 0.08862952561557644  
[05/04 16:40:49] SuperNet Training INFO: iter: 49440/144360  CE: 3.6264  
[05/04 16:41:49] SuperNet Training INFO: iter: 49560/144360  CE: 3.5873  
[05/04 16:42:50] SuperNet Training INFO: iter: 49680/144360  CE: 3.8498  
[05/04 16:43:53] SuperNet Training INFO: iter: 49800/144360  CE: 3.6836  
[05/04 16:44:54] SuperNet Training INFO: iter: 49920/144360  CE: 3.8827  
[05/04 16:45:56] SuperNet Training INFO: iter: 50040/144360  CE: 3.9685  
[05/04 16:46:59] SuperNet Training INFO: iter: 50160/144360  CE: 3.5813  
[05/04 16:48:02] SuperNet Training INFO: iter: 50280/144360  CE: 3.6692  
[05/04 16:49:03] SuperNet Training INFO: iter: 50400/144360  CE: 4.0674  
[05/04 16:50:05] SuperNet Training INFO: iter: 50520/144360  CE: 3.4256  
[05/04 16:50:07] SuperNet Training INFO: --> epoch:  42/120  avg CE: 3.7855  lr: 0.08723942998437267  
[05/04 16:51:43] SuperNet Training INFO: iter: 50640/144360  CE: 3.6786  
[05/04 16:52:45] SuperNet Training INFO: iter: 50760/144360  CE: 3.7970  
[05/04 16:53:47] SuperNet Training INFO: iter: 50880/144360  CE: 3.8820  
[05/04 16:54:48] SuperNet Training INFO: iter: 51000/144360  CE: 3.5399  
[05/04 16:55:49] SuperNet Training INFO: iter: 51120/144360  CE: 3.8771  
[05/04 16:56:49] SuperNet Training INFO: iter: 51240/144360  CE: 3.7394  
[05/04 16:57:51] SuperNet Training INFO: iter: 51360/144360  CE: 3.6732  
[05/04 16:58:53] SuperNet Training INFO: iter: 51480/144360  CE: 3.9467  
[05/04 16:59:53] SuperNet Training INFO: iter: 51600/144360  CE: 3.3022  
[05/04 17:00:56] SuperNet Training INFO: iter: 51720/144360  CE: 3.4699  
[05/04 17:00:59] SuperNet Training INFO: --> epoch:  43/120  avg CE: 3.7723  lr: 0.08583066580849745  
[05/04 17:02:33] SuperNet Training INFO: iter: 51840/144360  CE: 4.0312  
[05/04 17:03:35] SuperNet Training INFO: iter: 51960/144360  CE: 3.5481  
[05/04 17:04:37] SuperNet Training INFO: iter: 52080/144360  CE: 3.4653  
[05/04 17:05:40] SuperNet Training INFO: iter: 52200/144360  CE: 3.6785  
[05/04 17:06:41] SuperNet Training INFO: iter: 52320/144360  CE: 3.8952  
[05/04 17:07:42] SuperNet Training INFO: iter: 52440/144360  CE: 3.7035  
[05/04 17:08:44] SuperNet Training INFO: iter: 52560/144360  CE: 3.8606  
[05/04 17:09:46] SuperNet Training INFO: iter: 52680/144360  CE: 3.4491  
[05/04 17:10:48] SuperNet Training INFO: iter: 52800/144360  CE: 3.8413  
[05/04 17:11:49] SuperNet Training INFO: iter: 52920/144360  CE: 3.8457  
[05/04 17:11:55] SuperNet Training INFO: --> epoch:  44/120  avg CE: 3.7553  lr: 0.08440419858454766  
[05/04 17:13:28] SuperNet Training INFO: iter: 53040/144360  CE: 3.6903  
[05/04 17:14:30] SuperNet Training INFO: iter: 53160/144360  CE: 3.8553  
[05/04 17:15:32] SuperNet Training INFO: iter: 53280/144360  CE: 3.9471  
[05/04 17:16:33] SuperNet Training INFO: iter: 53400/144360  CE: 3.7264  
[05/04 17:17:34] SuperNet Training INFO: iter: 53520/144360  CE: 3.2642  
[05/04 17:18:37] SuperNet Training INFO: iter: 53640/144360  CE: 3.6732  
[05/04 17:19:38] SuperNet Training INFO: iter: 53760/144360  CE: 3.7924  
[05/04 17:20:40] SuperNet Training INFO: iter: 53880/144360  CE: 3.7204  
[05/04 17:21:41] SuperNet Training INFO: iter: 54000/144360  CE: 3.5504  
[05/04 17:22:41] SuperNet Training INFO: iter: 54120/144360  CE: 3.7903  
[05/04 17:22:48] SuperNet Training INFO: --> epoch:  45/120  avg CE: 3.7315  lr: 0.0829610059419049  
[05/04 17:24:18] SuperNet Training INFO: iter: 54240/144360  CE: 3.6348  
[05/04 17:25:18] SuperNet Training INFO: iter: 54360/144360  CE: 3.5632  
[05/04 17:26:19] SuperNet Training INFO: iter: 54480/144360  CE: 3.4601  
[05/04 17:27:20] SuperNet Training INFO: iter: 54600/144360  CE: 3.7376  
[05/04 17:28:21] SuperNet Training INFO: iter: 54720/144360  CE: 3.5272  
[05/04 17:29:23] SuperNet Training INFO: iter: 54840/144360  CE: 3.7173  
[05/04 17:30:26] SuperNet Training INFO: iter: 54960/144360  CE: 3.6980  
[05/04 17:31:28] SuperNet Training INFO: iter: 55080/144360  CE: 3.8662  
[05/04 17:32:29] SuperNet Training INFO: iter: 55200/144360  CE: 3.5997  
[05/04 17:33:30] SuperNet Training INFO: iter: 55320/144360  CE: 3.4393  
[05/04 17:33:38] SuperNet Training INFO: --> epoch:  46/120  avg CE: 3.7176  lr: 0.08150207697271764  
[05/04 17:35:08] SuperNet Training INFO: iter: 55440/144360  CE: 3.7443  
[05/04 17:36:10] SuperNet Training INFO: iter: 55560/144360  CE: 3.6572  
[05/04 17:37:12] SuperNet Training INFO: iter: 55680/144360  CE: 3.8692  
[05/04 17:38:13] SuperNet Training INFO: iter: 55800/144360  CE: 3.6573  
[05/04 17:39:16] SuperNet Training INFO: iter: 55920/144360  CE: 3.7258  
[05/04 17:40:17] SuperNet Training INFO: iter: 56040/144360  CE: 3.7409  
[05/04 17:41:18] SuperNet Training INFO: iter: 56160/144360  CE: 3.4126  
[05/04 17:42:19] SuperNet Training INFO: iter: 56280/144360  CE: 3.1394  
[05/04 17:43:21] SuperNet Training INFO: iter: 56400/144360  CE: 3.2086  
[05/04 17:44:22] SuperNet Training INFO: iter: 56520/144360  CE: 3.7465  
[05/04 17:44:32] SuperNet Training INFO: --> epoch:  47/120  avg CE: 3.6831  lr: 0.08002841155402596  
[05/04 17:46:02] SuperNet Training INFO: iter: 56640/144360  CE: 3.7135  
[05/04 17:47:02] SuperNet Training INFO: iter: 56760/144360  CE: 3.7035  
[05/04 17:48:04] SuperNet Training INFO: iter: 56880/144360  CE: 3.7304  
[05/04 17:49:06] SuperNet Training INFO: iter: 57000/144360  CE: 3.5434  
[05/04 17:50:08] SuperNet Training INFO: iter: 57120/144360  CE: 3.8543  
[05/04 17:51:10] SuperNet Training INFO: iter: 57240/144360  CE: 3.5545  
[05/04 17:52:10] SuperNet Training INFO: iter: 57360/144360  CE: 3.6243  
[05/04 17:53:11] SuperNet Training INFO: iter: 57480/144360  CE: 3.4421  
[05/04 17:54:12] SuperNet Training INFO: iter: 57600/144360  CE: 3.8000  
[05/04 17:55:13] SuperNet Training INFO: iter: 57720/144360  CE: 3.5852  
[05/04 17:55:24] SuperNet Training INFO: --> epoch:  48/120  avg CE: 3.6717  lr: 0.07854101966249659  
[05/04 17:56:51] SuperNet Training INFO: iter: 57840/144360  CE: 3.6307  
[05/04 17:57:52] SuperNet Training INFO: iter: 57960/144360  CE: 3.8254  
[05/04 17:58:54] SuperNet Training INFO: iter: 58080/144360  CE: 3.4911  
[05/04 17:59:56] SuperNet Training INFO: iter: 58200/144360  CE: 3.3298  
[05/04 18:00:58] SuperNet Training INFO: iter: 58320/144360  CE: 3.5751  
[05/04 18:02:00] SuperNet Training INFO: iter: 58440/144360  CE: 3.6536  
[05/04 18:03:03] SuperNet Training INFO: iter: 58560/144360  CE: 3.9935  
[05/04 18:04:04] SuperNet Training INFO: iter: 58680/144360  CE: 3.8814  
[05/04 18:05:07] SuperNet Training INFO: iter: 58800/144360  CE: 3.4637  
[05/04 18:06:07] SuperNet Training INFO: iter: 58920/144360  CE: 3.9298  
[05/04 18:06:20] SuperNet Training INFO: --> epoch:  49/120  avg CE: 3.6575  lr: 0.07704092068223518  
[05/04 18:07:46] SuperNet Training INFO: iter: 59040/144360  CE: 3.5615  
[05/04 18:08:49] SuperNet Training INFO: iter: 59160/144360  CE: 3.5768  
[05/04 18:09:51] SuperNet Training INFO: iter: 59280/144360  CE: 3.4857  
[05/04 18:10:51] SuperNet Training INFO: iter: 59400/144360  CE: 3.3340  
[05/04 18:11:52] SuperNet Training INFO: iter: 59520/144360  CE: 3.6449  
[05/04 18:12:53] SuperNet Training INFO: iter: 59640/144360  CE: 3.6639  
[05/04 18:13:53] SuperNet Training INFO: iter: 59760/144360  CE: 3.8157  
[05/04 18:14:54] SuperNet Training INFO: iter: 59880/144360  CE: 3.5673  
[05/04 18:15:54] SuperNet Training INFO: iter: 60000/144360  CE: 3.6395  
[05/04 18:16:55] SuperNet Training INFO: iter: 60120/144360  CE: 3.3441  
[05/04 18:17:09] SuperNet Training INFO: --> epoch:  50/120  avg CE: 3.6354  lr: 0.07552914270615126  
[05/04 18:18:33] SuperNet Training INFO: iter: 60240/144360  CE: 3.6866  
[05/04 18:19:33] SuperNet Training INFO: iter: 60360/144360  CE: 3.6606  
[05/04 18:20:34] SuperNet Training INFO: iter: 60480/144360  CE: 3.7779  
[05/04 18:21:35] SuperNet Training INFO: iter: 60600/144360  CE: 3.5217  
[05/04 18:22:35] SuperNet Training INFO: iter: 60720/144360  CE: 3.9492  
[05/04 18:23:36] SuperNet Training INFO: iter: 60840/144360  CE: 3.5232  
[05/04 18:24:37] SuperNet Training INFO: iter: 60960/144360  CE: 3.8633  
[05/04 18:25:39] SuperNet Training INFO: iter: 61080/144360  CE: 3.6997  
[05/04 18:26:40] SuperNet Training INFO: iter: 61200/144360  CE: 3.5422  
[05/04 18:27:42] SuperNet Training INFO: iter: 61320/144360  CE: 3.6701  
[05/04 18:27:57] SuperNet Training INFO: --> epoch:  51/120  avg CE: 3.6215  lr: 0.0740067218313545  
[05/04 18:29:19] SuperNet Training INFO: iter: 61440/144360  CE: 3.6640  
[05/04 18:30:21] SuperNet Training INFO: iter: 61560/144360  CE: 3.7870  
[05/04 18:31:23] SuperNet Training INFO: iter: 61680/144360  CE: 3.4065  
[05/04 18:32:25] SuperNet Training INFO: iter: 61800/144360  CE: 3.8276  
[05/04 18:33:25] SuperNet Training INFO: iter: 61920/144360  CE: 3.5401  
[05/04 18:34:27] SuperNet Training INFO: iter: 62040/144360  CE: 3.6868  
[05/04 18:35:28] SuperNet Training INFO: iter: 62160/144360  CE: 3.3806  
[05/04 18:36:28] SuperNet Training INFO: iter: 62280/144360  CE: 3.2285  
[05/04 18:37:30] SuperNet Training INFO: iter: 62400/144360  CE: 3.7777  
[05/04 18:38:31] SuperNet Training INFO: iter: 62520/144360  CE: 3.5127  
[05/04 18:38:49] SuperNet Training INFO: --> epoch:  52/120  avg CE: 3.6072  lr: 0.07247470144906537  
[05/04 18:40:09] SuperNet Training INFO: iter: 62640/144360  CE: 3.8019  
[05/04 18:41:12] SuperNet Training INFO: iter: 62760/144360  CE: 3.6312  
[05/04 18:42:14] SuperNet Training INFO: iter: 62880/144360  CE: 3.5177  
[05/04 18:43:14] SuperNet Training INFO: iter: 63000/144360  CE: 3.5481  
[05/04 18:44:15] SuperNet Training INFO: iter: 63120/144360  CE: 3.5782  
[05/04 18:45:15] SuperNet Training INFO: iter: 63240/144360  CE: 3.4639  
[05/04 18:46:17] SuperNet Training INFO: iter: 63360/144360  CE: 3.4757  
[05/04 18:47:20] SuperNet Training INFO: iter: 63480/144360  CE: 3.2102  
[05/04 18:48:23] SuperNet Training INFO: iter: 63600/144360  CE: 3.5619  
[05/04 18:49:24] SuperNet Training INFO: iter: 63720/144360  CE: 3.5473  
[05/04 18:49:43] SuperNet Training INFO: --> epoch:  53/120  avg CE: 3.5944  lr: 0.07093413152952865  
[05/04 18:51:01] SuperNet Training INFO: iter: 63840/144360  CE: 3.4811  
[05/04 18:52:03] SuperNet Training INFO: iter: 63960/144360  CE: 3.6962  
[05/04 18:53:04] SuperNet Training INFO: iter: 64080/144360  CE: 3.5822  
[05/04 18:54:05] SuperNet Training INFO: iter: 64200/144360  CE: 3.5390  
[05/04 18:55:06] SuperNet Training INFO: iter: 64320/144360  CE: 3.3562  
[05/04 18:56:06] SuperNet Training INFO: iter: 64440/144360  CE: 3.5377  
[05/04 18:57:08] SuperNet Training INFO: iter: 64560/144360  CE: 3.5306  
[05/04 18:58:10] SuperNet Training INFO: iter: 64680/144360  CE: 3.3504  
[05/04 18:59:12] SuperNet Training INFO: iter: 64800/144360  CE: 3.3499  
[05/04 19:00:14] SuperNet Training INFO: iter: 64920/144360  CE: 3.7046  
[05/04 19:00:35] SuperNet Training INFO: --> epoch:  54/120  avg CE: 3.5820  lr: 0.06938606790241343  
[05/04 19:01:52] SuperNet Training INFO: iter: 65040/144360  CE: 4.2100  
[05/04 19:02:54] SuperNet Training INFO: iter: 65160/144360  CE: 3.5383  
[05/04 19:03:54] SuperNet Training INFO: iter: 65280/144360  CE: 3.6992  
[05/04 19:04:54] SuperNet Training INFO: iter: 65400/144360  CE: 3.2963  
[05/04 19:05:55] SuperNet Training INFO: iter: 65520/144360  CE: 3.4012  
[05/04 19:06:55] SuperNet Training INFO: iter: 65640/144360  CE: 3.2986  
[05/04 19:07:56] SuperNet Training INFO: iter: 65760/144360  CE: 3.3659  
[05/04 19:08:56] SuperNet Training INFO: iter: 65880/144360  CE: 3.5063  
[05/04 19:09:57] SuperNet Training INFO: iter: 66000/144360  CE: 3.4220  
[05/04 19:10:57] SuperNet Training INFO: iter: 66120/144360  CE: 3.4524  
[05/04 19:11:19] SuperNet Training INFO: --> epoch:  55/120  avg CE: 3.5600  lr: 0.06783157153320266  
[05/04 19:12:35] SuperNet Training INFO: iter: 66240/144360  CE: 3.2772  
[05/04 19:13:37] SuperNet Training INFO: iter: 66360/144360  CE: 3.3244  
[05/04 19:14:39] SuperNet Training INFO: iter: 66480/144360  CE: 3.5799  
[05/04 19:15:41] SuperNet Training INFO: iter: 66600/144360  CE: 3.5902  
[05/04 19:16:42] SuperNet Training INFO: iter: 66720/144360  CE: 3.4381  
[05/04 19:17:44] SuperNet Training INFO: iter: 66840/144360  CE: 3.2405  
[05/04 19:18:45] SuperNet Training INFO: iter: 66960/144360  CE: 3.4692  
[05/04 19:19:48] SuperNet Training INFO: iter: 67080/144360  CE: 3.7432  
[05/04 19:20:48] SuperNet Training INFO: iter: 67200/144360  CE: 3.7527  
[05/04 19:21:51] SuperNet Training INFO: iter: 67320/144360  CE: 3.6093  
[05/04 19:22:15] SuperNet Training INFO: --> epoch:  56/120  avg CE: 3.5420  lr: 0.06627170779605904  
[05/04 19:23:30] SuperNet Training INFO: iter: 67440/144360  CE: 3.5275  
[05/04 19:24:31] SuperNet Training INFO: iter: 67560/144360  CE: 3.5443  
[05/04 19:25:33] SuperNet Training INFO: iter: 67680/144360  CE: 3.4516  
[05/04 19:26:34] SuperNet Training INFO: iter: 67800/144360  CE: 3.7726  
[05/04 19:27:35] SuperNet Training INFO: iter: 67920/144360  CE: 3.5535  
[05/04 19:28:36] SuperNet Training INFO: iter: 68040/144360  CE: 3.4688  
[05/04 19:29:37] SuperNet Training INFO: iter: 68160/144360  CE: 3.2449  
[05/04 19:30:38] SuperNet Training INFO: iter: 68280/144360  CE: 3.4798  
[05/04 19:31:40] SuperNet Training INFO: iter: 68400/144360  CE: 3.6773  
[05/04 19:32:42] SuperNet Training INFO: iter: 68520/144360  CE: 3.5872  
[05/04 19:33:08] SuperNet Training INFO: --> epoch:  57/120  avg CE: 3.5374  lr: 0.06470754574367053  
[05/04 19:34:21] SuperNet Training INFO: iter: 68640/144360  CE: 3.5076  
[05/04 19:35:23] SuperNet Training INFO: iter: 68760/144360  CE: 3.5169  
[05/04 19:36:25] SuperNet Training INFO: iter: 68880/144360  CE: 3.2354  
[05/04 19:37:27] SuperNet Training INFO: iter: 69000/144360  CE: 3.5262  
[05/04 19:38:28] SuperNet Training INFO: iter: 69120/144360  CE: 3.3901  
[05/04 19:39:29] SuperNet Training INFO: iter: 69240/144360  CE: 3.5614  
[05/04 19:40:31] SuperNet Training INFO: iter: 69360/144360  CE: 3.7100  
[05/04 19:41:34] SuperNet Training INFO: iter: 69480/144360  CE: 3.2374  
[05/04 19:42:36] SuperNet Training INFO: iter: 69600/144360  CE: 3.2998  
[05/04 19:43:38] SuperNet Training INFO: iter: 69720/144360  CE: 3.4963  
[05/04 19:44:05] SuperNet Training INFO: --> epoch:  58/120  avg CE: 3.5144  lr: 0.06314015737457618  
[05/04 19:45:15] SuperNet Training INFO: iter: 69840/144360  CE: 3.4963  
[05/04 19:46:17] SuperNet Training INFO: iter: 69960/144360  CE: 3.7042  
[05/04 19:47:20] SuperNet Training INFO: iter: 70080/144360  CE: 3.6676  
[05/04 19:48:21] SuperNet Training INFO: iter: 70200/144360  CE: 3.2478  
[05/04 19:49:23] SuperNet Training INFO: iter: 70320/144360  CE: 3.6176  
[05/04 19:50:24] SuperNet Training INFO: iter: 70440/144360  CE: 3.3584  
[05/04 19:51:23] SuperNet Training INFO: iter: 70560/144360  CE: 3.6418  
[05/04 19:52:24] SuperNet Training INFO: iter: 70680/144360  CE: 3.5105  
[05/04 19:53:24] SuperNet Training INFO: iter: 70800/144360  CE: 3.2926  
[05/04 19:54:23] SuperNet Training INFO: iter: 70920/144360  CE: 3.1614  
[05/04 19:54:50] SuperNet Training INFO: --> epoch:  59/120  avg CE: 3.5012  lr: 0.061570616898472125  
[05/04 19:56:02] SuperNet Training INFO: iter: 71040/144360  CE: 3.1469  
[05/04 19:57:03] SuperNet Training INFO: iter: 71160/144360  CE: 3.3673  
[05/04 19:58:05] SuperNet Training INFO: iter: 71280/144360  CE: 3.5359  
[05/04 19:59:06] SuperNet Training INFO: iter: 71400/144360  CE: 3.4989  
[05/04 20:00:09] SuperNet Training INFO: iter: 71520/144360  CE: 3.3919  
[05/04 20:01:10] SuperNet Training INFO: iter: 71640/144360  CE: 3.3820  
[05/04 20:02:12] SuperNet Training INFO: iter: 71760/144360  CE: 3.4562  
[05/04 20:03:14] SuperNet Training INFO: iter: 71880/144360  CE: 3.5116  
[05/04 20:04:15] SuperNet Training INFO: iter: 72000/144360  CE: 3.4826  
[05/04 20:05:15] SuperNet Training INFO: iter: 72120/144360  CE: 3.3848  
[05/04 20:05:45] SuperNet Training INFO: --> epoch:  60/120  avg CE: 3.4935  lr: 0.05999999999999976  
[05/04 20:06:52] SuperNet Training INFO: iter: 72240/144360  CE: 3.4039  
[05/04 20:07:54] SuperNet Training INFO: iter: 72360/144360  CE: 3.4226  
[05/04 20:08:56] SuperNet Training INFO: iter: 72480/144360  CE: 3.3993  
[05/04 20:09:58] SuperNet Training INFO: iter: 72600/144360  CE: 3.5981  
[05/04 20:10:59] SuperNet Training INFO: iter: 72720/144360  CE: 3.1957  
[05/04 20:12:02] SuperNet Training INFO: iter: 72840/144360  CE: 3.2668  
[05/04 20:13:04] SuperNet Training INFO: iter: 72960/144360  CE: 3.3769  
[05/04 20:14:06] SuperNet Training INFO: iter: 73080/144360  CE: 3.5052  
[05/04 20:15:08] SuperNet Training INFO: iter: 73200/144360  CE: 3.7623  
[05/04 20:16:09] SuperNet Training INFO: iter: 73320/144360  CE: 3.6332  
[05/04 20:16:40] SuperNet Training INFO: --> epoch:  61/120  avg CE: 3.4815  lr: 0.058429383101527455  
[05/04 20:17:47] SuperNet Training INFO: iter: 73440/144360  CE: 3.2791  
[05/04 20:18:48] SuperNet Training INFO: iter: 73560/144360  CE: 3.2141  
[05/04 20:19:49] SuperNet Training INFO: iter: 73680/144360  CE: 3.4134  
[05/04 20:20:50] SuperNet Training INFO: iter: 73800/144360  CE: 3.3385  
[05/04 20:21:52] SuperNet Training INFO: iter: 73920/144360  CE: 3.4955  
[05/04 20:22:53] SuperNet Training INFO: iter: 74040/144360  CE: 3.5196  
[05/04 20:23:54] SuperNet Training INFO: iter: 74160/144360  CE: 3.3057  
[05/04 20:24:56] SuperNet Training INFO: iter: 74280/144360  CE: 3.5248  
[05/04 20:25:57] SuperNet Training INFO: iter: 74400/144360  CE: 3.4931  
[05/04 20:27:00] SuperNet Training INFO: iter: 74520/144360  CE: 3.3798  
[05/04 20:27:33] SuperNet Training INFO: --> epoch:  62/120  avg CE: 3.4660  lr: 0.05685984262542327  
[05/04 20:28:38] SuperNet Training INFO: iter: 74640/144360  CE: 3.8267  
[05/04 20:29:40] SuperNet Training INFO: iter: 74760/144360  CE: 3.5817  
[05/04 20:30:41] SuperNet Training INFO: iter: 74880/144360  CE: 3.7361  
[05/04 20:31:41] SuperNet Training INFO: iter: 75000/144360  CE: 3.6042  
[05/04 20:32:40] SuperNet Training INFO: iter: 75120/144360  CE: 3.4121  
[05/04 20:33:42] SuperNet Training INFO: iter: 75240/144360  CE: 3.2743  
[05/04 20:34:43] SuperNet Training INFO: iter: 75360/144360  CE: 3.3546  
[05/04 20:35:45] SuperNet Training INFO: iter: 75480/144360  CE: 3.6844  
[05/04 20:36:46] SuperNet Training INFO: iter: 75600/144360  CE: 3.3417  
[05/04 20:37:49] SuperNet Training INFO: iter: 75720/144360  CE: 3.0948  
[05/04 20:38:23] SuperNet Training INFO: --> epoch:  63/120  avg CE: 3.4466  lr: 0.05529245425632924  
[05/04 20:39:27] SuperNet Training INFO: iter: 75840/144360  CE: 3.4181  
[05/04 20:40:28] SuperNet Training INFO: iter: 75960/144360  CE: 3.3215  
[05/04 20:41:29] SuperNet Training INFO: iter: 76080/144360  CE: 3.2602  
[05/04 20:42:30] SuperNet Training INFO: iter: 76200/144360  CE: 3.2005  
[05/04 20:43:32] SuperNet Training INFO: iter: 76320/144360  CE: 3.3552  
[05/04 20:44:34] SuperNet Training INFO: iter: 76440/144360  CE: 3.3914  
[05/04 20:45:36] SuperNet Training INFO: iter: 76560/144360  CE: 3.5843  
[05/04 20:46:39] SuperNet Training INFO: iter: 76680/144360  CE: 3.4233  
[05/04 20:47:41] SuperNet Training INFO: iter: 76800/144360  CE: 3.3679  
[05/04 20:48:43] SuperNet Training INFO: iter: 76920/144360  CE: 3.5102  
[05/04 20:49:19] SuperNet Training INFO: --> epoch:  64/120  avg CE: 3.4250  lr: 0.05372829220394078  
[05/04 20:50:20] SuperNet Training INFO: iter: 77040/144360  CE: 3.4892  
[05/04 20:51:23] SuperNet Training INFO: iter: 77160/144360  CE: 3.4278  
[05/04 20:52:24] SuperNet Training INFO: iter: 77280/144360  CE: 3.4056  
[05/04 20:53:24] SuperNet Training INFO: iter: 77400/144360  CE: 3.3832  
[05/04 20:54:24] SuperNet Training INFO: iter: 77520/144360  CE: 3.4362  
[05/04 20:55:24] SuperNet Training INFO: iter: 77640/144360  CE: 3.5134  
[05/04 20:56:26] SuperNet Training INFO: iter: 77760/144360  CE: 3.3285  
[05/04 20:57:26] SuperNet Training INFO: iter: 77880/144360  CE: 3.3793  
[05/04 20:58:28] SuperNet Training INFO: iter: 78000/144360  CE: 3.7839  
[05/04 20:59:27] SuperNet Training INFO: iter: 78120/144360  CE: 3.2040  
[05/04 21:00:04] SuperNet Training INFO: --> epoch:  65/120  avg CE: 3.4113  lr: 0.05216842846679694  
[05/04 21:01:05] SuperNet Training INFO: iter: 78240/144360  CE: 3.3575  
[05/04 21:02:07] SuperNet Training INFO: iter: 78360/144360  CE: 3.1374  
[05/04 21:03:07] SuperNet Training INFO: iter: 78480/144360  CE: 3.2870  
[05/04 21:04:08] SuperNet Training INFO: iter: 78600/144360  CE: 3.4733  
[05/04 21:05:08] SuperNet Training INFO: iter: 78720/144360  CE: 3.3085  
[05/04 21:06:09] SuperNet Training INFO: iter: 78840/144360  CE: 3.3235  
[05/04 21:07:11] SuperNet Training INFO: iter: 78960/144360  CE: 3.5121  
[05/04 21:08:12] SuperNet Training INFO: iter: 79080/144360  CE: 3.4044  
[05/04 21:09:14] SuperNet Training INFO: iter: 79200/144360  CE: 3.5356  
[05/04 21:10:16] SuperNet Training INFO: iter: 79320/144360  CE: 3.4744  
[05/04 21:10:55] SuperNet Training INFO: --> epoch:  66/120  avg CE: 3.4085  lr: 0.05061393209758616  
[05/04 21:11:54] SuperNet Training INFO: iter: 79440/144360  CE: 3.6404  
[05/04 21:12:56] SuperNet Training INFO: iter: 79560/144360  CE: 3.4085  
[05/04 21:13:59] SuperNet Training INFO: iter: 79680/144360  CE: 3.4735  
[05/04 21:15:01] SuperNet Training INFO: iter: 79800/144360  CE: 3.3091  
[05/04 21:16:02] SuperNet Training INFO: iter: 79920/144360  CE: 3.3786  
[05/04 21:17:04] SuperNet Training INFO: iter: 80040/144360  CE: 3.3986  
[05/04 21:18:07] SuperNet Training INFO: iter: 80160/144360  CE: 3.2026  
[05/04 21:19:09] SuperNet Training INFO: iter: 80280/144360  CE: 3.5515  
[05/04 21:20:09] SuperNet Training INFO: iter: 80400/144360  CE: 3.5237  
[05/04 21:21:10] SuperNet Training INFO: iter: 80520/144360  CE: 3.5153  
[05/04 21:21:50] SuperNet Training INFO: --> epoch:  67/120  avg CE: 3.3962  lr: 0.04906586847047105  
[05/04 21:22:47] SuperNet Training INFO: iter: 80640/144360  CE: 3.0069  
[05/04 21:23:48] SuperNet Training INFO: iter: 80760/144360  CE: 3.1776  
[05/04 21:24:49] SuperNet Training INFO: iter: 80880/144360  CE: 3.0829  
[05/04 21:25:49] SuperNet Training INFO: iter: 81000/144360  CE: 3.6397  
[05/04 21:26:50] SuperNet Training INFO: iter: 81120/144360  CE: 3.2482  
[05/04 21:27:52] SuperNet Training INFO: iter: 81240/144360  CE: 3.7755  
[05/04 21:28:52] SuperNet Training INFO: iter: 81360/144360  CE: 3.4664  
[05/04 21:29:53] SuperNet Training INFO: iter: 81480/144360  CE: 3.0726  
[05/04 21:30:53] SuperNet Training INFO: iter: 81600/144360  CE: 3.4178  
[05/04 21:31:54] SuperNet Training INFO: iter: 81720/144360  CE: 3.3646  
[05/04 21:32:36] SuperNet Training INFO: --> epoch:  68/120  avg CE: 3.3677  lr: 0.04752529855093431  
[05/04 21:33:31] SuperNet Training INFO: iter: 81840/144360  CE: 2.9885  
[05/04 21:34:32] SuperNet Training INFO: iter: 81960/144360  CE: 3.0883  
[05/04 21:35:32] SuperNet Training INFO: iter: 82080/144360  CE: 3.3222  
[05/04 21:36:32] SuperNet Training INFO: iter: 82200/144360  CE: 3.3298  
[05/04 21:37:30] SuperNet Training INFO: iter: 82320/144360  CE: 3.2711  
[05/04 21:38:30] SuperNet Training INFO: iter: 82440/144360  CE: 3.6226  
[05/04 21:39:30] SuperNet Training INFO: iter: 82560/144360  CE: 3.3586  
[05/04 21:40:29] SuperNet Training INFO: iter: 82680/144360  CE: 3.3684  
[05/04 21:41:29] SuperNet Training INFO: iter: 82800/144360  CE: 3.4359  
[05/04 21:42:30] SuperNet Training INFO: iter: 82920/144360  CE: 3.0896  
[05/04 21:43:14] SuperNet Training INFO: --> epoch:  69/120  avg CE: 3.3615  lr: 0.04599327816864548  
[05/04 21:44:08] SuperNet Training INFO: iter: 83040/144360  CE: 3.1573  
[05/04 21:45:10] SuperNet Training INFO: iter: 83160/144360  CE: 3.5195  
[05/04 21:46:12] SuperNet Training INFO: iter: 83280/144360  CE: 3.4676  
[05/04 21:47:11] SuperNet Training INFO: iter: 83400/144360  CE: 3.3092  
[05/04 21:48:12] SuperNet Training INFO: iter: 83520/144360  CE: 3.5199  
[05/04 21:49:15] SuperNet Training INFO: iter: 83640/144360  CE: 3.1081  
[05/04 21:50:16] SuperNet Training INFO: iter: 83760/144360  CE: 3.2331  
[05/04 21:51:19] SuperNet Training INFO: iter: 83880/144360  CE: 3.3807  
[05/04 21:52:21] SuperNet Training INFO: iter: 84000/144360  CE: 3.3901  
[05/04 21:53:23] SuperNet Training INFO: iter: 84120/144360  CE: 3.2366  
[05/04 21:54:08] SuperNet Training INFO: --> epoch:  70/120  avg CE: 3.3455  lr: 0.04447085729384866  
[05/04 21:55:01] SuperNet Training INFO: iter: 84240/144360  CE: 3.3961  
[05/04 21:56:03] SuperNet Training INFO: iter: 84360/144360  CE: 3.0563  
[05/04 21:57:05] SuperNet Training INFO: iter: 84480/144360  CE: 3.3159  
[05/04 21:58:07] SuperNet Training INFO: iter: 84600/144360  CE: 3.5393  
[05/04 21:59:08] SuperNet Training INFO: iter: 84720/144360  CE: 3.0737  
[05/04 22:00:09] SuperNet Training INFO: iter: 84840/144360  CE: 3.2053  
[05/04 22:01:09] SuperNet Training INFO: iter: 84960/144360  CE: 3.4213  
[05/04 22:02:10] SuperNet Training INFO: iter: 85080/144360  CE: 3.2868  
[05/04 22:03:13] SuperNet Training INFO: iter: 85200/144360  CE: 3.3345  
[05/04 22:04:14] SuperNet Training INFO: iter: 85320/144360  CE: 2.9997  
[05/04 22:05:02] SuperNet Training INFO: --> epoch:  71/120  avg CE: 3.3395  lr: 0.04295907931776456  
[05/04 22:05:52] SuperNet Training INFO: iter: 85440/144360  CE: 3.3933  
[05/04 22:06:54] SuperNet Training INFO: iter: 85560/144360  CE: 3.4224  
[05/04 22:07:56] SuperNet Training INFO: iter: 85680/144360  CE: 3.2256  
[05/04 22:08:57] SuperNet Training INFO: iter: 85800/144360  CE: 3.2896  
[05/04 22:09:59] SuperNet Training INFO: iter: 85920/144360  CE: 3.0711  
[05/04 22:10:58] SuperNet Training INFO: iter: 86040/144360  CE: 3.2729  
[05/04 22:11:59] SuperNet Training INFO: iter: 86160/144360  CE: 3.4116  
[05/04 22:13:01] SuperNet Training INFO: iter: 86280/144360  CE: 3.0481  
[05/04 22:14:02] SuperNet Training INFO: iter: 86400/144360  CE: 3.0498  
[05/04 22:15:03] SuperNet Training INFO: iter: 86520/144360  CE: 3.4240  
[05/04 22:15:52] SuperNet Training INFO: --> epoch:  72/120  avg CE: 3.3251  lr: 0.04145898033750296  
[05/04 22:16:40] SuperNet Training INFO: iter: 86640/144360  CE: 3.4331  
[05/04 22:17:41] SuperNet Training INFO: iter: 86760/144360  CE: 3.4011  
[05/04 22:18:41] SuperNet Training INFO: iter: 86880/144360  CE: 2.9991  
[05/04 22:19:42] SuperNet Training INFO: iter: 87000/144360  CE: 3.0913  
[05/04 22:20:42] SuperNet Training INFO: iter: 87120/144360  CE: 3.0821  
[05/04 22:21:43] SuperNet Training INFO: iter: 87240/144360  CE: 3.2041  
[05/04 22:22:44] SuperNet Training INFO: iter: 87360/144360  CE: 3.2960  
[05/04 22:23:45] SuperNet Training INFO: iter: 87480/144360  CE: 3.1872  
[05/04 22:24:47] SuperNet Training INFO: iter: 87600/144360  CE: 2.9999  
[05/04 22:25:48] SuperNet Training INFO: iter: 87720/144360  CE: 3.0891  
[05/04 22:26:37] SuperNet Training INFO: --> epoch:  73/120  avg CE: 3.3113  lr: 0.03997158844597365  
[05/04 22:27:25] SuperNet Training INFO: iter: 87840/144360  CE: 3.1689  
[05/04 22:28:27] SuperNet Training INFO: iter: 87960/144360  CE: 3.2657  
[05/04 22:29:30] SuperNet Training INFO: iter: 88080/144360  CE: 3.1113  
[05/04 22:30:31] SuperNet Training INFO: iter: 88200/144360  CE: 3.2937  
[05/04 22:31:33] SuperNet Training INFO: iter: 88320/144360  CE: 3.3169  
[05/04 22:32:34] SuperNet Training INFO: iter: 88440/144360  CE: 3.2336  
[05/04 22:33:35] SuperNet Training INFO: iter: 88560/144360  CE: 2.8879  
[05/04 22:34:37] SuperNet Training INFO: iter: 88680/144360  CE: 3.1339  
[05/04 22:35:39] SuperNet Training INFO: iter: 88800/144360  CE: 3.1309  
[05/04 22:36:41] SuperNet Training INFO: iter: 88920/144360  CE: 3.5745  
[05/04 22:37:34] SuperNet Training INFO: --> epoch:  74/120  avg CE: 3.2976  lr: 0.03849792302728192  
[05/04 22:38:20] SuperNet Training INFO: iter: 89040/144360  CE: 3.2149  
[05/04 22:39:23] SuperNet Training INFO: iter: 89160/144360  CE: 3.1620  
[05/04 22:40:25] SuperNet Training INFO: iter: 89280/144360  CE: 2.9933  
[05/04 22:41:27] SuperNet Training INFO: iter: 89400/144360  CE: 3.0654  
[05/04 22:42:28] SuperNet Training INFO: iter: 89520/144360  CE: 3.2142  
[05/04 22:43:30] SuperNet Training INFO: iter: 89640/144360  CE: 3.2927  
[05/04 22:44:32] SuperNet Training INFO: iter: 89760/144360  CE: 3.3993  
[05/04 22:45:34] SuperNet Training INFO: iter: 89880/144360  CE: 3.2696  
[05/04 22:46:36] SuperNet Training INFO: iter: 90000/144360  CE: 3.4495  
[05/04 22:47:38] SuperNet Training INFO: iter: 90120/144360  CE: 2.9971  
[05/04 22:48:30] SuperNet Training INFO: --> epoch:  75/120  avg CE: 3.2874  lr: 0.03703899405809455  
[05/04 22:49:16] SuperNet Training INFO: iter: 90240/144360  CE: 3.2854  
[05/04 22:50:16] SuperNet Training INFO: iter: 90360/144360  CE: 3.2619  
[05/04 22:51:17] SuperNet Training INFO: iter: 90480/144360  CE: 3.3770  
[05/04 22:52:17] SuperNet Training INFO: iter: 90600/144360  CE: 3.0663  
[05/04 22:53:18] SuperNet Training INFO: iter: 90720/144360  CE: 3.1021  
[05/04 22:54:19] SuperNet Training INFO: iter: 90840/144360  CE: 3.2328  
[05/04 22:55:22] SuperNet Training INFO: iter: 90960/144360  CE: 3.3352  
[05/04 22:56:24] SuperNet Training INFO: iter: 91080/144360  CE: 3.4555  
[05/04 22:57:23] SuperNet Training INFO: iter: 91200/144360  CE: 3.1232  
[05/04 22:58:25] SuperNet Training INFO: iter: 91320/144360  CE: 3.2652  
[05/04 22:59:19] SuperNet Training INFO: --> epoch:  76/120  avg CE: 3.2746  lr: 0.035595801415451815  
[05/04 23:00:02] SuperNet Training INFO: iter: 91440/144360  CE: 3.2638  
[05/04 23:01:02] SuperNet Training INFO: iter: 91560/144360  CE: 3.4280  
[05/04 23:02:03] SuperNet Training INFO: iter: 91680/144360  CE: 3.1211  
[05/04 23:03:03] SuperNet Training INFO: iter: 91800/144360  CE: 3.2155  
[05/04 23:04:05] SuperNet Training INFO: iter: 91920/144360  CE: 2.9545  
[05/04 23:05:06] SuperNet Training INFO: iter: 92040/144360  CE: 3.2486  
[05/04 23:06:06] SuperNet Training INFO: iter: 92160/144360  CE: 3.4201  
[05/04 23:07:07] SuperNet Training INFO: iter: 92280/144360  CE: 3.1607  
[05/04 23:08:07] SuperNet Training INFO: iter: 92400/144360  CE: 3.2946  
[05/04 23:09:08] SuperNet Training INFO: iter: 92520/144360  CE: 3.0997  
[05/04 23:10:03] SuperNet Training INFO: --> epoch:  77/120  avg CE: 3.2705  lr: 0.03416933419150217  
[05/04 23:10:45] SuperNet Training INFO: iter: 92640/144360  CE: 3.1793  
[05/04 23:11:45] SuperNet Training INFO: iter: 92760/144360  CE: 3.1045  
[05/04 23:12:46] SuperNet Training INFO: iter: 92880/144360  CE: 3.3604  
[05/04 23:13:46] SuperNet Training INFO: iter: 93000/144360  CE: 3.4248  
[05/04 23:14:47] SuperNet Training INFO: iter: 93120/144360  CE: 3.2556  
[05/04 23:15:48] SuperNet Training INFO: iter: 93240/144360  CE: 3.1847  
[05/04 23:16:50] SuperNet Training INFO: iter: 93360/144360  CE: 3.3749  
[05/04 23:17:52] SuperNet Training INFO: iter: 93480/144360  CE: 3.0538  
[05/04 23:18:54] SuperNet Training INFO: iter: 93600/144360  CE: 3.2758  
[05/04 23:19:56] SuperNet Training INFO: iter: 93720/144360  CE: 3.5225  
[05/04 23:20:53] SuperNet Training INFO: --> epoch:  78/120  avg CE: 3.2627  lr: 0.03276057001562702  
[05/04 23:21:34] SuperNet Training INFO: iter: 93840/144360  CE: 3.3985  
[05/04 23:22:37] SuperNet Training INFO: iter: 93960/144360  CE: 3.1056  
[05/04 23:23:38] SuperNet Training INFO: iter: 94080/144360  CE: 3.2907  
[05/04 23:24:39] SuperNet Training INFO: iter: 94200/144360  CE: 3.0194  
[05/04 23:25:43] SuperNet Training INFO: iter: 94320/144360  CE: 3.1705  
[05/04 23:26:44] SuperNet Training INFO: iter: 94440/144360  CE: 3.2391  
[05/04 23:27:46] SuperNet Training INFO: iter: 94560/144360  CE: 3.1815  
[05/04 23:28:48] SuperNet Training INFO: iter: 94680/144360  CE: 3.3585  
[05/04 23:29:50] SuperNet Training INFO: iter: 94800/144360  CE: 3.2589  
[05/04 23:30:51] SuperNet Training INFO: iter: 94920/144360  CE: 3.4343  
[05/04 23:31:49] SuperNet Training INFO: --> epoch:  79/120  avg CE: 3.2435  lr: 0.031370474384423336  
[05/04 23:32:28] SuperNet Training INFO: iter: 95040/144360  CE: 3.4104  
[05/04 23:33:28] SuperNet Training INFO: iter: 95160/144360  CE: 3.3772  
[05/04 23:34:30] SuperNet Training INFO: iter: 95280/144360  CE: 3.2102  
[05/04 23:35:31] SuperNet Training INFO: iter: 95400/144360  CE: 3.1337  
[05/04 23:36:33] SuperNet Training INFO: iter: 95520/144360  CE: 3.0478  
[05/04 23:37:35] SuperNet Training INFO: iter: 95640/144360  CE: 3.2202  
[05/04 23:38:36] SuperNet Training INFO: iter: 95760/144360  CE: 3.2767  
[05/04 23:39:38] SuperNet Training INFO: iter: 95880/144360  CE: 3.4176  
[05/04 23:40:40] SuperNet Training INFO: iter: 96000/144360  CE: 3.3076  
[05/04 23:41:41] SuperNet Training INFO: iter: 96120/144360  CE: 3.0972  
[05/04 23:42:41] SuperNet Training INFO: iter: 96240/144360  CE: 3.3088  
[05/04 23:42:41] SuperNet Training INFO: --> epoch:  80/120  avg CE: 3.2337  lr: 0.02999999999999983  
[05/04 23:44:18] SuperNet Training INFO: iter: 96360/144360  CE: 3.0924  
[05/04 23:45:19] SuperNet Training INFO: iter: 96480/144360  CE: 2.8471  
[05/04 23:46:21] SuperNet Training INFO: iter: 96600/144360  CE: 3.0531  
[05/04 23:47:22] SuperNet Training INFO: iter: 96720/144360  CE: 3.3674  
[05/04 23:48:23] SuperNet Training INFO: iter: 96840/144360  CE: 3.0281  
[05/04 23:49:24] SuperNet Training INFO: iter: 96960/144360  CE: 3.4222  
[05/04 23:50:26] SuperNet Training INFO: iter: 97080/144360  CE: 3.1619  
[05/04 23:51:28] SuperNet Training INFO: iter: 97200/144360  CE: 3.3617  
[05/04 23:52:29] SuperNet Training INFO: iter: 97320/144360  CE: 3.6225  
[05/04 23:53:29] SuperNet Training INFO: iter: 97440/144360  CE: 3.0201  
[05/04 23:53:30] SuperNet Training INFO: --> epoch:  81/120  avg CE: 3.2231  lr: 0.028650086117042926  
[05/04 23:55:08] SuperNet Training INFO: iter: 97560/144360  CE: 3.4054  
[05/04 23:56:10] SuperNet Training INFO: iter: 97680/144360  CE: 3.3518  
[05/04 23:57:12] SuperNet Training INFO: iter: 97800/144360  CE: 3.2470  
[05/04 23:58:14] SuperNet Training INFO: iter: 97920/144360  CE: 3.2314  
[05/04 23:59:17] SuperNet Training INFO: iter: 98040/144360  CE: 3.1897  
[05/05 00:00:18] SuperNet Training INFO: iter: 98160/144360  CE: 3.3091  
[05/05 00:01:19] SuperNet Training INFO: iter: 98280/144360  CE: 3.3521  
[05/05 00:02:20] SuperNet Training INFO: iter: 98400/144360  CE: 3.1327  
[05/05 00:03:21] SuperNet Training INFO: iter: 98520/144360  CE: 3.4079  
[05/05 00:04:21] SuperNet Training INFO: iter: 98640/144360  CE: 3.3925  
[05/05 00:04:23] SuperNet Training INFO: --> epoch:  82/120  avg CE: 3.2106  lr: 0.027321657899098132  
[05/05 00:05:59] SuperNet Training INFO: iter: 98760/144360  CE: 2.9052  
[05/05 00:07:02] SuperNet Training INFO: iter: 98880/144360  CE: 3.2914  
[05/05 00:08:04] SuperNet Training INFO: iter: 99000/144360  CE: 2.9540  
[05/05 00:09:06] SuperNet Training INFO: iter: 99120/144360  CE: 3.0774  
[05/05 00:10:07] SuperNet Training INFO: iter: 99240/144360  CE: 3.0907  
[05/05 00:11:09] SuperNet Training INFO: iter: 99360/144360  CE: 3.3181  
[05/05 00:12:12] SuperNet Training INFO: iter: 99480/144360  CE: 3.1708  
[05/05 00:13:14] SuperNet Training INFO: iter: 99600/144360  CE: 3.1298  
[05/05 00:14:17] SuperNet Training INFO: iter: 99720/144360  CE: 3.0204  
[05/05 00:15:19] SuperNet Training INFO: iter: 99840/144360  CE: 3.3078  
[05/05 00:15:23] SuperNet Training INFO: --> epoch:  83/120  avg CE: 3.1983  lr: 0.0260156257845098  
[05/05 00:16:56] SuperNet Training INFO: iter: 99960/144360  CE: 3.3615  
[05/05 00:17:56] SuperNet Training INFO: iter: 100080/144360  CE: 3.2293  
[05/05 00:18:57] SuperNet Training INFO: iter: 100200/144360  CE: 3.4133  
[05/05 00:19:56] SuperNet Training INFO: iter: 100320/144360  CE: 3.1607  
[05/05 00:20:57] SuperNet Training INFO: iter: 100440/144360  CE: 3.2009  
[05/05 00:21:58] SuperNet Training INFO: iter: 100560/144360  CE: 3.1209  
[05/05 00:23:01] SuperNet Training INFO: iter: 100680/144360  CE: 2.9857  
[05/05 00:24:03] SuperNet Training INFO: iter: 100800/144360  CE: 3.0881  
[05/05 00:25:04] SuperNet Training INFO: iter: 100920/144360  CE: 3.3170  
[05/05 00:26:06] SuperNet Training INFO: iter: 101040/144360  CE: 3.1555  
[05/05 00:26:11] SuperNet Training INFO: --> epoch:  84/120  avg CE: 3.1807  lr: 0.02473288486245143  
[05/05 00:27:42] SuperNet Training INFO: iter: 101160/144360  CE: 3.1248  
[05/05 00:28:43] SuperNet Training INFO: iter: 101280/144360  CE: 3.2585  
[05/05 00:29:45] SuperNet Training INFO: iter: 101400/144360  CE: 3.0736  
[05/05 00:30:47] SuperNet Training INFO: iter: 101520/144360  CE: 3.0802  
[05/05 00:31:47] SuperNet Training INFO: iter: 101640/144360  CE: 3.2661  
[05/05 00:32:47] SuperNet Training INFO: iter: 101760/144360  CE: 3.2341  
[05/05 00:33:49] SuperNet Training INFO: iter: 101880/144360  CE: 3.3900  
[05/05 00:34:49] SuperNet Training INFO: iter: 102000/144360  CE: 3.1645  
[05/05 00:35:50] SuperNet Training INFO: iter: 102120/144360  CE: 3.0066  
[05/05 00:36:51] SuperNet Training INFO: iter: 102240/144360  CE: 3.1242  
[05/05 00:36:58] SuperNet Training INFO: --> epoch:  85/120  avg CE: 3.1783  lr: 0.023474314259476523  
[05/05 00:38:28] SuperNet Training INFO: iter: 102360/144360  CE: 3.0260  
[05/05 00:39:29] SuperNet Training INFO: iter: 102480/144360  CE: 3.1742  
[05/05 00:40:30] SuperNet Training INFO: iter: 102600/144360  CE: 3.3172  
[05/05 00:41:31] SuperNet Training INFO: iter: 102720/144360  CE: 3.0499  
[05/05 00:42:31] SuperNet Training INFO: iter: 102840/144360  CE: 3.2253  
[05/05 00:43:33] SuperNet Training INFO: iter: 102960/144360  CE: 3.2484  
[05/05 00:44:32] SuperNet Training INFO: iter: 103080/144360  CE: 3.2344  
[05/05 00:45:32] SuperNet Training INFO: iter: 103200/144360  CE: 3.1554  
[05/05 00:46:33] SuperNet Training INFO: iter: 103320/144360  CE: 3.0685  
[05/05 00:47:34] SuperNet Training INFO: iter: 103440/144360  CE: 3.3168  
[05/05 00:47:41] SuperNet Training INFO: --> epoch:  86/120  avg CE: 3.1651  lr: 0.02224077653700959  
[05/05 00:49:10] SuperNet Training INFO: iter: 103560/144360  CE: 3.1028  
[05/05 00:50:12] SuperNet Training INFO: iter: 103680/144360  CE: 2.8511  
[05/05 00:51:14] SuperNet Training INFO: iter: 103800/144360  CE: 3.0160  
[05/05 00:52:15] SuperNet Training INFO: iter: 103920/144360  CE: 3.2599  
[05/05 00:53:14] SuperNet Training INFO: iter: 104040/144360  CE: 3.2042  
[05/05 00:54:15] SuperNet Training INFO: iter: 104160/144360  CE: 3.2014  
[05/05 00:55:15] SuperNet Training INFO: iter: 104280/144360  CE: 3.1761  
[05/05 00:56:16] SuperNet Training INFO: iter: 104400/144360  CE: 3.0491  
[05/05 00:57:17] SuperNet Training INFO: iter: 104520/144360  CE: 3.0974  
[05/05 00:58:19] SuperNet Training INFO: iter: 104640/144360  CE: 3.3393  
[05/05 00:58:29] SuperNet Training INFO: --> epoch:  87/120  avg CE: 3.1531  lr: 0.02103311710018879  
[05/05 00:59:57] SuperNet Training INFO: iter: 104760/144360  CE: 3.1541  
[05/05 01:00:57] SuperNet Training INFO: iter: 104880/144360  CE: 3.0387  
[05/05 01:01:59] SuperNet Training INFO: iter: 105000/144360  CE: 3.3323  
[05/05 01:02:59] SuperNet Training INFO: iter: 105120/144360  CE: 3.1135  
[05/05 01:03:59] SuperNet Training INFO: iter: 105240/144360  CE: 3.2270  
[05/05 01:05:00] SuperNet Training INFO: iter: 105360/144360  CE: 3.1027  
[05/05 01:06:03] SuperNet Training INFO: iter: 105480/144360  CE: 3.3387  
[05/05 01:07:04] SuperNet Training INFO: iter: 105600/144360  CE: 3.4735  
[05/05 01:08:07] SuperNet Training INFO: iter: 105720/144360  CE: 3.2698  
[05/05 01:09:08] SuperNet Training INFO: iter: 105840/144360  CE: 3.0578  
[05/05 01:09:19] SuperNet Training INFO: --> epoch:  88/120  avg CE: 3.1506  lr: 0.019852163618468272  
[05/05 01:10:45] SuperNet Training INFO: iter: 105960/144360  CE: 3.1763  
[05/05 01:11:48] SuperNet Training INFO: iter: 106080/144360  CE: 3.0068  
[05/05 01:12:48] SuperNet Training INFO: iter: 106200/144360  CE: 2.8351  
[05/05 01:13:51] SuperNet Training INFO: iter: 106320/144360  CE: 2.9034  
[05/05 01:14:52] SuperNet Training INFO: iter: 106440/144360  CE: 2.9179  
[05/05 01:15:53] SuperNet Training INFO: iter: 106560/144360  CE: 3.1421  
[05/05 01:16:54] SuperNet Training INFO: iter: 106680/144360  CE: 2.8495  
[05/05 01:17:55] SuperNet Training INFO: iter: 106800/144360  CE: 3.1639  
[05/05 01:18:56] SuperNet Training INFO: iter: 106920/144360  CE: 3.0388  
[05/05 01:19:59] SuperNet Training INFO: iter: 107040/144360  CE: 3.2917  
[05/05 01:20:12] SuperNet Training INFO: --> epoch:  89/120  avg CE: 3.1326  lr: 0.018698725458374543  
[05/05 01:21:37] SuperNet Training INFO: iter: 107160/144360  CE: 3.1338  
[05/05 01:22:40] SuperNet Training INFO: iter: 107280/144360  CE: 3.1723  
[05/05 01:23:42] SuperNet Training INFO: iter: 107400/144360  CE: 3.1660  
[05/05 01:24:44] SuperNet Training INFO: iter: 107520/144360  CE: 2.8672  
[05/05 01:25:45] SuperNet Training INFO: iter: 107640/144360  CE: 3.3947  
[05/05 01:26:47] SuperNet Training INFO: iter: 107760/144360  CE: 2.7724  
[05/05 01:27:49] SuperNet Training INFO: iter: 107880/144360  CE: 3.1689  
[05/05 01:28:51] SuperNet Training INFO: iter: 108000/144360  CE: 3.0633  
[05/05 01:29:52] SuperNet Training INFO: iter: 108120/144360  CE: 3.1847  
[05/05 01:30:54] SuperNet Training INFO: iter: 108240/144360  CE: 3.3263  
[05/05 01:31:08] SuperNet Training INFO: --> epoch:  90/120  avg CE: 3.1261  lr: 0.01757359312880703  
[05/05 01:32:32] SuperNet Training INFO: iter: 108360/144360  CE: 3.2659  
[05/05 01:33:33] SuperNet Training INFO: iter: 108480/144360  CE: 2.9693  
[05/05 01:34:34] SuperNet Training INFO: iter: 108600/144360  CE: 3.1432  
[05/05 01:35:36] SuperNet Training INFO: iter: 108720/144360  CE: 3.3478  
[05/05 01:36:36] SuperNet Training INFO: iter: 108840/144360  CE: 3.0610  
[05/05 01:37:37] SuperNet Training INFO: iter: 108960/144360  CE: 2.8839  
[05/05 01:38:38] SuperNet Training INFO: iter: 109080/144360  CE: 3.0610  
[05/05 01:39:38] SuperNet Training INFO: iter: 109200/144360  CE: 3.0444  
[05/05 01:40:39] SuperNet Training INFO: iter: 109320/144360  CE: 3.1533  
[05/05 01:41:40] SuperNet Training INFO: iter: 109440/144360  CE: 2.9312  
[05/05 01:41:56] SuperNet Training INFO: --> epoch:  91/120  avg CE: 3.1078  lr: 0.016477537739262627  
[05/05 01:43:17] SuperNet Training INFO: iter: 109560/144360  CE: 2.9528  
[05/05 01:44:18] SuperNet Training INFO: iter: 109680/144360  CE: 3.0651  
[05/05 01:45:18] SuperNet Training INFO: iter: 109800/144360  CE: 3.0644  
[05/05 01:46:20] SuperNet Training INFO: iter: 109920/144360  CE: 2.9447  
[05/05 01:47:21] SuperNet Training INFO: iter: 110040/144360  CE: 2.9550  
[05/05 01:48:22] SuperNet Training INFO: iter: 110160/144360  CE: 2.7574  
[05/05 01:49:23] SuperNet Training INFO: iter: 110280/144360  CE: 2.9908  
[05/05 01:50:23] SuperNet Training INFO: iter: 110400/144360  CE: 3.0341  
[05/05 01:51:23] SuperNet Training INFO: iter: 110520/144360  CE: 3.0869  
[05/05 01:52:23] SuperNet Training INFO: iter: 110640/144360  CE: 3.2851  
[05/05 01:52:41] SuperNet Training INFO: --> epoch:  92/120  avg CE: 3.1021  lr: 0.015411310471356233  
[05/05 01:54:01] SuperNet Training INFO: iter: 110760/144360  CE: 3.2263  
[05/05 01:55:02] SuperNet Training INFO: iter: 110880/144360  CE: 3.0620  
[05/05 01:56:04] SuperNet Training INFO: iter: 111000/144360  CE: 2.9134  
[05/05 01:57:06] SuperNet Training INFO: iter: 111120/144360  CE: 3.3953  
[05/05 01:58:06] SuperNet Training INFO: iter: 111240/144360  CE: 3.2018  
[05/05 01:59:07] SuperNet Training INFO: iter: 111360/144360  CE: 2.5417  
[05/05 02:00:07] SuperNet Training INFO: iter: 111480/144360  CE: 3.3447  
[05/05 02:01:08] SuperNet Training INFO: iter: 111600/144360  CE: 2.7733  
[05/05 02:02:08] SuperNet Training INFO: iter: 111720/144360  CE: 3.2948  
[05/05 02:03:08] SuperNet Training INFO: iter: 111840/144360  CE: 2.9888  
[05/05 02:03:26] SuperNet Training INFO: --> epoch:  93/120  avg CE: 3.0948  lr: 0.014375642063998082  
[05/05 02:04:45] SuperNet Training INFO: iter: 111960/144360  CE: 2.9833  
[05/05 02:05:48] SuperNet Training INFO: iter: 112080/144360  CE: 3.2550  
[05/05 02:06:49] SuperNet Training INFO: iter: 112200/144360  CE: 2.9158  
[05/05 02:07:49] SuperNet Training INFO: iter: 112320/144360  CE: 2.9549  
[05/05 02:08:50] SuperNet Training INFO: iter: 112440/144360  CE: 3.4944  
[05/05 02:09:51] SuperNet Training INFO: iter: 112560/144360  CE: 3.0733  
[05/05 02:10:52] SuperNet Training INFO: iter: 112680/144360  CE: 3.0584  
[05/05 02:11:52] SuperNet Training INFO: iter: 112800/144360  CE: 2.7984  
[05/05 02:12:52] SuperNet Training INFO: iter: 112920/144360  CE: 2.8755  
[05/05 02:13:52] SuperNet Training INFO: iter: 113040/144360  CE: 2.7530  
[05/05 02:14:13] SuperNet Training INFO: --> epoch:  94/120  avg CE: 3.0846  lr: 0.01337124231258167  
[05/05 02:15:31] SuperNet Training INFO: iter: 113160/144360  CE: 2.9810  
[05/05 02:16:32] SuperNet Training INFO: iter: 113280/144360  CE: 3.0874  
[05/05 02:17:35] SuperNet Training INFO: iter: 113400/144360  CE: 3.0702  
[05/05 02:18:36] SuperNet Training INFO: iter: 113520/144360  CE: 3.2414  
[05/05 02:19:35] SuperNet Training INFO: iter: 113640/144360  CE: 3.1138  
[05/05 02:20:37] SuperNet Training INFO: iter: 113760/144360  CE: 2.8275  
[05/05 02:21:38] SuperNet Training INFO: iter: 113880/144360  CE: 2.7947  
[05/05 02:22:38] SuperNet Training INFO: iter: 114000/144360  CE: 2.9096  
[05/05 02:23:39] SuperNet Training INFO: iter: 114120/144360  CE: 2.9225  
[05/05 02:24:43] SuperNet Training INFO: iter: 114240/144360  CE: 3.1323  
[05/05 02:25:05] SuperNet Training INFO: --> epoch:  95/120  avg CE: 3.0815  lr: 0.012398799582525794  
[05/05 02:26:22] SuperNet Training INFO: iter: 114360/144360  CE: 2.9504  
[05/05 02:27:23] SuperNet Training INFO: iter: 114480/144360  CE: 2.9929  
[05/05 02:28:24] SuperNet Training INFO: iter: 114600/144360  CE: 3.0414  
[05/05 02:29:26] SuperNet Training INFO: iter: 114720/144360  CE: 2.9803  
[05/05 02:30:28] SuperNet Training INFO: iter: 114840/144360  CE: 3.0932  
[05/05 02:31:28] SuperNet Training INFO: iter: 114960/144360  CE: 3.0650  
[05/05 02:32:31] SuperNet Training INFO: iter: 115080/144360  CE: 2.8748  
[05/05 02:33:32] SuperNet Training INFO: iter: 115200/144360  CE: 3.0920  
[05/05 02:34:33] SuperNet Training INFO: iter: 115320/144360  CE: 3.1996  
[05/05 02:35:34] SuperNet Training INFO: iter: 115440/144360  CE: 2.9543  
[05/05 02:35:57] SuperNet Training INFO: --> epoch:  96/120  avg CE: 3.0744  lr: 0.01145898033750309  
[05/05 02:37:11] SuperNet Training INFO: iter: 115560/144360  CE: 3.0982  
[05/05 02:38:13] SuperNet Training INFO: iter: 115680/144360  CE: 2.7928  
[05/05 02:39:16] SuperNet Training INFO: iter: 115800/144360  CE: 3.1999  
[05/05 02:40:18] SuperNet Training INFO: iter: 115920/144360  CE: 3.0192  
[05/05 02:41:20] SuperNet Training INFO: iter: 116040/144360  CE: 3.1310  
[05/05 02:42:21] SuperNet Training INFO: iter: 116160/144360  CE: 2.8935  
[05/05 02:43:23] SuperNet Training INFO: iter: 116280/144360  CE: 2.7926  
[05/05 02:44:24] SuperNet Training INFO: iter: 116400/144360  CE: 3.0066  
[05/05 02:45:25] SuperNet Training INFO: iter: 116520/144360  CE: 3.1377  
[05/05 02:46:26] SuperNet Training INFO: iter: 116640/144360  CE: 3.0990  
[05/05 02:46:50] SuperNet Training INFO: --> epoch:  97/120  avg CE: 3.0550  lr: 0.01055242868267905  
[05/05 02:48:04] SuperNet Training INFO: iter: 116760/144360  CE: 2.9833  
[05/05 02:49:05] SuperNet Training INFO: iter: 116880/144360  CE: 2.7338  
[05/05 02:50:07] SuperNet Training INFO: iter: 117000/144360  CE: 3.1065  
[05/05 02:51:09] SuperNet Training INFO: iter: 117120/144360  CE: 3.0868  
[05/05 02:52:10] SuperNet Training INFO: iter: 117240/144360  CE: 2.8623  
[05/05 02:53:10] SuperNet Training INFO: iter: 117360/144360  CE: 2.9072  
[05/05 02:54:12] SuperNet Training INFO: iter: 117480/144360  CE: 2.8256  
[05/05 02:55:12] SuperNet Training INFO: iter: 117600/144360  CE: 2.8892  
[05/05 02:56:12] SuperNet Training INFO: iter: 117720/144360  CE: 3.2120  
[05/05 02:57:13] SuperNet Training INFO: iter: 117840/144360  CE: 3.0832  
[05/05 02:57:39] SuperNet Training INFO: --> epoch:  98/120  avg CE: 3.0476  lr: 0.009679765923274538  
[05/05 02:58:51] SuperNet Training INFO: iter: 117960/144360  CE: 3.0763  
[05/05 02:59:53] SuperNet Training INFO: iter: 118080/144360  CE: 3.0477  
[05/05 03:00:54] SuperNet Training INFO: iter: 118200/144360  CE: 3.3483  
[05/05 03:01:57] SuperNet Training INFO: iter: 118320/144360  CE: 3.0461  
[05/05 03:02:58] SuperNet Training INFO: iter: 118440/144360  CE: 3.2178  
[05/05 03:04:01] SuperNet Training INFO: iter: 118560/144360  CE: 2.7085  
[05/05 03:05:01] SuperNet Training INFO: iter: 118680/144360  CE: 3.0807  
[05/05 03:06:03] SuperNet Training INFO: iter: 118800/144360  CE: 2.6991  
[05/05 03:07:03] SuperNet Training INFO: iter: 118920/144360  CE: 3.2645  
[05/05 03:08:05] SuperNet Training INFO: iter: 119040/144360  CE: 3.0406  
[05/05 03:08:33] SuperNet Training INFO: --> epoch:  99/120  avg CE: 3.0382  lr: 0.008841590138754444  
[05/05 03:09:42] SuperNet Training INFO: iter: 119160/144360  CE: 2.7623  
[05/05 03:10:42] SuperNet Training INFO: iter: 119280/144360  CE: 2.9747  
[05/05 03:11:45] SuperNet Training INFO: iter: 119400/144360  CE: 3.1619  
[05/05 03:12:46] SuperNet Training INFO: iter: 119520/144360  CE: 3.1483  
[05/05 03:13:47] SuperNet Training INFO: iter: 119640/144360  CE: 2.9673  
[05/05 03:14:49] SuperNet Training INFO: iter: 119760/144360  CE: 2.9839  
[05/05 03:15:49] SuperNet Training INFO: iter: 119880/144360  CE: 2.9328  
[05/05 03:16:50] SuperNet Training INFO: iter: 120000/144360  CE: 3.0730  
[05/05 03:17:49] SuperNet Training INFO: iter: 120120/144360  CE: 3.0917  
[05/05 03:18:49] SuperNet Training INFO: iter: 120240/144360  CE: 2.8510  
[05/05 03:19:18] SuperNet Training INFO: --> epoch: 100/120  avg CE: 3.0244  lr: 0.00803847577293368  
[05/05 03:20:26] SuperNet Training INFO: iter: 120360/144360  CE: 2.9357  
[05/05 03:21:28] SuperNet Training INFO: iter: 120480/144360  CE: 2.7318  
[05/05 03:22:30] SuperNet Training INFO: iter: 120600/144360  CE: 3.1371  
[05/05 03:23:30] SuperNet Training INFO: iter: 120720/144360  CE: 3.3353  
[05/05 03:24:33] SuperNet Training INFO: iter: 120840/144360  CE: 3.2450  
[05/05 03:25:34] SuperNet Training INFO: iter: 120960/144360  CE: 2.9014  
[05/05 03:26:37] SuperNet Training INFO: iter: 121080/144360  CE: 2.9049  
[05/05 03:27:38] SuperNet Training INFO: iter: 121200/144360  CE: 2.9918  
[05/05 03:28:40] SuperNet Training INFO: iter: 121320/144360  CE: 3.3197  
[05/05 03:29:42] SuperNet Training INFO: iter: 121440/144360  CE: 2.8558  
[05/05 03:30:13] SuperNet Training INFO: --> epoch: 101/120  avg CE: 3.0309  lr: 0.007270973240282054  
[05/05 03:31:20] SuperNet Training INFO: iter: 121560/144360  CE: 2.9379  
[05/05 03:32:21] SuperNet Training INFO: iter: 121680/144360  CE: 2.9966  
[05/05 03:33:21] SuperNet Training INFO: iter: 121800/144360  CE: 3.0252  
[05/05 03:34:21] SuperNet Training INFO: iter: 121920/144360  CE: 2.7619  
[05/05 03:35:21] SuperNet Training INFO: iter: 122040/144360  CE: 2.9614  
[05/05 03:36:21] SuperNet Training INFO: iter: 122160/144360  CE: 3.2867  
[05/05 03:37:21] SuperNet Training INFO: iter: 122280/144360  CE: 2.8178  
[05/05 03:38:23] SuperNet Training INFO: iter: 122400/144360  CE: 2.9822  
[05/05 03:39:24] SuperNet Training INFO: iter: 122520/144360  CE: 3.1630  
[05/05 03:40:25] SuperNet Training INFO: iter: 122640/144360  CE: 3.2470  
[05/05 03:40:58] SuperNet Training INFO: --> epoch: 102/120  avg CE: 3.0187  lr: 0.006539608548697928  
[05/05 03:42:02] SuperNet Training INFO: iter: 122760/144360  CE: 3.1241  
[05/05 03:43:04] SuperNet Training INFO: iter: 122880/144360  CE: 3.1321  
[05/05 03:44:06] SuperNet Training INFO: iter: 123000/144360  CE: 2.9444  
[05/05 03:45:08] SuperNet Training INFO: iter: 123120/144360  CE: 2.9856  
[05/05 03:46:08] SuperNet Training INFO: iter: 123240/144360  CE: 3.0114  
[05/05 03:47:10] SuperNet Training INFO: iter: 123360/144360  CE: 3.0365  
[05/05 03:48:09] SuperNet Training INFO: iter: 123480/144360  CE: 3.1083  
[05/05 03:49:10] SuperNet Training INFO: iter: 123600/144360  CE: 3.1257  
[05/05 03:50:10] SuperNet Training INFO: iter: 123720/144360  CE: 3.2468  
[05/05 03:51:10] SuperNet Training INFO: iter: 123840/144360  CE: 3.2253  
[05/05 03:51:43] SuperNet Training INFO: --> epoch: 103/120  avg CE: 3.0209  lr: 0.00584488293900834  
[05/05 03:52:46] SuperNet Training INFO: iter: 123960/144360  CE: 2.9893  
[05/05 03:53:46] SuperNet Training INFO: iter: 124080/144360  CE: 3.0324  
[05/05 03:54:47] SuperNet Training INFO: iter: 124200/144360  CE: 3.0386  
[05/05 03:55:49] SuperNet Training INFO: iter: 124320/144360  CE: 3.0233  
[05/05 03:56:49] SuperNet Training INFO: iter: 124440/144360  CE: 3.0922  
[05/05 03:57:50] SuperNet Training INFO: iter: 124560/144360  CE: 2.8960  
[05/05 03:58:50] SuperNet Training INFO: iter: 124680/144360  CE: 3.1171  
[05/05 03:59:50] SuperNet Training INFO: iter: 124800/144360  CE: 2.9176  
[05/05 04:00:51] SuperNet Training INFO: iter: 124920/144360  CE: 2.9653  
[05/05 04:01:52] SuperNet Training INFO: iter: 125040/144360  CE: 3.1307  
[05/05 04:02:27] SuperNet Training INFO: --> epoch: 104/120  avg CE: 3.0018  lr: 0.005187272541443939  
[05/05 04:03:27] SuperNet Training INFO: iter: 125160/144360  CE: 3.1369  
[05/05 04:04:27] SuperNet Training INFO: iter: 125280/144360  CE: 2.9673  
[05/05 04:05:28] SuperNet Training INFO: iter: 125400/144360  CE: 2.8960  
[05/05 04:06:28] SuperNet Training INFO: iter: 125520/144360  CE: 3.1857  
[05/05 04:07:30] SuperNet Training INFO: iter: 125640/144360  CE: 3.3150  
[05/05 04:08:31] SuperNet Training INFO: iter: 125760/144360  CE: 2.8210  
[05/05 04:09:32] SuperNet Training INFO: iter: 125880/144360  CE: 2.9222  
[05/05 04:10:33] SuperNet Training INFO: iter: 126000/144360  CE: 2.9033  
[05/05 04:11:35] SuperNet Training INFO: iter: 126120/144360  CE: 2.8277  
[05/05 04:12:37] SuperNet Training INFO: iter: 126240/144360  CE: 2.9630  
[05/05 04:13:14] SuperNet Training INFO: --> epoch: 105/120  avg CE: 2.9975  lr: 0.00456722804932279  
[05/05 04:14:14] SuperNet Training INFO: iter: 126360/144360  CE: 2.8903  
[05/05 04:15:16] SuperNet Training INFO: iter: 126480/144360  CE: 3.0009  
[05/05 04:16:16] SuperNet Training INFO: iter: 126600/144360  CE: 2.9220  
[05/05 04:17:17] SuperNet Training INFO: iter: 126720/144360  CE: 2.8762  
[05/05 04:18:19] SuperNet Training INFO: iter: 126840/144360  CE: 2.8933  
[05/05 04:19:21] SuperNet Training INFO: iter: 126960/144360  CE: 2.8797  
[05/05 04:20:22] SuperNet Training INFO: iter: 127080/144360  CE: 2.9520  
[05/05 04:21:23] SuperNet Training INFO: iter: 127200/144360  CE: 2.9134  
[05/05 04:22:25] SuperNet Training INFO: iter: 127320/144360  CE: 2.9853  
[05/05 04:23:25] SuperNet Training INFO: iter: 127440/144360  CE: 2.7055  
[05/05 04:24:03] SuperNet Training INFO: --> epoch: 106/120  avg CE: 2.9865  lr: 0.003985174410167894  
[05/05 04:25:02] SuperNet Training INFO: iter: 127560/144360  CE: 2.7686  
[05/05 04:26:04] SuperNet Training INFO: iter: 127680/144360  CE: 2.8479  
[05/05 04:27:06] SuperNet Training INFO: iter: 127800/144360  CE: 2.9910  
[05/05 04:28:06] SuperNet Training INFO: iter: 127920/144360  CE: 2.8581  
[05/05 04:29:07] SuperNet Training INFO: iter: 128040/144360  CE: 2.6991  
[05/05 04:30:08] SuperNet Training INFO: iter: 128160/144360  CE: 3.2397  
[05/05 04:31:09] SuperNet Training INFO: iter: 128280/144360  CE: 2.8920  
[05/05 04:32:09] SuperNet Training INFO: iter: 128400/144360  CE: 2.8286  
[05/05 04:33:12] SuperNet Training INFO: iter: 128520/144360  CE: 2.8206  
[05/05 04:34:12] SuperNet Training INFO: iter: 128640/144360  CE: 3.1305  
[05/05 04:34:53] SuperNet Training INFO: --> epoch: 107/120  avg CE: 2.9862  lr: 0.003441510534469298  
[05/05 04:35:50] SuperNet Training INFO: iter: 128760/144360  CE: 2.9346  
[05/05 04:36:50] SuperNet Training INFO: iter: 128880/144360  CE: 2.8664  
[05/05 04:37:50] SuperNet Training INFO: iter: 129000/144360  CE: 3.0068  
[05/05 04:38:52] SuperNet Training INFO: iter: 129120/144360  CE: 3.0069  
[05/05 04:39:54] SuperNet Training INFO: iter: 129240/144360  CE: 2.9868  
[05/05 04:40:55] SuperNet Training INFO: iter: 129360/144360  CE: 2.9118  
[05/05 04:41:58] SuperNet Training INFO: iter: 129480/144360  CE: 3.1104  
[05/05 04:42:59] SuperNet Training INFO: iter: 129600/144360  CE: 3.1573  
[05/05 04:44:00] SuperNet Training INFO: iter: 129720/144360  CE: 2.9845  
[05/05 04:45:01] SuperNet Training INFO: iter: 129840/144360  CE: 3.1823  
[05/05 04:45:42] SuperNet Training INFO: --> epoch: 108/120  avg CE: 2.9817  lr: 0.002936609022290792  
[05/05 04:46:36] SuperNet Training INFO: iter: 129960/144360  CE: 3.0712  
[05/05 04:47:37] SuperNet Training INFO: iter: 130080/144360  CE: 2.9057  
[05/05 04:48:37] SuperNet Training INFO: iter: 130200/144360  CE: 3.0360  
[05/05 04:49:38] SuperNet Training INFO: iter: 130320/144360  CE: 2.8624  
[05/05 04:50:37] SuperNet Training INFO: iter: 130440/144360  CE: 3.0730  
[05/05 04:51:39] SuperNet Training INFO: iter: 130560/144360  CE: 2.9157  
[05/05 04:52:39] SuperNet Training INFO: iter: 130680/144360  CE: 3.2869  
[05/05 04:53:40] SuperNet Training INFO: iter: 130800/144360  CE: 3.0681  
[05/05 04:54:40] SuperNet Training INFO: iter: 130920/144360  CE: 3.3110  
[05/05 04:55:40] SuperNet Training INFO: iter: 131040/144360  CE: 2.8912  
[05/05 04:56:23] SuperNet Training INFO: --> epoch: 109/120  avg CE: 2.9786  lr: 0.0024708159079084185  
[05/05 04:57:17] SuperNet Training INFO: iter: 131160/144360  CE: 2.9974  
[05/05 04:58:18] SuperNet Training INFO: iter: 131280/144360  CE: 3.1184  
[05/05 04:59:20] SuperNet Training INFO: iter: 131400/144360  CE: 2.8777  
[05/05 05:00:21] SuperNet Training INFO: iter: 131520/144360  CE: 2.7152  
[05/05 05:01:22] SuperNet Training INFO: iter: 131640/144360  CE: 3.2142  
[05/05 05:02:23] SuperNet Training INFO: iter: 131760/144360  CE: 2.7875  
[05/05 05:03:24] SuperNet Training INFO: iter: 131880/144360  CE: 3.5020  
[05/05 05:04:25] SuperNet Training INFO: iter: 132000/144360  CE: 2.7848  
[05/05 05:05:27] SuperNet Training INFO: iter: 132120/144360  CE: 3.0500  
[05/05 05:06:28] SuperNet Training INFO: iter: 132240/144360  CE: 3.1835  
[05/05 05:07:13] SuperNet Training INFO: --> epoch: 110/120  avg CE: 2.9773  lr: 0.0020444504226559065  
[05/05 05:08:04] SuperNet Training INFO: iter: 132360/144360  CE: 3.1026  
[05/05 05:09:06] SuperNet Training INFO: iter: 132480/144360  CE: 3.3053  
[05/05 05:10:07] SuperNet Training INFO: iter: 132600/144360  CE: 3.0484  
[05/05 05:11:09] SuperNet Training INFO: iter: 132720/144360  CE: 2.7121  
[05/05 05:12:10] SuperNet Training INFO: iter: 132840/144360  CE: 3.2213  
[05/05 05:13:13] SuperNet Training INFO: iter: 132960/144360  CE: 2.9643  
[05/05 05:14:16] SuperNet Training INFO: iter: 133080/144360  CE: 3.0780  
[05/05 05:15:18] SuperNet Training INFO: iter: 133200/144360  CE: 2.9255  
[05/05 05:16:18] SuperNet Training INFO: iter: 133320/144360  CE: 2.8331  
[05/05 05:17:18] SuperNet Training INFO: iter: 133440/144360  CE: 3.0077  
[05/05 05:18:04] SuperNet Training INFO: --> epoch: 111/120  avg CE: 2.9730  lr: 0.0016578047761394107  
[05/05 05:18:54] SuperNet Training INFO: iter: 133560/144360  CE: 3.0122  
[05/05 05:19:56] SuperNet Training INFO: iter: 133680/144360  CE: 3.1189  
[05/05 05:20:56] SuperNet Training INFO: iter: 133800/144360  CE: 3.0896  
[05/05 05:21:57] SuperNet Training INFO: iter: 133920/144360  CE: 3.2037  
[05/05 05:22:58] SuperNet Training INFO: iter: 134040/144360  CE: 2.7691  
[05/05 05:23:58] SuperNet Training INFO: iter: 134160/144360  CE: 2.8071  
[05/05 05:24:59] SuperNet Training INFO: iter: 134280/144360  CE: 3.0153  
[05/05 05:26:00] SuperNet Training INFO: iter: 134400/144360  CE: 3.0030  
[05/05 05:27:01] SuperNet Training INFO: iter: 134520/144360  CE: 2.8437  
[05/05 05:28:01] SuperNet Training INFO: iter: 134640/144360  CE: 2.9682  
[05/05 05:28:49] SuperNet Training INFO: --> epoch: 112/120  avg CE: 2.9804  lr: 0.0013111439559716617  
[05/05 05:29:38] SuperNet Training INFO: iter: 134760/144360  CE: 2.9023  
[05/05 05:30:40] SuperNet Training INFO: iter: 134880/144360  CE: 2.9668  
[05/05 05:31:41] SuperNet Training INFO: iter: 135000/144360  CE: 2.9561  
[05/05 05:32:43] SuperNet Training INFO: iter: 135120/144360  CE: 2.8750  
[05/05 05:33:44] SuperNet Training INFO: iter: 135240/144360  CE: 2.8081  
[05/05 05:34:46] SuperNet Training INFO: iter: 135360/144360  CE: 3.1711  
[05/05 05:35:48] SuperNet Training INFO: iter: 135480/144360  CE: 3.1303  
[05/05 05:36:49] SuperNet Training INFO: iter: 135600/144360  CE: 2.9043  
[05/05 05:37:50] SuperNet Training INFO: iter: 135720/144360  CE: 2.8308  
[05/05 05:38:51] SuperNet Training INFO: iter: 135840/144360  CE: 2.8475  
[05/05 05:39:40] SuperNet Training INFO: --> epoch: 113/120  avg CE: 2.9686  lr: 0.0010047055461627253  
[05/05 05:40:28] SuperNet Training INFO: iter: 135960/144360  CE: 3.0164  
[05/05 05:41:30] SuperNet Training INFO: iter: 136080/144360  CE: 2.9316  
[05/05 05:42:32] SuperNet Training INFO: iter: 136200/144360  CE: 2.8207  
[05/05 05:43:34] SuperNet Training INFO: iter: 136320/144360  CE: 3.1942  
[05/05 05:44:35] SuperNet Training INFO: iter: 136440/144360  CE: 3.0179  
[05/05 05:45:37] SuperNet Training INFO: iter: 136560/144360  CE: 2.6671  
[05/05 05:46:39] SuperNet Training INFO: iter: 136680/144360  CE: 2.9511  
[05/05 05:47:41] SuperNet Training INFO: iter: 136800/144360  CE: 2.8050  
[05/05 05:48:42] SuperNet Training INFO: iter: 136920/144360  CE: 2.9199  
[05/05 05:49:43] SuperNet Training INFO: iter: 137040/144360  CE: 3.2470  
[05/05 05:50:32] SuperNet Training INFO: --> epoch: 114/120  avg CE: 2.9666  lr: 0.000738699564291742  
[05/05 05:51:18] SuperNet Training INFO: iter: 137160/144360  CE: 2.7178  
[05/05 05:52:20] SuperNet Training INFO: iter: 137280/144360  CE: 2.6560  
[05/05 05:53:22] SuperNet Training INFO: iter: 137400/144360  CE: 2.5607  
[05/05 05:54:23] SuperNet Training INFO: iter: 137520/144360  CE: 2.9263  
[05/05 05:55:23] SuperNet Training INFO: iter: 137640/144360  CE: 2.7787  
[05/05 05:56:24] SuperNet Training INFO: iter: 137760/144360  CE: 2.9346  
[05/05 05:57:26] SuperNet Training INFO: iter: 137880/144360  CE: 2.7450  
[05/05 05:58:26] SuperNet Training INFO: iter: 138000/144360  CE: 3.0274  
[05/05 05:59:27] SuperNet Training INFO: iter: 138120/144360  CE: 2.8293  
[05/05 06:00:27] SuperNet Training INFO: iter: 138240/144360  CE: 2.9653  
[05/05 06:01:20] SuperNet Training INFO: --> epoch: 115/120  avg CE: 2.9619  lr: 0.0005133083175713779  
[05/05 06:02:04] SuperNet Training INFO: iter: 138360/144360  CE: 2.9706  
[05/05 06:03:04] SuperNet Training INFO: iter: 138480/144360  CE: 3.1186  
[05/05 06:04:04] SuperNet Training INFO: iter: 138600/144360  CE: 2.7609  
[05/05 06:05:06] SuperNet Training INFO: iter: 138720/144360  CE: 2.9601  
[05/05 06:06:07] SuperNet Training INFO: iter: 138840/144360  CE: 2.9695  
[05/05 06:07:08] SuperNet Training INFO: iter: 138960/144360  CE: 3.1219  
[05/05 06:08:08] SuperNet Training INFO: iter: 139080/144360  CE: 2.8921  
[05/05 06:09:09] SuperNet Training INFO: iter: 139200/144360  CE: 3.0417  
[05/05 06:10:11] SuperNet Training INFO: iter: 139320/144360  CE: 2.9023  
[05/05 06:11:12] SuperNet Training INFO: iter: 139440/144360  CE: 3.0182  
[05/05 06:12:06] SuperNet Training INFO: --> epoch: 116/120  avg CE: 2.9591  lr: 0.00032868627790359544  
[05/05 06:12:48] SuperNet Training INFO: iter: 139560/144360  CE: 2.9115  
[05/05 06:13:49] SuperNet Training INFO: iter: 139680/144360  CE: 2.8837  
[05/05 06:14:51] SuperNet Training INFO: iter: 139800/144360  CE: 2.5323  
[05/05 06:15:52] SuperNet Training INFO: iter: 139920/144360  CE: 2.8624  
[05/05 06:16:52] SuperNet Training INFO: iter: 140040/144360  CE: 2.6637  
[05/05 06:17:54] SuperNet Training INFO: iter: 140160/144360  CE: 2.9604  
[05/05 06:18:54] SuperNet Training INFO: iter: 140280/144360  CE: 2.7612  
[05/05 06:19:55] SuperNet Training INFO: iter: 140400/144360  CE: 2.8600  
[05/05 06:20:58] SuperNet Training INFO: iter: 140520/144360  CE: 2.9882  
[05/05 06:21:58] SuperNet Training INFO: iter: 140640/144360  CE: 2.9908  
[05/05 06:22:55] SuperNet Training INFO: --> epoch: 117/120  avg CE: 2.9613  lr: 0.00018495997601232129  
[05/05 06:23:37] SuperNet Training INFO: iter: 140760/144360  CE: 2.9138  
[05/05 06:24:40] SuperNet Training INFO: iter: 140880/144360  CE: 3.0998  
[05/05 06:25:41] SuperNet Training INFO: iter: 141000/144360  CE: 3.1678  
[05/05 06:26:43] SuperNet Training INFO: iter: 141120/144360  CE: 3.1143  
[05/05 06:27:44] SuperNet Training INFO: iter: 141240/144360  CE: 3.2687  
[05/05 06:28:46] SuperNet Training INFO: iter: 141360/144360  CE: 2.7160  
[05/05 06:29:49] SuperNet Training INFO: iter: 141480/144360  CE: 2.8767  
[05/05 06:30:49] SuperNet Training INFO: iter: 141600/144360  CE: 3.0237  
[05/05 06:31:52] SuperNet Training INFO: iter: 141720/144360  CE: 2.8425  
[05/05 06:32:53] SuperNet Training INFO: iter: 141840/144360  CE: 2.9188  
[05/05 06:33:50] SuperNet Training INFO: --> epoch: 118/120  avg CE: 2.9546  lr: 8.222791472556962e-05  
[05/05 06:34:30] SuperNet Training INFO: iter: 141960/144360  CE: 2.8693  
[05/05 06:35:30] SuperNet Training INFO: iter: 142080/144360  CE: 2.8924  
[05/05 06:36:32] SuperNet Training INFO: iter: 142200/144360  CE: 3.1615  
[05/05 06:37:32] SuperNet Training INFO: iter: 142320/144360  CE: 2.8719  
[05/05 06:38:34] SuperNet Training INFO: iter: 142440/144360  CE: 2.9308  
[05/05 06:39:35] SuperNet Training INFO: iter: 142560/144360  CE: 2.9715  
[05/05 06:40:37] SuperNet Training INFO: iter: 142680/144360  CE: 2.8905  
[05/05 06:41:37] SuperNet Training INFO: iter: 142800/144360  CE: 2.8740  
[05/05 06:42:39] SuperNet Training INFO: iter: 142920/144360  CE: 2.8729  
[05/05 06:43:40] SuperNet Training INFO: iter: 143040/144360  CE: 2.9277  
[05/05 06:44:39] SuperNet Training INFO: --> epoch: 119/120  avg CE: 2.9499  lr: 2.0560501466564365e-05  
[05/05 06:45:17] SuperNet Training INFO: iter: 143160/144360  CE: 2.8415  
[05/05 06:46:18] SuperNet Training INFO: iter: 143280/144360  CE: 2.7441  
[05/05 06:47:20] SuperNet Training INFO: iter: 143400/144360  CE: 2.6613  
[05/05 06:48:23] SuperNet Training INFO: iter: 143520/144360  CE: 2.6937  
[05/05 06:49:25] SuperNet Training INFO: iter: 143640/144360  CE: 2.9719  
[05/05 06:50:26] SuperNet Training INFO: iter: 143760/144360  CE: 3.0079  
[05/05 06:51:28] SuperNet Training INFO: iter: 143880/144360  CE: 3.0190  
[05/05 06:52:29] SuperNet Training INFO: iter: 144000/144360  CE: 3.2233  
[05/05 06:53:31] SuperNet Training INFO: iter: 144120/144360  CE: 3.0006  
[05/05 06:54:31] SuperNet Training INFO: iter: 144240/144360  CE: 3.0719  
[05/05 06:55:32] SuperNet Training INFO: iter: 144360/144360  CE: 3.3985  
[05/05 06:55:32] SuperNet Training INFO: --> epoch: 120/120  avg CE: 2.9566  lr: 0.0  
[05/05 06:55:32] SuperNet Training INFO: --> END mobile0-tbs236-seed-0
[05/05 06:55:32] SuperNet Training INFO: {0: 72180, 1: 72180}
[05/05 06:55:38] SuperNet Training INFO: ELAPSED TIME: 78356.6(s) = 21(h) 45(m)
